{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9a4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from collections import Counter, defaultdict, deque\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, log_loss, roc_auc_score\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29506b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# suppress only the “y_pred values do not sum to one” warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*y_pred values do not sum to one.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc7a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = -∑_c [1{c = y_true_i} · log P_model(c | x_i)]\n",
    "    If the true label isn’t in model.classes_, returns a default high loss.\n",
    "    Works for any len(x_test) >= 1, including the single-class case.\n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(x_test)\n",
    "    default = log_loss([[1, 0]], [[0, 1]]) + 1  # fallback loss\n",
    "\n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        classes = model.classes_\n",
    "\n",
    "        # if only one class in the model\n",
    "        if sample_probs.size == 1:\n",
    "            if classes[0] == true_label:\n",
    "                losses.append(0.0)  # perfect prediction\n",
    "            else:\n",
    "                losses.append(default)\n",
    "            continue\n",
    "\n",
    "        # find index of the true label\n",
    "        idx_arr = np.where(classes == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(default)\n",
    "        else:\n",
    "            y_true_onehot = np.zeros_like(sample_probs)\n",
    "            y_true_onehot[idx_arr[0]] = 1\n",
    "\n",
    "            # normalize just in case\n",
    "            sample_probs = sample_probs / sample_probs.sum()\n",
    "            y_true_onehot = y_true_onehot / y_true_onehot.sum()\n",
    "\n",
    "            loss_i = log_loss([y_true_onehot], [sample_probs])\n",
    "            losses.append(loss_i)\n",
    "\n",
    "    return np.array(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4baf8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = 1 - P_model(y_true_i | x_i)\n",
    "    If the true label isn’t in model.classes_, we return 1.1 as before.\n",
    "    Works for any len(x_test) >= 1.\n",
    "    \"\"\"\n",
    "    # predict_proba returns shape (n_samples, n_classes)\n",
    "    probs = model.predict_proba(x_test)\n",
    "    \n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        # find index of the true label in model.classes_\n",
    "        idx_arr = np.where(model.classes_ == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(1.1)\n",
    "        else:\n",
    "            col_index = idx_arr[0]\n",
    "            losses.append(1 - sample_probs[col_index])\n",
    "    \n",
    "    return np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ae2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_transform_target(encoder, targets, unknown_value=-1):\n",
    "    classes = set(encoder.classes_)\n",
    "    transformed = []\n",
    "    for t in targets:\n",
    "        if t in classes:\n",
    "            transformed.append(encoder.transform([t])[0])\n",
    "        else:\n",
    "            transformed.append(unknown_value)\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e5afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_loss(normal_loss_value, cross_entropy_loss_value):\n",
    "    normal_loss_dist = []\n",
    "    cross_loss_dist = []\n",
    "    for pos, prediction in  enumerate(normal_loss_value):\n",
    "        if prediction != 1:\n",
    "            cross_loss_dist.append(cross_entropy_loss_value[pos])\n",
    "            normal_loss_dist.append(prediction)\n",
    "\n",
    "    return np.array(normal_loss_dist), np.array(cross_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f0a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_cls_result(classification_result):\n",
    "    \n",
    "    for i in classification_result.keys():\n",
    "        print(i, classification_result[i].keys())\n",
    "\n",
    "        if '1' not in classification_result[i].keys():\n",
    "            classification_result[i]['1'] = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0.0}\n",
    "    return classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3b0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_gap(losses):\n",
    "    y = sorted(losses, reverse=True)\n",
    "    diffs = abs(np.diff(y))\n",
    "    idx = np.argmax(diffs) + 1   # +1 because diffs[i] = y[i+1]-y[i]\n",
    "    return idx, y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16104a78-5d5f-493d-b279-c6ba4dca76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap_cutoff(rf, Xw, yw):\n",
    "    \"\"\"\n",
    "    Given a fitted RandomForest `rf` and its training data (Xw, yw),\n",
    "    compute cross‐entropy losses for each sample. If there are fewer than\n",
    "    2 samples, just return the single loss (or 0 if somehow empty). Otherwise\n",
    "    use find_largest_gap to get a gap‐based cutoff.\n",
    "    \"\"\"\n",
    "    ce_losses = cross_entropy_loss(rf, Xw, yw)\n",
    "    n = ce_losses.size\n",
    "\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    if n == 1:\n",
    "        # Only one loss → no “gap” to find. Use the single value as cutoff.\n",
    "        return float(ce_losses[0])\n",
    "\n",
    "    # Now we have ≥2 losses; sorting in descending order ensures diff is nonempty\n",
    "    _, cutoff_gap = find_largest_gap(ce_losses)\n",
    "    return cutoff_gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19809b29-a1af-49a2-bf28-8527883df1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_min_anomalies(gt_labels, num_samples=10, min_anomalies=3, random_state=None):\n",
    "    \"\"\"\n",
    "    Randomly sample `num_samples` indices from gt_labels (0/1 array),\n",
    "    ensuring at least `min_anomalies` true-anomaly (1) indices are included.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt_labels : array-like, shape (n_samples,)\n",
    "        Ground-truth labels (0 = normal, 1 = anomaly).\n",
    "    num_samples : int, default=10\n",
    "        Total number of indices to sample.\n",
    "    min_anomalies : int, default=3\n",
    "        Minimum number of anomaly indices to include.\n",
    "    random_state : int or None\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_indices : ndarray, shape (<= num_samples,)\n",
    "        Shuffled indices, containing at least `min_anomalies` anomalies\n",
    "        (or as many as available if fewer exist).\n",
    "    \"\"\"\n",
    "    gt_labels = np.asarray(gt_labels)\n",
    "    if random_state is not None:\n",
    "        np.random.seed(42)\n",
    "\n",
    "    # locate anomaly vs normal indices\n",
    "    anomaly_idx = np.where(gt_labels == 1)[0]\n",
    "    normal_idx  = np.where(gt_labels == 0)[0]\n",
    "\n",
    "    # determine how many anomalies we can pick\n",
    "    n_anom = min(len(anomaly_idx), min_anomalies)\n",
    "    # pick anomalies without replacement\n",
    "    picked_anom = np.random.choice(anomaly_idx, n_anom, replace=False) if n_anom > 0 else np.array([], dtype=int)\n",
    "\n",
    "    # fill the rest from normals\n",
    "    n_normal = num_samples - n_anom\n",
    "    n_normal = min(n_normal, len(normal_idx))\n",
    "    picked_norm = np.random.choice(normal_idx, n_normal, replace=False) if n_normal > 0 else np.array([], dtype=int)\n",
    "\n",
    "    # combine and shuffle\n",
    "    selected = np.concatenate([picked_anom, picked_norm])\n",
    "    np.random.shuffle(selected)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7da4421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049_noise.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Read and Process the Data\n",
    "# ----------------------------\n",
    "dataset = '0.049_noise.csv'\n",
    "df = pd.read_csv(\"../data/%s\" % (dataset))\n",
    "df = df.sort_values(by='Timestamp')\n",
    "# Process the 'noise' column:\n",
    "# - If NaN, assume Normal (0).\n",
    "# - Otherwise, treat True/1/'True' as anomaly (1); everything else as Normal (0).\n",
    "df['noise'] = df['noise'].fillna(0).apply(lambda x: 1 if (x == True or x == 1 or x == 'True' or x=='true') else 0)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "print(dataset)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Prefixes & global window settings\n",
    "# ----------------------------\n",
    "prefix_range = range(2, 35)   # prefix lengths 2..15\n",
    "WINDOW_EVENTS = 2500          # keep the last 2 500 raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c9f53495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Pre‐fit encoders for each prefix’s NAP ---\n",
    "all_acts = df[\"Activity\"].unique()\n",
    "ohe_nap  = {p: OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "              .fit(np.array([[a]*(p-1) for a in all_acts]))\n",
    "            for p in prefix_range}\n",
    "le_nap   = {p: LabelEncoder().fit(all_acts) for p in prefix_range}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c4fb32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4) Buffers & global state\n",
    "# ----------------------------\n",
    "# Create a single sliding window for the last WINDOW_EVENTS raw prefix-events\n",
    "global_events = deque(maxlen=WINDOW_EVENTS)\n",
    "\n",
    "# Per-prefix buffers (unbounded; we’ll evict manually when global_events drops)\n",
    "buffers = {}\n",
    "for p in prefix_range:\n",
    "    buffers[p] = {\n",
    "        \"raw_feats\":      deque(),   # stores list of activities for each prefix-event\n",
    "        \"raw_tgts\":       deque(),   # stores the target activity string\n",
    "        \"X\":               deque(),   # one-hot–encoded feature vectors\n",
    "        \"y\":               deque(),   # label‐encoded target indices\n",
    "        \"noise\":           deque(),   # true anomaly flag (0/1)\n",
    "        \"model\":          None,       # RandomForest NAP model\n",
    "        \"filled\":         False,      # has the NAP model been trained at least once?\n",
    "        \"cutoff\":         None,       # CE‐loss cutoff for anomaly flagging\n",
    "        \"update_counter\": 0           # no longer used per-prefix\n",
    "    }\n",
    "\n",
    "case_events      = defaultdict(list)\n",
    "detect_pool      = []   # accumulated AD training samples (dicts)\n",
    "anom_clf         = None\n",
    "enc_ad           = None\n",
    "max_prob_ad      = 0\n",
    "max_pfx          = max(prefix_range) - 1\n",
    "\n",
    "online_nap_reports = []\n",
    "online_ad_reports  = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a7b57278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/78504 rows (1.3%)\n",
      "Processed 2000/78504 rows (2.5%)\n",
      "Processed 3000/78504 rows (3.8%)\n",
      "Processed 4000/78504 rows (5.1%)\n",
      "Processed 5000/78504 rows (6.4%)\n",
      "Processed 6000/78504 rows (7.6%)\n",
      "Processed 7000/78504 rows (8.9%)\n",
      "Processed 8000/78504 rows (10.2%)\n",
      "Processed 9000/78504 rows (11.5%)\n",
      "Processed 10000/78504 rows (12.7%)\n",
      "Processed 11000/78504 rows (14.0%)\n",
      "Processed 12000/78504 rows (15.3%)\n",
      "Processed 13000/78504 rows (16.6%)\n",
      "Processed 14000/78504 rows (17.8%)\n",
      "Processed 15000/78504 rows (19.1%)\n",
      "Processed 16000/78504 rows (20.4%)\n",
      "Processed 17000/78504 rows (21.7%)\n",
      "Processed 18000/78504 rows (22.9%)\n",
      "Processed 19000/78504 rows (24.2%)\n",
      "Processed 20000/78504 rows (25.5%)\n",
      "Processed 21000/78504 rows (26.8%)\n",
      "Processed 22000/78504 rows (28.0%)\n",
      "Processed 23000/78504 rows (29.3%)\n",
      "Processed 24000/78504 rows (30.6%)\n",
      "Processed 25000/78504 rows (31.8%)\n",
      "Processed 26000/78504 rows (33.1%)\n",
      "Processed 27000/78504 rows (34.4%)\n",
      "Processed 28000/78504 rows (35.7%)\n",
      "Processed 29000/78504 rows (36.9%)\n",
      "Processed 30000/78504 rows (38.2%)\n",
      "Processed 31000/78504 rows (39.5%)\n",
      "Processed 32000/78504 rows (40.8%)\n",
      "Processed 33000/78504 rows (42.0%)\n",
      "Processed 34000/78504 rows (43.3%)\n",
      "Processed 35000/78504 rows (44.6%)\n",
      "Processed 36000/78504 rows (45.9%)\n",
      "Processed 37000/78504 rows (47.1%)\n",
      "Processed 38000/78504 rows (48.4%)\n",
      "Processed 39000/78504 rows (49.7%)\n",
      "Processed 40000/78504 rows (51.0%)\n",
      "Processed 41000/78504 rows (52.2%)\n",
      "Processed 42000/78504 rows (53.5%)\n",
      "Processed 43000/78504 rows (54.8%)\n",
      "Processed 44000/78504 rows (56.0%)\n",
      "Processed 45000/78504 rows (57.3%)\n",
      "Processed 46000/78504 rows (58.6%)\n",
      "Processed 47000/78504 rows (59.9%)\n",
      "Processed 48000/78504 rows (61.1%)\n",
      "Processed 49000/78504 rows (62.4%)\n",
      "Processed 50000/78504 rows (63.7%)\n",
      "Processed 51000/78504 rows (65.0%)\n",
      "Processed 52000/78504 rows (66.2%)\n",
      "Processed 53000/78504 rows (67.5%)\n",
      "Processed 54000/78504 rows (68.8%)\n",
      "Processed 55000/78504 rows (70.1%)\n",
      "Processed 56000/78504 rows (71.3%)\n",
      "Processed 57000/78504 rows (72.6%)\n",
      "Processed 58000/78504 rows (73.9%)\n",
      "Processed 59000/78504 rows (75.2%)\n",
      "Processed 60000/78504 rows (76.4%)\n",
      "Processed 61000/78504 rows (77.7%)\n",
      "Processed 62000/78504 rows (79.0%)\n",
      "Processed 63000/78504 rows (80.3%)\n",
      "Processed 64000/78504 rows (81.5%)\n",
      "Processed 65000/78504 rows (82.8%)\n",
      "Processed 66000/78504 rows (84.1%)\n",
      "Processed 67000/78504 rows (85.3%)\n",
      "Processed 68000/78504 rows (86.6%)\n",
      "Processed 69000/78504 rows (87.9%)\n",
      "Processed 70000/78504 rows (89.2%)\n",
      "Processed 71000/78504 rows (90.4%)\n",
      "Processed 72000/78504 rows (91.7%)\n",
      "Processed 73000/78504 rows (93.0%)\n",
      "Processed 74000/78504 rows (94.3%)\n",
      "Processed 75000/78504 rows (95.5%)\n",
      "Processed 76000/78504 rows (96.8%)\n",
      "Processed 77000/78504 rows (98.1%)\n",
      "Processed 78000/78504 rows (99.4%)\n",
      "Processed 78504/78504 rows (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Streaming loop with NAP + AD\n",
    "# ----------------------------\n",
    "total = len(df)\n",
    "# single sliding window of the last WINDOW_EVENTS raw events\n",
    "global_update_counter = 0\n",
    "global_retrain_batch = WINDOW_EVENTS // 2   # 1250\n",
    "known_nap_anomalies = set() \n",
    "for i, (_, row) in enumerate(df.iterrows(), start=1):\n",
    "    # progress logging\n",
    "    if i % 1000 == 0 or i == total:\n",
    "        pct = i / total * 100\n",
    "        print(f\"Processed {i}/{total} rows ({pct:.1f}%)\")\n",
    "    global_update_counter += 1\n",
    "    \n",
    "    cid = row[\"Case ID\"]\n",
    "    case_events[cid].append(row)\n",
    "    cur_len = len(case_events[cid])\n",
    "\n",
    "   # Only process when a case first reaches prefix length p\n",
    "    for p in prefix_range:\n",
    "        if cur_len != p:\n",
    "            continue\n",
    "\n",
    "        # 5.1) Build current sample\n",
    "        group      = case_events[cid]\n",
    "        feats      = [e.Activity for e in group[: p - 1]]\n",
    "        target_act = group[p - 1].Activity\n",
    "        noise_flag = group[p - 1].noise\n",
    "\n",
    "        buf = buffers[p]\n",
    "\n",
    "        # --- Slide the global window: peek dropped if full ---\n",
    "        dropped = None\n",
    "        if len(global_events) == WINDOW_EVENTS:\n",
    "            dropped = global_events[0]  # will be auto-evicted on append()\n",
    "\n",
    "        # Transform features/target for NAP\n",
    "        Xp_vec = ohe_nap[p].transform([feats]).ravel()\n",
    "        yp     = le_nap[p].transform([target_act])[0]\n",
    "\n",
    "        # Append to global_events: store (prefix, X_vec, y_label, noise, raw_feats, raw_target)\n",
    "        global_events.append((p, Xp_vec, yp, noise_flag, feats, target_act))\n",
    "\n",
    "        # Append to this prefix’s buffers (unbounded deques)\n",
    "        buf[\"raw_feats\"].append(feats)\n",
    "        buf[\"raw_tgts\"].append(target_act)\n",
    "        buf[\"X\"].append(Xp_vec)\n",
    "        buf[\"y\"].append(yp)\n",
    "        buf[\"noise\"].append(noise_flag)\n",
    "\n",
    "        # If something was dropped from global_events, evict it from its prefix buffer\n",
    "        if dropped is not None:\n",
    "            old_p, old_Xp, old_yp, old_noise, old_feats, old_tgt = dropped\n",
    "            old_buf = buffers[old_p]\n",
    "            if old_buf[\"X\"]:\n",
    "                old_buf[\"raw_feats\"].popleft()\n",
    "                old_buf[\"raw_tgts\"].popleft()\n",
    "                old_buf[\"X\"].popleft()\n",
    "                old_buf[\"y\"].popleft()\n",
    "                old_buf[\"noise\"].popleft()\n",
    "\n",
    "        # --- 5.2) Initial NAP training (once we have the first sample) ---\n",
    "        if buf[\"model\"] is None:\n",
    "            Xw = np.vstack(buf[\"X\"])\n",
    "            yw = np.array(buf[\"y\"])\n",
    "            \n",
    "            # 5.2a) Bootstrap the AD pool\n",
    "            MAX_ANOM = 25\n",
    "            TOTAL_SAMPLES = 50\n",
    "\n",
    "            anom_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 1]\n",
    "            norm_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 0]\n",
    "            \n",
    "            n_anom = min(MAX_ANOM, len(anom_idxs))\n",
    "            sel_anom = random.sample(anom_idxs, n_anom) if n_anom > 0 else []\n",
    "            needed_norm = TOTAL_SAMPLES - n_anom\n",
    "            sel_norm = (random.sample(norm_idxs, needed_norm)\n",
    "                        if len(norm_idxs) >= needed_norm\n",
    "                        else norm_idxs)\n",
    "            \n",
    "            sel_idxs = sel_anom + sel_norm\n",
    "            random.shuffle(sel_idxs)\n",
    "            sel_idxs = sample_with_min_anomalies(buf[\"noise\"], num_samples=TOTAL_SAMPLES, min_anomalies=MAX_ANOM, random_state=None)\n",
    "\n",
    "            for idx in sel_idxs:\n",
    "                if buf[\"noise\"][idx] == 1:\n",
    "                    raw_feat = tuple(buf[\"raw_feats\"][idx])\n",
    "                    raw_tgt = buf[\"raw_tgts\"][idx]\n",
    "                    known_nap_anomalies.add((p, raw_feat, raw_tgt))\n",
    "                    \n",
    "            normal_indices = [\n",
    "                i for i in range(len(buf[\"X\"]))\n",
    "                if (p, tuple(buf[\"raw_feats\"][0][i]), buf[\"raw_tgts\"][0][i]) not in known_nap_anomalies\n",
    "            ]\n",
    "\n",
    "            Xw = np.vstack([buf[\"X\"][i] for i in normal_indices])\n",
    "            yw = np.array([buf[\"y\"][i] for i in normal_indices])\n",
    "            \n",
    "            if len(normal_indices) == 0:\n",
    "                continue\n",
    "    \n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=100, random_state=42, n_jobs=-1\n",
    "            )\n",
    "            rf.fit(Xw, yw)\n",
    "            \n",
    "            feats_i = buf[\"raw_feats\"][idx]\n",
    "            Xp_i = ohe_nap[p].transform([feats_i]).ravel().reshape(1, -1)\n",
    "            \n",
    "            # Compute CE‐loss cutoff (gap‐based) on current buffer\n",
    "            cutoff = compute_gap_cutoff(rf, Xw, yw)\n",
    "\n",
    "            buf[\"model\"]  = rf\n",
    "            buf[\"filled\"] = True\n",
    "            buf[\"cutoff\"] = cutoff\n",
    "\n",
    "            for idx in sel_idxs:\n",
    "                prob_vec = rf.predict_proba(buf[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                ce0      = cross_entropy_loss(rf, buf[\"X\"][idx].reshape(1, -1), [buf[\"y\"][idx]])[0]\n",
    "                detect_pool.append({\n",
    "                    \"raw_feats\": buf[\"raw_feats\"][idx],\n",
    "                    \"target\":    buf[\"raw_tgts\"][idx],\n",
    "                    \"prefix\":    p,\n",
    "                    \"prob\":      prob_vec,\n",
    "                    \"ce_loss\":   ce0,\n",
    "                    \"anomaly\":   buf[\"noise\"][idx]\n",
    "                })\n",
    "                    \n",
    "            # print(f\"Prefix {p} NAP initial train (buffer size = {len(buf['X'])})\")\n",
    "\n",
    "\n",
    "            # 5.2b) Train the AD classifier if we have ≥20 samples\n",
    "            cat_rows = []\n",
    "            for d in detect_pool:\n",
    "                row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                cat_rows.append(row_cat)\n",
    "            enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "            X_cat = enc_ad.transform(cat_rows)\n",
    "\n",
    "            max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "            prob_mat = [\n",
    "                d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                for d in detect_pool\n",
    "            ]\n",
    "            ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "            X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "            y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "            X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "            # anom_clf = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "            # anom_clf.fit(X_ad, y_ad)\n",
    "            # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "            #     random_state=42).fit(X_ad, y_ad)\n",
    "            anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.1, eval_metric='logloss',\n",
    "                                     random_state=42).fit(X_ad, y_ad)\n",
    "\n",
    "            # print(f\"Prefix {p} AD initial train on {len(detect_pool)} samples\")\n",
    "\n",
    "            AD_CAT_FEATS = X_cat.shape[1]\n",
    "            AD_NUM_FEATS = X_num.shape[1]\n",
    "            # Skip further processing of this new event\n",
    "    \n",
    "\n",
    "        # --- 5.3) Prequential NAP prediction & store ---\n",
    "        rf   = buf[\"model\"]\n",
    "        Xp   = Xp_vec.reshape(1, -1)\n",
    "        y_sp = yp\n",
    "        cutoff_nap = buf[\"cutoff\"]\n",
    "\n",
    "        ce_cur = cross_entropy_loss(rf, Xp, [y_sp])[0]\n",
    "        pred_nap_anom = int(ce_cur > cutoff_nap)\n",
    "\n",
    "        online_nap_reports.append({\n",
    "            \"i\":             i,\n",
    "            \"prefix\":        p,\n",
    "            \"case_id\":       cid,\n",
    "            \"true_noise\":    noise_flag,\n",
    "            \"pred_nap_anom\": pred_nap_anom,\n",
    "            \"cutoff\":        cutoff_nap\n",
    "        })\n",
    "\n",
    "        # --- 5.4) Global retrain trigger (increment once per prefix-event) ---\n",
    "        if global_update_counter >= global_retrain_batch:\n",
    "            # print(\"=== Global retrain of all prefix NAP models ===\")\n",
    "\n",
    "            # Retrain each NAP model on its current buffer, recompute cutoff, \n",
    "            # and sample AD points\n",
    "            for q in prefix_range:\n",
    "                buf_q = buffers[q]\n",
    "                if len(buf_q[\"X\"]) == 0:\n",
    "                    continue\n",
    "                                        \n",
    "                Xw = np.vstack(buf_q[\"X\"])\n",
    "                yw = np.array(buf_q[\"y\"])\n",
    "                \n",
    "                anom_idxs = [idx for idx, flag in enumerate(buf_q[\"noise\"]) if flag == 1]\n",
    "                norm_idxs = [idx for idx, flag in enumerate(buf_q[\"noise\"]) if flag == 0]\n",
    "            \n",
    "                n_anom = min(MAX_ANOM, len(anom_idxs))\n",
    "                sel_anom = random.sample(anom_idxs, n_anom) if n_anom > 0 else []\n",
    "                needed_norm = TOTAL_SAMPLES - n_anom\n",
    "                sel_norm = (random.sample(norm_idxs, needed_norm)\n",
    "                            if len(norm_idxs) >= needed_norm\n",
    "                            else norm_idxs)\n",
    "                \n",
    "                sel_idxs = sel_anom + sel_norm\n",
    "                random.shuffle(sel_idxs)\n",
    "                sel_idxs = sample_with_min_anomalies(buf_q[\"noise\"], num_samples=TOTAL_SAMPLES, min_anomalies=MAX_ANOM, random_state=None)\n",
    "\n",
    "                for idx in sel_idxs:\n",
    "                    if buf_q[\"noise\"][idx] == 1:\n",
    "                        raw_feat = tuple(buf_q[\"raw_feats\"][idx])\n",
    "                        raw_tgt = buf_q[\"raw_tgts\"][idx]\n",
    "                        known_nap_anomalies.add((q, raw_feat, raw_tgt))\n",
    "                normal_indices = [\n",
    "                    i for i in range(len(buf_q[\"X\"]))\n",
    "                    if (p, tuple(buf_q[\"raw_feats\"][i]), buf_q[\"raw_tgts\"][i]) not in known_nap_anomalies\n",
    "                ]\n",
    "\n",
    "                if len(normal_indices) !=0:\n",
    "                    Xw = np.vstack([buf_q[\"X\"][i] for i in normal_indices])\n",
    "                    yw = np.array([buf_q[\"y\"][i] for i in normal_indices])     \n",
    "                    \n",
    "                    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                    rf.fit(Xw, yw)\n",
    "                buf_q[\"model\"] = rf\n",
    "\n",
    "                # Recompute CE‐loss cutoff (gap-based)\n",
    "                # cutoff_q = compute_gap_cutoff(rf, Xw, yw)\n",
    "                # buf_q[\"cutoff\"] = cutoff_q\n",
    "                # print(f\"  Recomputed cutoff for prefix {q} (buffer size = {len(buf_q['X'])})\")\n",
    "            \n",
    "                for idx in sel_idxs:\n",
    "                    prob_vec = rf.predict_proba(buf_q[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                    ce0      = cross_entropy_loss(rf, buf_q[\"X\"][idx].reshape(1, -1), [buf_q[\"y\"][idx]])[0]\n",
    "                    detect_pool.append({\n",
    "                        \"raw_feats\": buf_q[\"raw_feats\"][idx],\n",
    "                        \"target\":    buf_q[\"raw_tgts\"][idx],\n",
    "                        \"prefix\":    q,\n",
    "                        \"prob\":      prob_vec,\n",
    "                        \"ce_loss\":   ce0,\n",
    "                        \"anomaly\":   buf_q[\"noise\"][idx]\n",
    "                    })\n",
    "                    \n",
    "            # Retrain AD classifier if we have ≥20 samples\n",
    "            if len(detect_pool) >= 20:\n",
    "                cat_rows = []\n",
    "                for d in detect_pool:\n",
    "                    row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                    row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                    cat_rows.append(row_cat)\n",
    "                enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "                X_cat = enc_ad.transform(cat_rows)\n",
    "                max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "                prob_mat = [\n",
    "                    d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                    for d in detect_pool\n",
    "                ]\n",
    "                ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "                X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "                y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "                X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "                # anom_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                # anom_clf.fit(X_ad, y_ad)\n",
    "                AD_CAT_FEATS = X_cat.shape[1]\n",
    "                AD_NUM_FEATS = X_num.shape[1]\n",
    "                                \n",
    "                # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "                #     random_state=42).fit(X_ad, y_ad)\n",
    "                anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.1, eval_metric='logloss',\n",
    "                                         random_state=42).fit(X_ad, y_ad)\n",
    "                # print(f\"  AD retrain on {len(detect_pool)} samples\")\n",
    "                # detect_pool = []\n",
    "            global_update_counter = 0\n",
    "\n",
    "        # --- 5.5) Prequential AD classification for current event ---\n",
    "        if anom_clf is not None:\n",
    "            # Build AD feature vector: categorical + numeric\n",
    "            row_cat = feats + [None] * (max_pfx - len(feats)) + [p, y_sp]\n",
    "            # 1) Categorical part\n",
    "            Xc = enc_ad.transform([row_cat])\n",
    "            if Xc.shape[1] != AD_CAT_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_CAT_FEATS} cat features, got {Xc.shape[1]}\")\n",
    "            \n",
    "            # 2) Numeric part (prob_vector + ce_loss)\n",
    "            model = buffers[p]['model']\n",
    "            pvec = model.predict_proba(Xp)[0].tolist()\n",
    "            pad_len = AD_NUM_FEATS - 1\n",
    "            pvec_padded = pvec + [0.0] * (pad_len - len(pvec))\n",
    "            Xn = np.array([pvec_padded + [ce_cur]])\n",
    "            if Xn.shape[1] != AD_NUM_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_NUM_FEATS} num features, got {Xn.shape[1]}\")\n",
    "            \n",
    "            # 3) Combine & predict\n",
    "            Xa = np.hstack([Xc, Xn])\n",
    "            pred_ad = anom_clf.predict(Xa)[0]\n",
    "            prob_ad = anom_clf.predict_proba(Xa)[0, 1]\n",
    "            \n",
    "            online_ad_reports.append({\n",
    "                \"i\":            i,\n",
    "                \"prefix\":       p,\n",
    "                \"case_id\":      cid,\n",
    "                \"true_noise\":   noise_flag,\n",
    "                \"pred_ad_anom\": int(pred_ad),\n",
    "                \"prob_ad\":        float(prob_ad),\n",
    "                \"nap_prob\": pvec,\n",
    "                \"nap_class\": model.classes_,\n",
    "                \"predict_act\":model.predict(Xp),\n",
    "                \"actual_act\":y_sp\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7fb3dc75-691f-477d-af8a-fbe6acb7d26a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prefix 2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4707\n",
      "           1       1.00      0.96      0.98       292\n",
      "\n",
      "    accuracy                           1.00      4999\n",
      "   macro avg       1.00      0.98      0.99      4999\n",
      "weighted avg       1.00      1.00      1.00      4999\n",
      "\n",
      "\n",
      "--- Prefix 3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      4736\n",
      "           1       0.77      0.97      0.86       264\n",
      "\n",
      "    accuracy                           0.98      5000\n",
      "   macro avg       0.89      0.98      0.93      5000\n",
      "weighted avg       0.99      0.98      0.98      5000\n",
      "\n",
      "\n",
      "--- Prefix 4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      4748\n",
      "           1       0.46      0.92      0.62       252\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.73      0.93      0.79      5000\n",
      "weighted avg       0.97      0.94      0.95      5000\n",
      "\n",
      "\n",
      "--- Prefix 5 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      4784\n",
      "           1       0.38      0.87      0.53       216\n",
      "\n",
      "    accuracy                           0.93      5000\n",
      "   macro avg       0.68      0.90      0.74      5000\n",
      "weighted avg       0.97      0.93      0.94      5000\n",
      "\n",
      "\n",
      "--- Prefix 6 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      4765\n",
      "           1       0.58      0.96      0.72       235\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.79      0.96      0.85      5000\n",
      "weighted avg       0.98      0.96      0.97      5000\n",
      "\n",
      "\n",
      "--- Prefix 7 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      4755\n",
      "           1       0.54      0.96      0.69       245\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.77      0.96      0.83      5000\n",
      "weighted avg       0.98      0.96      0.96      5000\n",
      "\n",
      "\n",
      "--- Prefix 8 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      4741\n",
      "           1       0.46      0.95      0.62       259\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.73      0.95      0.79      5000\n",
      "weighted avg       0.97      0.94      0.95      5000\n",
      "\n",
      "\n",
      "--- Prefix 9 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      4727\n",
      "           1       0.36      0.97      0.53       273\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.68      0.94      0.74      5000\n",
      "weighted avg       0.96      0.91      0.92      5000\n",
      "\n",
      "\n",
      "--- Prefix 10 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      4786\n",
      "           1       0.29      0.96      0.44       214\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.64      0.93      0.69      5000\n",
      "weighted avg       0.97      0.90      0.92      5000\n",
      "\n",
      "\n",
      "--- Prefix 11 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      4030\n",
      "           1       0.28      0.95      0.43       187\n",
      "\n",
      "    accuracy                           0.89      4217\n",
      "   macro avg       0.64      0.92      0.68      4217\n",
      "weighted avg       0.97      0.89      0.92      4217\n",
      "\n",
      "\n",
      "--- Prefix 12 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91      3677\n",
      "           1       0.23      0.94      0.37       188\n",
      "\n",
      "    accuracy                           0.85      3865\n",
      "   macro avg       0.61      0.89      0.64      3865\n",
      "weighted avg       0.96      0.85      0.89      3865\n",
      "\n",
      "\n",
      "--- Prefix 13 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91      3601\n",
      "           1       0.22      0.95      0.36       184\n",
      "\n",
      "    accuracy                           0.83      3785\n",
      "   macro avg       0.61      0.89      0.63      3785\n",
      "weighted avg       0.96      0.83      0.88      3785\n",
      "\n",
      "\n",
      "--- Prefix 14 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90      3266\n",
      "           1       0.21      0.93      0.35       169\n",
      "\n",
      "    accuracy                           0.83      3435\n",
      "   macro avg       0.61      0.88      0.62      3435\n",
      "weighted avg       0.96      0.83      0.87      3435\n",
      "\n",
      "\n",
      "--- Prefix 15 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85      2442\n",
      "           1       0.16      0.96      0.27       123\n",
      "\n",
      "    accuracy                           0.75      2565\n",
      "   macro avg       0.58      0.85      0.56      2565\n",
      "weighted avg       0.96      0.75      0.82      2565\n",
      "\n",
      "\n",
      "--- Prefix 16 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85      1936\n",
      "           1       0.16      0.94      0.28       104\n",
      "\n",
      "    accuracy                           0.75      2040\n",
      "   macro avg       0.58      0.84      0.56      2040\n",
      "weighted avg       0.95      0.75      0.82      2040\n",
      "\n",
      "\n",
      "--- Prefix 17 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84      1677\n",
      "           1       0.11      0.94      0.20        64\n",
      "\n",
      "    accuracy                           0.73      1741\n",
      "   macro avg       0.55      0.83      0.52      1741\n",
      "weighted avg       0.96      0.73      0.81      1741\n",
      "\n",
      "\n",
      "--- Prefix 18 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78      1271\n",
      "           1       0.09      0.90      0.16        50\n",
      "\n",
      "    accuracy                           0.65      1321\n",
      "   macro avg       0.54      0.77      0.47      1321\n",
      "weighted avg       0.96      0.65      0.75      1321\n",
      "\n",
      "\n",
      "--- Prefix 19 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.59      0.74       987\n",
      "           1       0.11      0.88      0.19        56\n",
      "\n",
      "    accuracy                           0.60      1043\n",
      "   macro avg       0.55      0.73      0.47      1043\n",
      "weighted avg       0.94      0.60      0.71      1043\n",
      "\n",
      "\n",
      "--- Prefix 20 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.55      0.71       842\n",
      "           1       0.10      0.91      0.18        46\n",
      "\n",
      "    accuracy                           0.57       888\n",
      "   macro avg       0.55      0.73      0.45       888\n",
      "weighted avg       0.95      0.57      0.68       888\n",
      "\n",
      "\n",
      "--- Prefix 21 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.51      0.67       667\n",
      "           1       0.08      0.93      0.14        30\n",
      "\n",
      "    accuracy                           0.53       697\n",
      "   macro avg       0.54      0.72      0.41       697\n",
      "weighted avg       0.95      0.53      0.65       697\n",
      "\n",
      "\n",
      "--- Prefix 22 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.41      0.58       531\n",
      "           1       0.07      0.92      0.12        24\n",
      "\n",
      "    accuracy                           0.43       555\n",
      "   macro avg       0.53      0.66      0.35       555\n",
      "weighted avg       0.95      0.43      0.56       555\n",
      "\n",
      "\n",
      "--- Prefix 23 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.41      0.58       449\n",
      "           1       0.05      0.76      0.09        17\n",
      "\n",
      "    accuracy                           0.42       466\n",
      "   macro avg       0.51      0.59      0.33       466\n",
      "weighted avg       0.94      0.42      0.56       466\n",
      "\n",
      "\n",
      "--- Prefix 24 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.37      0.54       348\n",
      "           1       0.05      0.80      0.10        15\n",
      "\n",
      "    accuracy                           0.39       363\n",
      "   macro avg       0.51      0.59      0.32       363\n",
      "weighted avg       0.94      0.39      0.52       363\n",
      "\n",
      "\n",
      "--- Prefix 25 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.31      0.47       261\n",
      "           1       0.07      0.67      0.13        21\n",
      "\n",
      "    accuracy                           0.34       282\n",
      "   macro avg       0.50      0.49      0.30       282\n",
      "weighted avg       0.86      0.34      0.44       282\n",
      "\n",
      "\n",
      "--- Prefix 26 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.28      0.43       222\n",
      "           1       0.05      0.82      0.10        11\n",
      "\n",
      "    accuracy                           0.30       233\n",
      "   macro avg       0.51      0.55      0.27       233\n",
      "weighted avg       0.93      0.30      0.42       233\n",
      "\n",
      "\n",
      "--- Prefix 27 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.47       181\n",
      "           1       0.05      1.00      0.09         6\n",
      "\n",
      "    accuracy                           0.33       187\n",
      "   macro avg       0.52      0.65      0.28       187\n",
      "weighted avg       0.97      0.33      0.45       187\n",
      "\n",
      "\n",
      "--- Prefix 28 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.21      0.35       137\n",
      "           1       0.07      0.89      0.13         9\n",
      "\n",
      "    accuracy                           0.25       146\n",
      "   macro avg       0.52      0.55      0.24       146\n",
      "weighted avg       0.91      0.25      0.33       146\n",
      "\n",
      "\n",
      "--- Prefix 29 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.46       120\n",
      "           1       0.05      1.00      0.09         4\n",
      "\n",
      "    accuracy                           0.32       124\n",
      "   macro avg       0.52      0.65      0.27       124\n",
      "weighted avg       0.97      0.32      0.45       124\n",
      "\n",
      "\n",
      "--- Prefix 30 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.38        94\n",
      "           1       0.03      1.00      0.05         2\n",
      "\n",
      "    accuracy                           0.25        96\n",
      "   macro avg       0.51      0.62      0.22        96\n",
      "weighted avg       0.98      0.25      0.37        96\n",
      "\n",
      "\n",
      "--- Prefix 31 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        76\n",
      "           1       0.03      1.00      0.06         2\n",
      "\n",
      "    accuracy                           0.21        78\n",
      "   macro avg       0.52      0.59      0.19        78\n",
      "weighted avg       0.98      0.21      0.30        78\n",
      "\n",
      "\n",
      "--- Prefix 32 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.18      0.31        65\n",
      "           1       0.04      0.67      0.07         3\n",
      "\n",
      "    accuracy                           0.21        68\n",
      "   macro avg       0.48      0.43      0.19        68\n",
      "weighted avg       0.88      0.21      0.30        68\n",
      "\n",
      "\n",
      "--- Prefix 33 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.19      0.32        52\n",
      "           1       0.02      0.50      0.04         2\n",
      "\n",
      "    accuracy                           0.20        54\n",
      "   macro avg       0.47      0.35      0.18        54\n",
      "weighted avg       0.88      0.20      0.31        54\n",
      "\n",
      "\n",
      "--- Prefix 34 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.27        45\n",
      "           1       0.05      1.00      0.10         2\n",
      "\n",
      "    accuracy                           0.19        47\n",
      "   macro avg       0.53      0.58      0.18        47\n",
      "weighted avg       0.96      0.19      0.26        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) Summarize\n",
    "reports_df = pd.DataFrame(online_ad_reports)\n",
    "for p in prefix_range:\n",
    "    sub = reports_df[reports_df[\"prefix\"] == p]\n",
    "    if not sub.empty:\n",
    "        print(f\"\\n--- Prefix {p} ---\")\n",
    "        print(classification_report(\n",
    "            sub[\"true_noise\"], sub[\"pred_ad_anom\"], zero_division=0\n",
    "        ))\n",
    "reports_df \n",
    "reports_df.to_csv('../result/%s_classifier_xgb_%s_random_sample_napv2.csv'%(dataset, TOTAL_SAMPLES), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46396998-f1e2-42ba-bf6f-239b012b66b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
