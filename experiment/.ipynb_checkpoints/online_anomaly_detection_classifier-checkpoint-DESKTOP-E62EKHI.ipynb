{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9a4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from collections import Counter, defaultdict, deque\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, log_loss, roc_auc_score\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29506b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# suppress only the “y_pred values do not sum to one” warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*y_pred values do not sum to one.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc7a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = -∑_c [1{c = y_true_i} · log P_model(c | x_i)]\n",
    "    If the true label isn’t in model.classes_, returns a default high loss.\n",
    "    Works for any len(x_test) >= 1, including the single-class case.\n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(x_test)\n",
    "    default = log_loss([[1, 0]], [[0, 1]]) + 1  # fallback loss\n",
    "\n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        classes = model.classes_\n",
    "\n",
    "        # if only one class in the model\n",
    "        if sample_probs.size == 1:\n",
    "            if classes[0] == true_label:\n",
    "                losses.append(0.0)  # perfect prediction\n",
    "            else:\n",
    "                losses.append(default)\n",
    "            continue\n",
    "\n",
    "        # find index of the true label\n",
    "        idx_arr = np.where(classes == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(default)\n",
    "        else:\n",
    "            y_true_onehot = np.zeros_like(sample_probs)\n",
    "            y_true_onehot[idx_arr[0]] = 1\n",
    "\n",
    "            # normalize just in case\n",
    "            sample_probs = sample_probs / sample_probs.sum()\n",
    "            y_true_onehot = y_true_onehot / y_true_onehot.sum()\n",
    "\n",
    "            loss_i = log_loss([y_true_onehot], [sample_probs])\n",
    "            losses.append(loss_i)\n",
    "\n",
    "    return np.array(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4baf8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = 1 - P_model(y_true_i | x_i)\n",
    "    If the true label isn’t in model.classes_, we return 1.1 as before.\n",
    "    Works for any len(x_test) >= 1.\n",
    "    \"\"\"\n",
    "    # predict_proba returns shape (n_samples, n_classes)\n",
    "    probs = model.predict_proba(x_test)\n",
    "    \n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        # find index of the true label in model.classes_\n",
    "        idx_arr = np.where(model.classes_ == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(1.1)\n",
    "        else:\n",
    "            col_index = idx_arr[0]\n",
    "            losses.append(1 - sample_probs[col_index])\n",
    "    \n",
    "    return np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ae2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_transform_target(encoder, targets, unknown_value=-1):\n",
    "    classes = set(encoder.classes_)\n",
    "    transformed = []\n",
    "    for t in targets:\n",
    "        if t in classes:\n",
    "            transformed.append(encoder.transform([t])[0])\n",
    "        else:\n",
    "            transformed.append(unknown_value)\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e5afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_loss(normal_loss_value, cross_entropy_loss_value):\n",
    "    normal_loss_dist = []\n",
    "    cross_loss_dist = []\n",
    "    for pos, prediction in  enumerate(normal_loss_value):\n",
    "        if prediction != 1:\n",
    "            cross_loss_dist.append(cross_entropy_loss_value[pos])\n",
    "            normal_loss_dist.append(prediction)\n",
    "\n",
    "    return np.array(normal_loss_dist), np.array(cross_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f0a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_cls_result(classification_result):\n",
    "    \n",
    "    for i in classification_result.keys():\n",
    "        print(i, classification_result[i].keys())\n",
    "\n",
    "        if '1' not in classification_result[i].keys():\n",
    "            classification_result[i]['1'] = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0.0}\n",
    "    return classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3b0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_gap(losses):\n",
    "    y = sorted(losses, reverse=True)\n",
    "    diffs = abs(np.diff(y))\n",
    "    idx = np.argmax(diffs) + 1   # +1 because diffs[i] = y[i+1]-y[i]\n",
    "    return idx, y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16104a78-5d5f-493d-b279-c6ba4dca76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap_cutoff(rf, Xw, yw):\n",
    "    \"\"\"\n",
    "    Given a fitted RandomForest `rf` and its training data (Xw, yw),\n",
    "    compute cross‐entropy losses for each sample. If there are fewer than\n",
    "    2 samples, just return the single loss (or 0 if somehow empty). Otherwise\n",
    "    use find_largest_gap to get a gap‐based cutoff.\n",
    "    \"\"\"\n",
    "    ce_losses = cross_entropy_loss(rf, Xw, yw)\n",
    "    n = ce_losses.size\n",
    "\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    if n == 1:\n",
    "        # Only one loss → no “gap” to find. Use the single value as cutoff.\n",
    "        return float(ce_losses[0])\n",
    "\n",
    "    # Now we have ≥2 losses; sorting in descending order ensures diff is nonempty\n",
    "    _, cutoff_gap = find_largest_gap(ce_losses)\n",
    "    return cutoff_gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7da4421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Read and Process the Data\n",
    "# ----------------------------\n",
    "dataset = '0.099_sample.csv'\n",
    "df = pd.read_csv(\"../data/%s\" % (dataset))\n",
    "df = df.sort_values(by='Timestamp')\n",
    "# Process the 'noise' column:\n",
    "# - If NaN, assume Normal (0).\n",
    "# - Otherwise, treat True/1/'True' as anomaly (1); everything else as Normal (0).\n",
    "df['noise'] = df['noise'].fillna(0).apply(lambda x: 1 if (x == True or x == 1 or x == 'True' or x=='true') else 0)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "print(dataset)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Prefixes & global window settings\n",
    "# ----------------------------\n",
    "prefix_range = range(2, 35)   # prefix lengths 2..15\n",
    "WINDOW_EVENTS = 2500          # keep the last 2 500 raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f53495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Pre‐fit encoders for each prefix’s NAP ---\n",
    "all_acts = df[\"Activity\"].unique()\n",
    "ohe_nap  = {p: OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "              .fit(np.array([[a]*(p-1) for a in all_acts]))\n",
    "            for p in prefix_range}\n",
    "le_nap   = {p: LabelEncoder().fit(all_acts) for p in prefix_range}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4fb32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4) Buffers & global state\n",
    "# ----------------------------\n",
    "# Create a single sliding window for the last WINDOW_EVENTS raw prefix-events\n",
    "global_events = deque(maxlen=WINDOW_EVENTS)\n",
    "\n",
    "# Per-prefix buffers (unbounded; we’ll evict manually when global_events drops)\n",
    "buffers = {}\n",
    "for p in prefix_range:\n",
    "    buffers[p] = {\n",
    "        \"raw_feats\":      deque(),   # stores list of activities for each prefix-event\n",
    "        \"raw_tgts\":       deque(),   # stores the target activity string\n",
    "        \"X\":               deque(),   # one-hot–encoded feature vectors\n",
    "        \"y\":               deque(),   # label‐encoded target indices\n",
    "        \"noise\":           deque(),   # true anomaly flag (0/1)\n",
    "        \"model\":          None,       # RandomForest NAP model\n",
    "        \"filled\":         False,      # has the NAP model been trained at least once?\n",
    "        \"cutoff\":         None,       # CE‐loss cutoff for anomaly flagging\n",
    "        \"update_counter\": 0           # no longer used per-prefix\n",
    "    }\n",
    "\n",
    "case_events      = defaultdict(list)\n",
    "detect_pool      = []   # accumulated AD training samples (dicts)\n",
    "anom_clf         = None\n",
    "enc_ad           = None\n",
    "max_prob_ad      = 0\n",
    "max_pfx          = max(prefix_range) - 1\n",
    "\n",
    "online_nap_reports = []\n",
    "online_ad_reports  = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7b57278",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2664/3207363650.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mpvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m             \u001b[0midx_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_sp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mpad_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAD_NUM_FEATS\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_model' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Streaming loop with NAP + AD\n",
    "# ----------------------------\n",
    "total = len(df)\n",
    "# single sliding window of the last WINDOW_EVENTS raw events\n",
    "global_update_counter = 0\n",
    "global_retrain_batch = WINDOW_EVENTS // 2   # 1250\n",
    "\n",
    "for i, (_, row) in enumerate(df.iterrows(), start=1):\n",
    "    # progress logging\n",
    "    if i % 1000 == 0 or i == total:\n",
    "        pct = i / total * 100\n",
    "        print(f\"Processed {i}/{total} rows ({pct:.1f}%)\")\n",
    "    global_update_counter += 1\n",
    "    \n",
    "    cid = row[\"ID\"]\n",
    "    case_events[cid].append(row)\n",
    "    cur_len = len(case_events[cid])\n",
    "\n",
    "   # Only process when a case first reaches prefix length p\n",
    "    for p in prefix_range:\n",
    "        if cur_len != p:\n",
    "            continue\n",
    "\n",
    "        # 5.1) Build current sample\n",
    "        group      = case_events[cid]\n",
    "        feats      = [e.Activity for e in group[: p - 1]]\n",
    "        target_act = group[p - 1].Activity\n",
    "        noise_flag = group[p - 1].noise\n",
    "\n",
    "        buf = buffers[p]\n",
    "\n",
    "        # --- Slide the global window: peek dropped if full ---\n",
    "        dropped = None\n",
    "        if len(global_events) == WINDOW_EVENTS:\n",
    "            dropped = global_events[0]  # will be auto-evicted on append()\n",
    "\n",
    "        # Transform features/target for NAP\n",
    "        Xp_vec = ohe_nap[p].transform([feats]).ravel()\n",
    "        yp     = le_nap[p].transform([target_act])[0]\n",
    "\n",
    "        # Append to global_events: store (prefix, X_vec, y_label, noise, raw_feats, raw_target)\n",
    "        global_events.append((p, Xp_vec, yp, noise_flag, feats, target_act))\n",
    "\n",
    "        # Append to this prefix’s buffers (unbounded deques)\n",
    "        buf[\"raw_feats\"].append(feats)\n",
    "        buf[\"raw_tgts\"].append(target_act)\n",
    "        buf[\"X\"].append(Xp_vec)\n",
    "        buf[\"y\"].append(yp)\n",
    "        buf[\"noise\"].append(noise_flag)\n",
    "\n",
    "        # If something was dropped from global_events, evict it from its prefix buffer\n",
    "        if dropped is not None:\n",
    "            old_p, old_Xp, old_yp, old_noise, old_feats, old_tgt = dropped\n",
    "            old_buf = buffers[old_p]\n",
    "            if old_buf[\"X\"]:\n",
    "                old_buf[\"raw_feats\"].popleft()\n",
    "                old_buf[\"raw_tgts\"].popleft()\n",
    "                old_buf[\"X\"].popleft()\n",
    "                old_buf[\"y\"].popleft()\n",
    "                old_buf[\"noise\"].popleft()\n",
    "\n",
    "        # --- 5.2) Initial NAP training (once we have the first sample) ---\n",
    "        if buf[\"model\"] is None:\n",
    "            Xw = np.vstack(buf[\"X\"])\n",
    "            yw = np.array(buf[\"y\"])\n",
    "\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=100, random_state=42, n_jobs=-1\n",
    "            )\n",
    "            rf.fit(Xw, yw)\n",
    "\n",
    "            # Compute CE‐loss cutoff (gap‐based) on current buffer\n",
    "            cutoff = compute_gap_cutoff(rf, Xw, yw)\n",
    "\n",
    "            buf[\"model\"]  = rf\n",
    "            buf[\"filled\"] = True\n",
    "            buf[\"cutoff\"] = cutoff\n",
    "\n",
    "            # print(f\"Prefix {p} NAP initial train (buffer size = {len(buf['X'])})\")\n",
    "\n",
    "            # 5.2a) Bootstrap the AD pool\n",
    "            MAX_ANOM = 100\n",
    "            TOTAL_SAMPLES = 200\n",
    "            \n",
    "            anom_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 1]\n",
    "            norm_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 0]\n",
    "            \n",
    "            n_anom = min(MAX_ANOM, len(anom_idxs))\n",
    "            sel_anom = random.sample(anom_idxs, n_anom) if n_anom > 0 else []\n",
    "            needed_norm = TOTAL_SAMPLES - n_anom\n",
    "            sel_norm = (random.sample(norm_idxs, needed_norm)\n",
    "                        if len(norm_idxs) >= needed_norm\n",
    "                        else norm_idxs)\n",
    "            \n",
    "            sel_idxs = sel_anom + sel_norm\n",
    "            random.shuffle(sel_idxs)\n",
    "\n",
    "            for idx in sel_idxs:\n",
    "                prob_vec = rf.predict_proba(buf[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                ce0      = cross_entropy_loss(rf, buf[\"X\"][idx].reshape(1, -1), [buf[\"y\"][idx]])[0]\n",
    "                detect_pool.append({\n",
    "                    \"raw_feats\": buf[\"raw_feats\"][idx],\n",
    "                    \"target\":    buf[\"raw_tgts\"][idx],\n",
    "                    \"prefix\":    p,\n",
    "                    \"prob\":      prob_vec,\n",
    "                    \"ce_loss\":   ce0,\n",
    "                    \"anomaly\":   buf[\"noise\"][idx]\n",
    "                })\n",
    "\n",
    "            # 5.2b) Train the AD classifier if we have ≥20 samples\n",
    "            cat_rows = []\n",
    "            for d in detect_pool:\n",
    "                row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                cat_rows.append(row_cat)\n",
    "            enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "            X_cat = enc_ad.transform(cat_rows)\n",
    "\n",
    "            max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "            prob_mat = [\n",
    "                d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                for d in detect_pool\n",
    "            ]\n",
    "            ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "            X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "            y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "            X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "            # anom_clf = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "            # anom_clf.fit(X_ad, y_ad)\n",
    "            # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "            #     random_state=42).fit(X_ad, y_ad)\n",
    "            anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.1, eval_metric='logloss',\n",
    "                                     random_state=42).fit(X_ad, y_ad)\n",
    "\n",
    "            # print(f\"Prefix {p} AD initial train on {len(detect_pool)} samples\")\n",
    "\n",
    "            AD_CAT_FEATS = X_cat.shape[1]\n",
    "            AD_NUM_FEATS = X_num.shape[1]\n",
    "            # Skip further processing of this new event\n",
    "    \n",
    "\n",
    "        # --- 5.3) Prequential NAP prediction & store ---\n",
    "        rf   = buf[\"model\"]\n",
    "        Xp   = Xp_vec.reshape(1, -1)\n",
    "        y_sp = yp\n",
    "        cutoff_nap = buf[\"cutoff\"]\n",
    "\n",
    "        ce_cur = cross_entropy_loss(rf, Xp, [y_sp])[0]\n",
    "        pred_nap_anom = int(ce_cur > cutoff_nap)\n",
    "\n",
    "        online_nap_reports.append({\n",
    "            \"i\":             i,\n",
    "            \"prefix\":        p,\n",
    "            \"case_id\":       cid,\n",
    "            \"true_noise\":    noise_flag,\n",
    "            \"pred_nap_anom\": pred_nap_anom,\n",
    "            \"cutoff\":        cutoff_nap\n",
    "        })\n",
    "\n",
    "        # --- 5.4) Global retrain trigger (increment once per prefix-event) ---\n",
    "        if global_update_counter >= global_retrain_batch:\n",
    "            # print(\"=== Global retrain of all prefix NAP models ===\")\n",
    "\n",
    "            # Retrain each NAP model on its current buffer, recompute cutoff, \n",
    "            # and sample AD points\n",
    "            for q in prefix_range:\n",
    "                buf_q = buffers[q]\n",
    "                if len(buf_q[\"X\"]) == 0:\n",
    "                    continue\n",
    "\n",
    "                Xw = np.vstack(buf_q[\"X\"])\n",
    "                yw = np.array(buf_q[\"y\"])\n",
    "                rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                rf.fit(Xw, yw)\n",
    "                buf_q[\"model\"] = rf\n",
    "\n",
    "                # Recompute CE‐loss cutoff (gap-based)\n",
    "                cutoff_q = compute_gap_cutoff(rf, Xw, yw)\n",
    "                buf_q[\"cutoff\"] = cutoff_q\n",
    "                # print(f\"  Recomputed cutoff for prefix {q} (buffer size = {len(buf_q['X'])})\")\n",
    "\n",
    "                anom_idxs = [idx for idx, flag in enumerate(buf_q[\"noise\"]) if flag == 1]\n",
    "                norm_idxs = [idx for idx, flag in enumerate(buf_q[\"noise\"]) if flag == 0]\n",
    "            \n",
    "                n_anom = min(MAX_ANOM, len(anom_idxs))\n",
    "                sel_anom = random.sample(anom_idxs, n_anom) if n_anom > 0 else []\n",
    "                needed_norm = TOTAL_SAMPLES - n_anom\n",
    "                sel_norm = (random.sample(norm_idxs, needed_norm)\n",
    "                            if len(norm_idxs) >= needed_norm\n",
    "                            else norm_idxs)\n",
    "                \n",
    "                sel_idxs = sel_anom + sel_norm\n",
    "                random.shuffle(sel_idxs)\n",
    "    \n",
    "                for idx in sel_idxs:\n",
    "                    prob_vec = rf.predict_proba(buf_q[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                    ce0      = cross_entropy_loss(rf, buf_q[\"X\"][idx].reshape(1, -1), [buf_q[\"y\"][idx]])[0]\n",
    "                    detect_pool.append({\n",
    "                        \"raw_feats\": buf_q[\"raw_feats\"][idx],\n",
    "                        \"target\":    buf_q[\"raw_tgts\"][idx],\n",
    "                        \"prefix\":    p,\n",
    "                        \"prob\":      prob_vec,\n",
    "                        \"ce_loss\":   ce0,\n",
    "                        \"anomaly\":   buf_q[\"noise\"][idx]\n",
    "                    })\n",
    "\n",
    "            # Retrain AD classifier if we have ≥20 samples\n",
    "            if len(detect_pool) >= 20:\n",
    "                cat_rows = []\n",
    "                for d in detect_pool:\n",
    "                    row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                    row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                    cat_rows.append(row_cat)\n",
    "                enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "                X_cat = enc_ad.transform(cat_rows)\n",
    "                max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "                prob_mat = [\n",
    "                    d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                    for d in detect_pool\n",
    "                ]\n",
    "                ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "                X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "                y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "                X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "                # anom_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                # anom_clf.fit(X_ad, y_ad)\n",
    "                AD_CAT_FEATS = X_cat.shape[1]\n",
    "                AD_NUM_FEATS = X_num.shape[1]\n",
    "                                \n",
    "                # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "                #     random_state=42).fit(X_ad, y_ad)\n",
    "                anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.1, eval_metric='logloss',\n",
    "                                         random_state=42).fit(X_ad, y_ad)\n",
    "                # print(f\"  AD retrain on {len(detect_pool)} samples\")\n",
    "                detect_pool = []\n",
    "            global_update_counter = 0\n",
    "\n",
    "        # --- 5.5) Prequential AD classification for current event ---\n",
    "        if anom_clf is not None:\n",
    "            # Build AD feature vector: categorical + numeric\n",
    "            row_cat = feats + [None] * (max_pfx - len(feats)) + [p, y_sp]\n",
    "            # 1) Categorical part\n",
    "            Xc = enc_ad.transform([row_cat])\n",
    "            if Xc.shape[1] != AD_CAT_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_CAT_FEATS} cat features, got {Xc.shape[1]}\")\n",
    "            \n",
    "            # 2) Numeric part (prob_vector + ce_loss)\n",
    "            model = buffers[p]['model']\n",
    "            pvec = model.predict_proba(Xp)[0].tolist()\n",
    "            pad_len = AD_NUM_FEATS - 1\n",
    "            pvec_padded = pvec + [0.0] * (pad_len - len(pvec))\n",
    "            Xn = np.array([pvec_padded + [ce_cur]])\n",
    "            if Xn.shape[1] != AD_NUM_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_NUM_FEATS} num features, got {Xn.shape[1]}\")\n",
    "            \n",
    "            # 3) Combine & predict\n",
    "            Xa = np.hstack([Xc, Xn])\n",
    "            pred_ad = anom_clf.predict(Xa)[0]\n",
    "            prob_ad = anom_clf.predict_proba(Xa)[0, 1]\n",
    "            rf_model   = buffers[p]['model']                       # ◀ Next‐Activity Prediction model\n",
    "            Xp_array   = Xp_vec.reshape(1, -1)\n",
    "            pvec       = rf_model.predict_proba(Xp_array)[0] \n",
    "            idx_true = list(rf_model.classes_).index(y_sp)\n",
    "            \n",
    "            online_ad_reports.append({\n",
    "                \"i\":            i,\n",
    "                \"prefix\":       p,\n",
    "                \"case_id\":      cid,\n",
    "                \"true_noise\":   noise_flag,\n",
    "                \"pred_ad_anom\": int(pred_ad),\n",
    "                \"score\":        float(prob_ad),\n",
    "                'next_act_prob':    pvec[idx_true]\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fb3dc75-691f-477d-af8a-fbe6acb7d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9632832011216134\n"
     ]
    }
   ],
   "source": [
    "rf_model   = buffers[p]['model']                       # ◀ Next‐Activity Prediction model\n",
    "Xp_array   = Xp_vec.reshape(1, -1)\n",
    "pvec       = rf_model.predict_proba(Xp_array)[0] \n",
    "idx_true = list(rf_model.classes_).index(y_sp)\n",
    "\n",
    "print(pvec[idx_true])\n",
    "# print(rf_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecf5cda9-680c-48e2-bc90-d23888d4c6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['raw_feats', 'raw_tgts', 'X', 'y', 'noise', 'model', 'filled', 'cutoff', 'update_counter'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffers[8].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e34eaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prefix 2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4463\n",
      "           1       0.00      0.00      0.00       537\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.45      0.50      0.47      5000\n",
      "weighted avg       0.80      0.89      0.84      5000\n",
      "\n",
      "\n",
      "--- Prefix 3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4550\n",
      "           1       0.00      0.00      0.00       450\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.46      0.50      0.48      5000\n",
      "weighted avg       0.83      0.91      0.87      5000\n",
      "\n",
      "\n",
      "--- Prefix 4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4529\n",
      "           1       0.00      0.00      0.00       471\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.45      0.50      0.48      5000\n",
      "weighted avg       0.82      0.91      0.86      5000\n",
      "\n",
      "\n",
      "--- Prefix 5 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4481\n",
      "           1       0.00      0.00      0.00       519\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.45      0.50      0.47      5000\n",
      "weighted avg       0.80      0.90      0.85      5000\n",
      "\n",
      "\n",
      "--- Prefix 6 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4549\n",
      "           1       0.00      0.00      0.00       451\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.45      0.50      0.48      5000\n",
      "weighted avg       0.83      0.91      0.87      5000\n",
      "\n",
      "\n",
      "--- Prefix 7 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4507\n",
      "           1       0.00      0.00      0.00       493\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.45      0.50      0.47      5000\n",
      "weighted avg       0.81      0.90      0.85      5000\n",
      "\n",
      "\n",
      "--- Prefix 8 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4507\n",
      "           1       0.00      0.00      0.00       493\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.45      0.50      0.47      5000\n",
      "weighted avg       0.81      0.90      0.85      5000\n",
      "\n",
      "\n",
      "--- Prefix 9 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4515\n",
      "           1       0.00      0.00      0.00       485\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.45      0.50      0.47      5000\n",
      "weighted avg       0.82      0.90      0.86      5000\n",
      "\n",
      "\n",
      "--- Prefix 10 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4533\n",
      "           1       0.00      0.00      0.00       467\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.45      0.50      0.48      5000\n",
      "weighted avg       0.82      0.91      0.86      5000\n",
      "\n",
      "\n",
      "--- Prefix 11 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4090\n",
      "           1       0.00      0.00      0.00       432\n",
      "\n",
      "    accuracy                           0.90      4522\n",
      "   macro avg       0.45      0.50      0.47      4522\n",
      "weighted avg       0.82      0.90      0.86      4522\n",
      "\n",
      "\n",
      "--- Prefix 12 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.96      3670\n",
      "           1       0.00      0.00      0.00       343\n",
      "\n",
      "    accuracy                           0.91      4013\n",
      "   macro avg       0.46      0.50      0.48      4013\n",
      "weighted avg       0.84      0.91      0.87      4013\n",
      "\n",
      "\n",
      "--- Prefix 13 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      3448\n",
      "           1       0.00      0.00      0.00       346\n",
      "\n",
      "    accuracy                           0.91      3794\n",
      "   macro avg       0.45      0.50      0.48      3794\n",
      "weighted avg       0.83      0.91      0.87      3794\n",
      "\n",
      "\n",
      "--- Prefix 14 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2962\n",
      "           1       0.00      0.00      0.00       290\n",
      "\n",
      "    accuracy                           0.91      3252\n",
      "   macro avg       0.46      0.50      0.48      3252\n",
      "weighted avg       0.83      0.91      0.87      3252\n",
      "\n",
      "\n",
      "--- Prefix 15 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2319\n",
      "           1       0.00      0.00      0.00       229\n",
      "\n",
      "    accuracy                           0.91      2548\n",
      "   macro avg       0.46      0.50      0.48      2548\n",
      "weighted avg       0.83      0.91      0.87      2548\n",
      "\n",
      "\n",
      "--- Prefix 16 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1936\n",
      "           1       0.00      0.00      0.00       183\n",
      "\n",
      "    accuracy                           0.91      2119\n",
      "   macro avg       0.46      0.50      0.48      2119\n",
      "weighted avg       0.83      0.91      0.87      2119\n",
      "\n",
      "\n",
      "--- Prefix 17 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1604\n",
      "           1       0.00      0.00      0.00       165\n",
      "\n",
      "    accuracy                           0.91      1769\n",
      "   macro avg       0.45      0.50      0.48      1769\n",
      "weighted avg       0.82      0.91      0.86      1769\n",
      "\n",
      "\n",
      "--- Prefix 18 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      1284\n",
      "           1       0.00      0.00      0.00       129\n",
      "\n",
      "    accuracy                           0.91      1413\n",
      "   macro avg       0.45      0.50      0.48      1413\n",
      "weighted avg       0.83      0.91      0.87      1413\n",
      "\n",
      "\n",
      "--- Prefix 19 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1063\n",
      "           1       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           0.92      1157\n",
      "   macro avg       0.46      0.50      0.48      1157\n",
      "weighted avg       0.84      0.92      0.88      1157\n",
      "\n",
      "\n",
      "--- Prefix 20 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       846\n",
      "           1       0.00      0.00      0.00        97\n",
      "\n",
      "    accuracy                           0.90       943\n",
      "   macro avg       0.45      0.50      0.47       943\n",
      "weighted avg       0.80      0.90      0.85       943\n",
      "\n",
      "\n",
      "--- Prefix 21 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       680\n",
      "           1       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.91       745\n",
      "   macro avg       0.46      0.50      0.48       745\n",
      "weighted avg       0.83      0.91      0.87       745\n",
      "\n",
      "\n",
      "--- Prefix 22 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       566\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.94       602\n",
      "   macro avg       0.47      0.50      0.48       602\n",
      "weighted avg       0.88      0.94      0.91       602\n",
      "\n",
      "\n",
      "--- Prefix 23 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       437\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.90       483\n",
      "   macro avg       0.45      0.50      0.47       483\n",
      "weighted avg       0.82      0.90      0.86       483\n",
      "\n",
      "\n",
      "--- Prefix 24 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       372\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.93       401\n",
      "   macro avg       0.46      0.50      0.48       401\n",
      "weighted avg       0.86      0.93      0.89       401\n",
      "\n",
      "\n",
      "--- Prefix 25 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       292\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.92       317\n",
      "   macro avg       0.46      0.50      0.48       317\n",
      "weighted avg       0.85      0.92      0.88       317\n",
      "\n",
      "\n",
      "--- Prefix 26 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       229\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.92       249\n",
      "   macro avg       0.46      0.50      0.48       249\n",
      "weighted avg       0.85      0.92      0.88       249\n",
      "\n",
      "\n",
      "--- Prefix 27 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       186\n",
      "           1       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.91       204\n",
      "   macro avg       0.46      0.50      0.48       204\n",
      "weighted avg       0.83      0.91      0.87       204\n",
      "\n",
      "\n",
      "--- Prefix 28 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       149\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.92       162\n",
      "   macro avg       0.46      0.50      0.48       162\n",
      "weighted avg       0.85      0.92      0.88       162\n",
      "\n",
      "\n",
      "--- Prefix 29 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       121\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.92       131\n",
      "   macro avg       0.46      0.50      0.48       131\n",
      "weighted avg       0.85      0.92      0.89       131\n",
      "\n",
      "\n",
      "--- Prefix 30 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        90\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.45      0.50      0.47       100\n",
      "weighted avg       0.81      0.90      0.85       100\n",
      "\n",
      "\n",
      "--- Prefix 31 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        69\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.44      0.50      0.47        79\n",
      "weighted avg       0.76      0.87      0.81        79\n",
      "\n",
      "\n",
      "--- Prefix 32 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        66\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        68\n",
      "   macro avg       0.49      0.50      0.49        68\n",
      "weighted avg       0.94      0.97      0.96        68\n",
      "\n",
      "\n",
      "--- Prefix 33 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        52\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.88        59\n",
      "   macro avg       0.44      0.50      0.47        59\n",
      "weighted avg       0.78      0.88      0.83        59\n",
      "\n",
      "\n",
      "--- Prefix 34 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        44\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.96        46\n",
      "   macro avg       0.48      0.50      0.49        46\n",
      "weighted avg       0.91      0.96      0.94        46\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>prefix</th>\n",
       "      <th>case_id</th>\n",
       "      <th>true_noise</th>\n",
       "      <th>pred_ad_anom</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74171</th>\n",
       "      <td>79437</td>\n",
       "      <td>6</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74172</th>\n",
       "      <td>79438</td>\n",
       "      <td>7</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74173</th>\n",
       "      <td>79439</td>\n",
       "      <td>8</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74174</th>\n",
       "      <td>79440</td>\n",
       "      <td>9</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74175</th>\n",
       "      <td>79441</td>\n",
       "      <td>10</td>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74176 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           i  prefix  case_id  true_noise  pred_ad_anom     score\n",
       "0          2       2        0           0             0  0.119203\n",
       "1          3       3        0           0             0  0.119203\n",
       "2          4       4        0           0             0  0.119203\n",
       "3          5       5        0           0             0  0.119203\n",
       "4          6       6        0           1             0  0.231475\n",
       "...      ...     ...      ...         ...           ...       ...\n",
       "74171  79437       6     4999           0             0  0.150148\n",
       "74172  79438       7     4999           0             0  0.149167\n",
       "74173  79439       8     4999           0             0  0.161985\n",
       "74174  79440       9     4999           0             0  0.149167\n",
       "74175  79441      10     4999           0             0  0.149167\n",
       "\n",
       "[74176 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Summarize\n",
    "reports_df = pd.DataFrame(online_ad_reports)\n",
    "for p in prefix_range:\n",
    "    sub = reports_df[reports_df[\"prefix\"] == p]\n",
    "    if not sub.empty:\n",
    "        print(f\"\\n--- Prefix {p} ---\")\n",
    "        print(classification_report(\n",
    "            sub[\"true_noise\"], sub[\"pred_ad_anom\"], zero_division=0\n",
    "        ))\n",
    "reports_df \n",
    "# reports_df.to_csv('../result/%s_classifier_xgb_%s_random_sample_cumulative.csv'%(dataset, TOTAL_SAMPLES), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
