{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6359130d-d83a-417d-8195-19fe8d5d063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c65daa7-625a-4cde-95d5-7b12162b2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from collections import Counter, defaultdict, deque\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, log_loss, roc_auc_score\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436c9ec0-6f87-4e03-8693-f65615e37d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = -∑_c [1{c = y_true_i} · log P_model(c | x_i)]\n",
    "    If the true label isn’t in model.classes_, returns a default high loss.\n",
    "    Works for any len(x_test) >= 1, including the single-class case.\n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(x_test)\n",
    "    default = log_loss([[1, 0]], [[0, 1]]) + 1  # fallback loss\n",
    "\n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        classes = model.classes_\n",
    "\n",
    "        # if only one class in the model\n",
    "        if sample_probs.size == 1:\n",
    "            if classes[0] == true_label:\n",
    "                losses.append(0.0)  # perfect prediction\n",
    "            else:\n",
    "                losses.append(default)\n",
    "            continue\n",
    "\n",
    "        # find index of the true label\n",
    "        idx_arr = np.where(classes == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(default)\n",
    "        else:\n",
    "            y_true_onehot = np.zeros_like(sample_probs)\n",
    "            y_true_onehot[idx_arr[0]] = 1\n",
    "\n",
    "            # normalize just in case\n",
    "            sample_probs = sample_probs / sample_probs.sum()\n",
    "            y_true_onehot = y_true_onehot / y_true_onehot.sum()\n",
    "\n",
    "            loss_i = log_loss([y_true_onehot], [sample_probs])\n",
    "            losses.append(loss_i)\n",
    "\n",
    "    return np.array(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a326d72-e423-4342-ab84-b6cc0f57f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = 1 - P_model(y_true_i | x_i)\n",
    "    If the true label isn’t in model.classes_, we return 1.1 as before.\n",
    "    Works for any len(x_test) >= 1.\n",
    "    \"\"\"\n",
    "    # predict_proba returns shape (n_samples, n_classes)\n",
    "    probs = model.predict_proba(x_test)\n",
    "    \n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        # find index of the true label in model.classes_\n",
    "        idx_arr = np.where(model.classes_ == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(1.1)\n",
    "        else:\n",
    "            col_index = idx_arr[0]\n",
    "            losses.append(1 - sample_probs[col_index])\n",
    "    \n",
    "    return np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67df5525-9258-4e21-8c52-e04640f5705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_transform_target(encoder, targets, unknown_value=-1):\n",
    "    classes = set(encoder.classes_)\n",
    "    transformed = []\n",
    "    for t in targets:\n",
    "        if t in classes:\n",
    "            transformed.append(encoder.transform([t])[0])\n",
    "        else:\n",
    "            transformed.append(unknown_value)\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f91784-9b9d-42e8-940a-449e7e5aa38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_loss(normal_loss_value, cross_entropy_loss_value):\n",
    "    normal_loss_dist = []\n",
    "    cross_loss_dist = []\n",
    "    for pos, prediction in  enumerate(normal_loss_value):\n",
    "        if prediction != 1:\n",
    "            cross_loss_dist.append(cross_entropy_loss_value[pos])\n",
    "            normal_loss_dist.append(prediction)\n",
    "\n",
    "    return np.array(normal_loss_dist), np.array(cross_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bccdc88-d8de-4e75-a345-f243d4456d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_cls_result(classification_result):\n",
    "    \n",
    "    for i in classification_result.keys():\n",
    "        print(i, classification_result[i].keys())\n",
    "\n",
    "        if '1' not in classification_result[i].keys():\n",
    "            classification_result[i]['1'] = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0.0}\n",
    "    return classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02992352-3427-4883-b6d3-22971e4f6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_gap(losses):\n",
    "    y = sorted(losses, reverse=True)\n",
    "    diffs = abs(np.diff(y))\n",
    "    idx = np.argmax(diffs) + 1   # +1 because diffs[i] = y[i+1]-y[i]\n",
    "    return idx, y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070dced0-5f9b-468c-a249-d9998bb3fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 0.099_noise.csv (n_rows=79441)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1) Read and Process the Data\n",
    "# ----------------------------\n",
    "dataset = '0.099_noise.csv'\n",
    "df = pd.read_csv(f\"../data/{dataset}\")\n",
    "df = df.sort_values(by='Timestamp')\n",
    "# Process 'noise' column: NaN→0, True/1/'True'/'true'→1, else 0\n",
    "df['noise'] = df['noise'].fillna(0).apply(lambda x: 1 if (x is True or x == 1 or x == 'True' or x == 'true') else 0)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.rename(columns={'Case ID': 'ID'})\n",
    "print(f\"Loaded: {dataset} (n_rows={len(df)})\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Prefixes & Global Window Settings\n",
    "# ----------------------------\n",
    "prefix_range = range(2, 38)   # 2..15\n",
    "WINDOW_EVENTS = 2500          # keep last 2500 prefix‐events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd85083b-d24f-4350-b687-95b5259c0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 3) Pre‐fit Encoders for NAP\n",
    "# ----------------------------\n",
    "all_acts = df[\"Activity\"].unique()\n",
    "ohe_nap = {\n",
    "    p: OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "         .fit(np.array([[a] * (p - 1) for a in all_acts]))\n",
    "    for p in prefix_range\n",
    "}\n",
    "le_nap = {p: LabelEncoder().fit(all_acts) for p in prefix_range}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cc257c-e921-4ab9-9f8e-87bd27c96ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 4) Buffers & State Initialization\n",
    "# ----------------------------\n",
    "# Global sliding window of the last WINDOW_EVENTS prefix‐events\n",
    "global_events = deque(maxlen=WINDOW_EVENTS)\n",
    "\n",
    "# Per‐prefix buffers (unbounded; we’ll evict manually)\n",
    "buffers = {}\n",
    "for p in prefix_range:\n",
    "    buffers[p] = {\n",
    "        \"raw_feats\":      deque(),\n",
    "        \"raw_tgts\":       deque(),\n",
    "        \"X\":               deque(),\n",
    "        \"y\":               deque(),\n",
    "        \"noise\":           deque(),\n",
    "        \"model\":          None,\n",
    "        \"filled\":         False,\n",
    "        \"cutoff\":         None\n",
    "    }\n",
    "\n",
    "case_events      = defaultdict(list)\n",
    "detect_pool      = []   # list of dicts for AD training\n",
    "anom_clf         = None\n",
    "enc_ad           = None\n",
    "max_prob_ad      = 0\n",
    "max_pfx          = max(prefix_range) - 1  # for padding raw_feats\n",
    "\n",
    "online_nap_reports = []\n",
    "online_ad_reports  = []\n",
    "\n",
    "# Build a vocabulary (activity→index) for LSTM sequencing\n",
    "act2idx = {act: i + 1 for i, act in enumerate(all_acts)}\n",
    "vocab_size = len(act2idx) + 1  # +1 for padding index=0\n",
    "\n",
    "# ----------------------------\n",
    "# 4.5) Helper: compute gap‐based CE cutoff\n",
    "# ----------------------------\n",
    "def compute_gap_cutoff(rf, Xw, yw):\n",
    "    ce_losses = cross_entropy_loss(rf, Xw, yw)\n",
    "    n = ce_losses.size\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    if n == 1:\n",
    "        return float(ce_losses[0])\n",
    "    # find_largest_gap returns (idx, cutoff)\n",
    "    _, cutoff_gap = find_largest_gap(ce_losses)\n",
    "    return cutoff_gap\n",
    "\n",
    "# ----------------------------\n",
    "# 4.6) Define LSTM‐based AD Classifier\n",
    "# ----------------------------\n",
    "class AD_LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_num_feats):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout_seq = nn.Dropout(0.2)\n",
    "        self.fc_num = nn.Sequential(\n",
    "            nn.Linear(num_num_feats, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(hidden_dim + 64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_seq, x_num):\n",
    "        # x_seq: (batch, seq_len), x_num: (batch, num_feats)\n",
    "        emb = self.embedding(x_seq)              # (batch, seq_len, embed_dim)\n",
    "        _, (h_n, _) = self.lstm(emb)             # h_n: (1, batch, hidden_dim)\n",
    "        h_last = h_n[0]                          # (batch, hidden_dim)\n",
    "        h_last = self.dropout_seq(h_last)\n",
    "\n",
    "        n_out = self.fc_num(x_num)               # (batch, 64)\n",
    "        combined = torch.cat([h_last, n_out], dim=1)  # (batch, hidden_dim+64)\n",
    "        return self.fc_combined(combined)        # (batch,1) sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e18b4876-8921-47f4-b816-3d66757ad570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/79441 rows (1.3%)\n",
      "Processed 2000/79441 rows (2.5%)\n",
      "Processed 3000/79441 rows (3.8%)\n",
      "Processed 4000/79441 rows (5.0%)\n",
      "Processed 5000/79441 rows (6.3%)\n",
      "Processed 6000/79441 rows (7.6%)\n",
      "Processed 7000/79441 rows (8.8%)\n",
      "Processed 8000/79441 rows (10.1%)\n",
      "Processed 9000/79441 rows (11.3%)\n",
      "Processed 10000/79441 rows (12.6%)\n",
      "Processed 11000/79441 rows (13.8%)\n",
      "Processed 12000/79441 rows (15.1%)\n",
      "Processed 13000/79441 rows (16.4%)\n",
      "Processed 14000/79441 rows (17.6%)\n",
      "Processed 15000/79441 rows (18.9%)\n",
      "Processed 16000/79441 rows (20.1%)\n",
      "Processed 17000/79441 rows (21.4%)\n",
      "Processed 18000/79441 rows (22.7%)\n",
      "Processed 19000/79441 rows (23.9%)\n",
      "Processed 20000/79441 rows (25.2%)\n",
      "Processed 21000/79441 rows (26.4%)\n",
      "Processed 22000/79441 rows (27.7%)\n",
      "Processed 23000/79441 rows (29.0%)\n",
      "Processed 24000/79441 rows (30.2%)\n",
      "Processed 25000/79441 rows (31.5%)\n",
      "Processed 26000/79441 rows (32.7%)\n",
      "Processed 27000/79441 rows (34.0%)\n",
      "Processed 28000/79441 rows (35.2%)\n",
      "Processed 29000/79441 rows (36.5%)\n",
      "Processed 30000/79441 rows (37.8%)\n",
      "Processed 31000/79441 rows (39.0%)\n",
      "Processed 32000/79441 rows (40.3%)\n",
      "Processed 33000/79441 rows (41.5%)\n",
      "Processed 34000/79441 rows (42.8%)\n",
      "Processed 35000/79441 rows (44.1%)\n",
      "Processed 36000/79441 rows (45.3%)\n",
      "Processed 37000/79441 rows (46.6%)\n",
      "Processed 38000/79441 rows (47.8%)\n",
      "Processed 39000/79441 rows (49.1%)\n",
      "Processed 40000/79441 rows (50.4%)\n",
      "Processed 41000/79441 rows (51.6%)\n",
      "Processed 42000/79441 rows (52.9%)\n",
      "Processed 43000/79441 rows (54.1%)\n",
      "Processed 44000/79441 rows (55.4%)\n",
      "Processed 45000/79441 rows (56.6%)\n",
      "Processed 46000/79441 rows (57.9%)\n",
      "Processed 47000/79441 rows (59.2%)\n",
      "Processed 48000/79441 rows (60.4%)\n",
      "Processed 49000/79441 rows (61.7%)\n",
      "Processed 50000/79441 rows (62.9%)\n",
      "Processed 51000/79441 rows (64.2%)\n",
      "Processed 52000/79441 rows (65.5%)\n",
      "Processed 53000/79441 rows (66.7%)\n",
      "Processed 54000/79441 rows (68.0%)\n",
      "Processed 55000/79441 rows (69.2%)\n",
      "Processed 56000/79441 rows (70.5%)\n",
      "Processed 57000/79441 rows (71.8%)\n",
      "Processed 58000/79441 rows (73.0%)\n",
      "Processed 59000/79441 rows (74.3%)\n",
      "Processed 60000/79441 rows (75.5%)\n",
      "Processed 61000/79441 rows (76.8%)\n",
      "Processed 62000/79441 rows (78.0%)\n",
      "Processed 63000/79441 rows (79.3%)\n",
      "Processed 64000/79441 rows (80.6%)\n",
      "Processed 65000/79441 rows (81.8%)\n",
      "Processed 66000/79441 rows (83.1%)\n",
      "Processed 67000/79441 rows (84.3%)\n",
      "Processed 68000/79441 rows (85.6%)\n",
      "Processed 69000/79441 rows (86.9%)\n",
      "Processed 70000/79441 rows (88.1%)\n",
      "Processed 71000/79441 rows (89.4%)\n",
      "Processed 72000/79441 rows (90.6%)\n",
      "Processed 73000/79441 rows (91.9%)\n",
      "Processed 74000/79441 rows (93.2%)\n",
      "Processed 75000/79441 rows (94.4%)\n",
      "Processed 76000/79441 rows (95.7%)\n",
      "Processed 77000/79441 rows (96.9%)\n",
      "Processed 78000/79441 rows (98.2%)\n",
      "Processed 79000/79441 rows (99.4%)\n",
      "Processed 79441/79441 rows (100.0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 5) Streaming Loop with NAP + LSTM‐AD\n",
    "# ----------------------------\n",
    "total = len(df)\n",
    "global_update_counter = 0\n",
    "global_retrain_batch = WINDOW_EVENTS // 2  # 1250\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i, (_, row) in enumerate(df.iterrows(), start=1):\n",
    "    # Progress logging\n",
    "    if i % 1000 == 0 or i == total:\n",
    "        pct = i / total * 100\n",
    "        print(f\"Processed {i}/{total} rows ({pct:.1f}%)\")\n",
    "\n",
    "    cid = row[\"ID\"]\n",
    "    case_events[cid].append(row)\n",
    "    cur_len = len(case_events[cid])\n",
    "\n",
    "    # Only process when a case first reaches prefix length p\n",
    "    for p in prefix_range:\n",
    "        if cur_len != p:\n",
    "            continue\n",
    "\n",
    "        # Build current sample\n",
    "        group      = case_events[cid]\n",
    "        feats      = [e.Activity for e in group[: p - 1]]\n",
    "        target_act = group[p - 1].Activity\n",
    "        noise_flag = group[p - 1].noise\n",
    "\n",
    "        buf = buffers[p]\n",
    "\n",
    "        # --- 5.1) Slide the global window (peek dropped if full) ---\n",
    "        dropped = None\n",
    "        if len(global_events) == WINDOW_EVENTS:\n",
    "            dropped = global_events[0]  # will be popped on append()\n",
    "\n",
    "        # Transform for NAP\n",
    "        Xp_vec = ohe_nap[p].transform([feats]).ravel()\n",
    "        yp     = le_nap[p].transform([target_act])[0]\n",
    "\n",
    "        # Append to global_events: (prefix, X_vec, y_label, noise, raw_feats, raw_target)\n",
    "        global_events.append((p, Xp_vec, yp, noise_flag, feats, target_act))\n",
    "\n",
    "        # Append to this prefix’s buffers\n",
    "        buf[\"raw_feats\"].append(feats)\n",
    "        buf[\"raw_tgts\"].append(target_act)\n",
    "        buf[\"X\"].append(Xp_vec)\n",
    "        buf[\"y\"].append(yp)\n",
    "        buf[\"noise\"].append(noise_flag)\n",
    "\n",
    "        # Evict from old prefix buffer if needed\n",
    "        if dropped is not None:\n",
    "            old_p, old_Xp, old_yp, old_noise, old_feats, old_tgt = dropped\n",
    "            old_buf = buffers[old_p]\n",
    "            if old_buf[\"X\"]:\n",
    "                old_buf[\"raw_feats\"].popleft()\n",
    "                old_buf[\"raw_tgts\"].popleft()\n",
    "                old_buf[\"X\"].popleft()\n",
    "                old_buf[\"y\"].popleft()\n",
    "                old_buf[\"noise\"].popleft()\n",
    "\n",
    "        # --- 5.2) Initial NAP training for prefix p ---\n",
    "        if buf[\"model\"] is None:\n",
    "            Xw = np.vstack(buf[\"X\"])\n",
    "            yw = np.array(buf[\"y\"])\n",
    "\n",
    "            rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "            rf.fit(Xw, yw)\n",
    "\n",
    "            cutoff = compute_gap_cutoff(rf, Xw, yw)\n",
    "            buf[\"model\"]  = rf\n",
    "            buf[\"filled\"] = True\n",
    "            buf[\"cutoff\"] = cutoff\n",
    "\n",
    "            # Bootstrap AD pool with up to 20 samples (≤10 anomalies)\n",
    "            anom_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 1]\n",
    "            norm_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 0]\n",
    "\n",
    "            n_anom = min(10, len(anom_idxs))\n",
    "            sel_anom = random.sample(anom_idxs, n_anom) if n_anom > 0 else []\n",
    "            sel_norm = random.sample(norm_idxs, 20 - n_anom) if len(norm_idxs) >= (20 - n_anom) else norm_idxs\n",
    "\n",
    "            sel_idxs = sel_anom + sel_norm\n",
    "            random.shuffle(sel_idxs)\n",
    "\n",
    "            for idx in sel_idxs:\n",
    "                prob_vec = rf.predict_proba(buf[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                ce0      = cross_entropy_loss(rf, buf[\"X\"][idx].reshape(1, -1), [buf[\"y\"][idx]])[0]\n",
    "                detect_pool.append({\n",
    "                    \"raw_feats\": buf[\"raw_feats\"][idx],\n",
    "                    \"prefix\":    p,\n",
    "                    \"target\":    buf[\"raw_tgts\"][idx],\n",
    "                    \"prob\":      prob_vec,\n",
    "                    \"ce_loss\":   ce0,\n",
    "                    \"anomaly\":   buf[\"noise\"][idx]\n",
    "                })\n",
    "\n",
    "            # Train LSTM‐AD if we have ≥20 samples\n",
    "            if len(detect_pool) >= 20:\n",
    "                # 1) Build categorical rows for OneHotEncoder (if needed)\n",
    "                cat_rows = []\n",
    "                for d in detect_pool:\n",
    "                    row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                    row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                    cat_rows.append(row_cat)\n",
    "                enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "                X_cat_np = enc_ad.transform(cat_rows)  # shape (N, D_cat)\n",
    "\n",
    "                # 2) Build numeric features: (prob_vector + [ce_loss])\n",
    "                max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "                prob_mat = [\n",
    "                    d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                    for d in detect_pool\n",
    "                ]\n",
    "                ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "                X_num_np = np.hstack([prob_mat, ce_vec])  # (N, max_prob_ad+1)\n",
    "\n",
    "                # 3) Build LSTM sequences\n",
    "                seqs = []\n",
    "                for d in detect_pool:\n",
    "                    seq = [act2idx[a] for a in d[\"raw_feats\"]]\n",
    "                    seqs.append(torch.tensor(seq, dtype=torch.long))\n",
    "                X_seq = pad_sequence(seqs, batch_first=True, padding_value=0)  # (N, max_seq_len)\n",
    "\n",
    "                # 4) Labels\n",
    "                y_ad_np = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "\n",
    "                # 5) Create PyTorch Dataset & DataLoader\n",
    "                class AD_LSTMDataset(Dataset):\n",
    "                    def __init__(self, X_seq, X_num, y):\n",
    "                        self.X_seq = X_seq       # LongTensor\n",
    "                        self.X_num = torch.from_numpy(X_num).float()\n",
    "                        self.y     = torch.from_numpy(y).float().unsqueeze(1)\n",
    "\n",
    "                    def __len__(self):\n",
    "                        return self.X_seq.shape[0]\n",
    "\n",
    "                    def __getitem__(self, idx):\n",
    "                        return self.X_seq[idx], self.X_num[idx], self.y[idx]\n",
    "\n",
    "                dataset_lstm = AD_LSTMDataset(X_seq, X_num_np, y_ad_np)\n",
    "                loader_lstm  = DataLoader(dataset_lstm, batch_size=64, shuffle=True)\n",
    "\n",
    "                # 6) Instantiate and train the LSTM model\n",
    "                embed_dim   = 32\n",
    "                hidden_dim  = 64\n",
    "                num_num_feats = X_num_np.shape[1]\n",
    "\n",
    "                model_lstm = AD_LSTM(vocab_size, embed_dim, hidden_dim, num_num_feats).to(device)\n",
    "                optimizer = optim.Adam(model_lstm.parameters(), lr=1e-3)\n",
    "                criterion = nn.BCELoss()\n",
    "\n",
    "                model_lstm.train()\n",
    "                for epoch in range(5):  # 5 epochs for simplicity\n",
    "                    total_loss = 0.0\n",
    "                    for Xseq_batch, Xnum_batch, y_batch in loader_lstm:\n",
    "                        Xseq_batch = Xseq_batch.to(device)\n",
    "                        Xnum_batch = Xnum_batch.to(device)\n",
    "                        y_batch    = y_batch.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model_lstm(Xseq_batch, Xnum_batch)\n",
    "                        loss = criterion(outputs, y_batch)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item() * Xseq_batch.size(0)\n",
    "\n",
    "                    total_loss /= len(dataset_lstm)\n",
    "                    # print(f\"Epoch {epoch+1}, Loss={total_loss:.4f}\")\n",
    "\n",
    "                anom_clf = model_lstm.eval()  # set to eval mode\n",
    "\n",
    "            continue  # skip further processing of this event\n",
    "\n",
    "        # --- 5.3) Prequential NAP Prediction & Store ---\n",
    "        rf   = buf[\"model\"]\n",
    "        Xp   = Xp_vec.reshape(1, -1)\n",
    "        y_sp = yp\n",
    "        cutoff_nap = buf[\"cutoff\"]\n",
    "\n",
    "        ce_cur = cross_entropy_loss(rf, Xp, [y_sp])[0]\n",
    "        pred_nap_anom = int(ce_cur > cutoff_nap)\n",
    "\n",
    "        online_nap_reports.append({\n",
    "            \"i\":             i,\n",
    "            \"prefix\":        p,\n",
    "            \"case_id\":       cid,\n",
    "            \"true_noise\":    noise_flag,\n",
    "            \"pred_nap_anom\": pred_nap_anom,\n",
    "            \"cutoff\":        cutoff_nap\n",
    "        })\n",
    "\n",
    "        # --- 5.4) Global Retrain Trigger (increment once per prefix-event) ---\n",
    "        global_update_counter += 1\n",
    "        if global_update_counter >= global_retrain_batch:\n",
    "            for q in prefix_range:\n",
    "                buf_q = buffers[q]\n",
    "                if len(buf_q[\"X\"]) == 0:\n",
    "                    continue\n",
    "\n",
    "                Xw = np.vstack(buf_q[\"X\"])\n",
    "                yw = np.array(buf_q[\"y\"])\n",
    "                rf_q = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                rf_q.fit(Xw, yw)\n",
    "                buf_q[\"model\"] = rf_q\n",
    "\n",
    "                cutoff_q = compute_gap_cutoff(rf_q, Xw, yw)\n",
    "                buf_q[\"cutoff\"] = cutoff_q\n",
    "\n",
    "                # Sample up to 20 events from this prefix buffer for AD pool\n",
    "                window_size = len(buf_q[\"y\"])\n",
    "                if window_size < 20:\n",
    "                    sample_idxs = list(range(window_size))\n",
    "                else:\n",
    "                    sample_idxs = random.sample(range(window_size), k=20)\n",
    "\n",
    "                for idx in sample_idxs:\n",
    "                    prob_vec = rf_q.predict_proba(buf_q[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                    ce0      = cross_entropy_loss(rf_q, buf_q[\"X\"][idx].reshape(1, -1), [buf_q[\"y\"][idx]])[0]\n",
    "                    detect_pool.append({\n",
    "                        \"raw_feats\": buf_q[\"raw_feats\"][idx],\n",
    "                        \"prefix\":    q,\n",
    "                        \"target\":    buf_q[\"raw_tgts\"][idx],\n",
    "                        \"prob\":      prob_vec,\n",
    "                        \"ce_loss\":   ce0,\n",
    "                        \"anomaly\":   buf_q[\"noise\"][idx]\n",
    "                    })\n",
    "\n",
    "            # Retrain LSTM‐AD if detect_pool has ≥20\n",
    "            if len(detect_pool) >= 20:\n",
    "                # Build categorical rows & OneHotEncoder\n",
    "                cat_rows = []\n",
    "                for d in detect_pool:\n",
    "                    row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                    row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                    cat_rows.append(row_cat)\n",
    "                enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "                X_cat_np = enc_ad.transform(cat_rows)\n",
    "\n",
    "                # Numeric features\n",
    "                max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "                prob_mat = [\n",
    "                    d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                    for d in detect_pool\n",
    "                ]\n",
    "                ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "                X_num_np = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "                # Build LSTM sequences\n",
    "                seqs = []\n",
    "                for d in detect_pool:\n",
    "                    seq = [act2idx[a] for a in d[\"raw_feats\"]]\n",
    "                    seqs.append(torch.tensor(seq, dtype=torch.long))\n",
    "                X_seq = pad_sequence(seqs, batch_first=True, padding_value=0)\n",
    "\n",
    "                # Labels\n",
    "                y_ad_np = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "\n",
    "                # Dataset & DataLoader\n",
    "                dataset_lstm = AD_LSTMDataset(X_seq, X_num_np, y_ad_np)\n",
    "                loader_lstm  = DataLoader(dataset_lstm, batch_size=64, shuffle=True)\n",
    "\n",
    "                # Retrain LSTM model\n",
    "                embed_dim     = 32\n",
    "                hidden_dim    = 64\n",
    "                num_num_feats = X_num_np.shape[1]\n",
    "\n",
    "                model_lstm = AD_LSTM(vocab_size, embed_dim, hidden_dim, num_num_feats).to(device)\n",
    "                optimizer = optim.Adam(model_lstm.parameters(), lr=1e-3)\n",
    "                criterion = nn.BCELoss()\n",
    "\n",
    "                model_lstm.train()\n",
    "                for epoch in range(5):\n",
    "                    total_loss = 0.0\n",
    "                    for Xseq_batch, Xnum_batch, y_batch in loader_lstm:\n",
    "                        Xseq_batch = Xseq_batch.to(device)\n",
    "                        Xnum_batch = Xnum_batch.to(device)\n",
    "                        y_batch    = y_batch.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model_lstm(Xseq_batch, Xnum_batch)\n",
    "                        loss = criterion(outputs, y_batch)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item() * Xseq_batch.size(0)\n",
    "\n",
    "                    total_loss /= len(dataset_lstm)\n",
    "                    # print(f\"(Retrain) Epoch {epoch+1}, Loss={total_loss:.4f}\")\n",
    "\n",
    "                anom_clf = model_lstm.eval()  # switch to eval mode\n",
    "\n",
    "            global_update_counter = 0\n",
    "\n",
    "        # --- 5.5) Prequential LSTM‐AD Classification for Current Event ---\n",
    "        if anom_clf is not None:\n",
    "            # Build sequence for current event\n",
    "            seq_new = [act2idx[a] for a in feats]\n",
    "            X_seq_new = pad_sequence([torch.tensor(seq_new, dtype=torch.long)],\n",
    "                                     batch_first=True, padding_value=0).to(device)\n",
    "            # Build numeric for current event\n",
    "            pvec_new = rf.predict_proba(Xp)[0].tolist()\n",
    "            pvec_new += [0.0] * (max_prob_ad - len(pvec_new))\n",
    "            ce0_new = ce_cur\n",
    "            X_num_new = torch.tensor([pvec_new + [ce0_new]], dtype=torch.float).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prob_ad = float(model_lstm(X_seq_new, X_num_new).item())\n",
    "            pred_ad = int(prob_ad > 0.5)\n",
    "\n",
    "            online_ad_reports.append({\n",
    "                \"i\":            i,\n",
    "                \"prefix\":       p,\n",
    "                \"case_id\":      cid,\n",
    "                \"true_noise\":   noise_flag,\n",
    "                \"pred_ad_anom\": pred_ad,\n",
    "                \"score\":        prob_ad\n",
    "            })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74591643-1ea5-46df-bdb8-7f421e01b605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prefix 2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4460\n",
      "           1       0.87      0.95      0.91       537\n",
      "\n",
      "    accuracy                           0.98      4997\n",
      "   macro avg       0.93      0.97      0.95      4997\n",
      "weighted avg       0.98      0.98      0.98      4997\n",
      "\n",
      "\n",
      "--- Prefix 3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4547\n",
      "           1       0.84      0.91      0.87       450\n",
      "\n",
      "    accuracy                           0.98      4997\n",
      "   macro avg       0.91      0.95      0.93      4997\n",
      "weighted avg       0.98      0.98      0.98      4997\n",
      "\n",
      "\n",
      "--- Prefix 4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      4526\n",
      "           1       0.54      0.90      0.68       471\n",
      "\n",
      "    accuracy                           0.92      4997\n",
      "   macro avg       0.77      0.91      0.82      4997\n",
      "weighted avg       0.95      0.92      0.93      4997\n",
      "\n",
      "\n",
      "--- Prefix 5 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      4478\n",
      "           1       0.51      0.93      0.66       519\n",
      "\n",
      "    accuracy                           0.90      4997\n",
      "   macro avg       0.75      0.92      0.80      4997\n",
      "weighted avg       0.94      0.90      0.91      4997\n",
      "\n",
      "\n",
      "--- Prefix 6 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      4547\n",
      "           1       0.69      0.94      0.79       450\n",
      "\n",
      "    accuracy                           0.96      4997\n",
      "   macro avg       0.84      0.95      0.88      4997\n",
      "weighted avg       0.97      0.96      0.96      4997\n",
      "\n",
      "\n",
      "--- Prefix 7 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96      4504\n",
      "           1       0.57      0.91      0.70       493\n",
      "\n",
      "    accuracy                           0.92      4997\n",
      "   macro avg       0.78      0.92      0.83      4997\n",
      "weighted avg       0.95      0.92      0.93      4997\n",
      "\n",
      "\n",
      "--- Prefix 8 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      4504\n",
      "           1       0.43      0.92      0.59       493\n",
      "\n",
      "    accuracy                           0.87      4997\n",
      "   macro avg       0.71      0.89      0.76      4997\n",
      "weighted avg       0.93      0.87      0.89      4997\n",
      "\n",
      "\n",
      "--- Prefix 9 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      4512\n",
      "           1       0.39      0.92      0.55       485\n",
      "\n",
      "    accuracy                           0.85      4997\n",
      "   macro avg       0.69      0.88      0.73      4997\n",
      "weighted avg       0.93      0.85      0.88      4997\n",
      "\n",
      "\n",
      "--- Prefix 10 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      4530\n",
      "           1       0.32      0.91      0.48       467\n",
      "\n",
      "    accuracy                           0.81      4997\n",
      "   macro avg       0.66      0.86      0.68      4997\n",
      "weighted avg       0.93      0.81      0.85      4997\n",
      "\n",
      "\n",
      "--- Prefix 11 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83      4087\n",
      "           1       0.26      0.94      0.41       432\n",
      "\n",
      "    accuracy                           0.74      4519\n",
      "   macro avg       0.63      0.83      0.62      4519\n",
      "weighted avg       0.92      0.74      0.79      4519\n",
      "\n",
      "\n",
      "--- Prefix 12 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80      3668\n",
      "           1       0.20      0.92      0.33       342\n",
      "\n",
      "    accuracy                           0.69      4010\n",
      "   macro avg       0.60      0.79      0.57      4010\n",
      "weighted avg       0.92      0.69      0.76      4010\n",
      "\n",
      "\n",
      "--- Prefix 13 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.79      3445\n",
      "           1       0.21      0.94      0.35       346\n",
      "\n",
      "    accuracy                           0.68      3791\n",
      "   macro avg       0.60      0.80      0.57      3791\n",
      "weighted avg       0.92      0.68      0.75      3791\n",
      "\n",
      "\n",
      "--- Prefix 14 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.59      0.74      2960\n",
      "           1       0.18      0.92      0.30       290\n",
      "\n",
      "    accuracy                           0.62      3250\n",
      "   macro avg       0.59      0.76      0.52      3250\n",
      "weighted avg       0.92      0.62      0.70      3250\n",
      "\n",
      "\n",
      "--- Prefix 15 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.53      0.69      2318\n",
      "           1       0.16      0.90      0.27       229\n",
      "\n",
      "    accuracy                           0.57      2547\n",
      "   macro avg       0.57      0.71      0.48      2547\n",
      "weighted avg       0.91      0.57      0.65      2547\n",
      "\n",
      "\n",
      "--- Prefix 16 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.50      0.66      1935\n",
      "           1       0.15      0.91      0.25       183\n",
      "\n",
      "    accuracy                           0.54      2118\n",
      "   macro avg       0.57      0.71      0.46      2118\n",
      "weighted avg       0.91      0.54      0.63      2118\n",
      "\n",
      "\n",
      "--- Prefix 17 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.64      1604\n",
      "           1       0.15      0.95      0.27       164\n",
      "\n",
      "    accuracy                           0.52      1768\n",
      "   macro avg       0.57      0.71      0.45      1768\n",
      "weighted avg       0.91      0.52      0.60      1768\n",
      "\n",
      "\n",
      "--- Prefix 18 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.42      0.59      1283\n",
      "           1       0.14      0.94      0.24       129\n",
      "\n",
      "    accuracy                           0.47      1412\n",
      "   macro avg       0.56      0.68      0.42      1412\n",
      "weighted avg       0.91      0.47      0.56      1412\n",
      "\n",
      "\n",
      "--- Prefix 19 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.39      0.56      1062\n",
      "           1       0.12      0.91      0.21        94\n",
      "\n",
      "    accuracy                           0.44      1156\n",
      "   macro avg       0.55      0.65      0.39      1156\n",
      "weighted avg       0.91      0.44      0.53      1156\n",
      "\n",
      "\n",
      "--- Prefix 20 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.37      0.54       845\n",
      "           1       0.14      0.88      0.24        97\n",
      "\n",
      "    accuracy                           0.43       942\n",
      "   macro avg       0.55      0.63      0.39       942\n",
      "weighted avg       0.88      0.43      0.51       942\n",
      "\n",
      "\n",
      "--- Prefix 21 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.33      0.49       679\n",
      "           1       0.11      0.85      0.19        65\n",
      "\n",
      "    accuracy                           0.37       744\n",
      "   macro avg       0.53      0.59      0.34       744\n",
      "weighted avg       0.88      0.37      0.46       744\n",
      "\n",
      "\n",
      "--- Prefix 22 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.32      0.48       565\n",
      "           1       0.08      0.89      0.14        36\n",
      "\n",
      "    accuracy                           0.36       601\n",
      "   macro avg       0.53      0.61      0.31       601\n",
      "weighted avg       0.92      0.36      0.46       601\n",
      "\n",
      "\n",
      "--- Prefix 23 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.28      0.44       436\n",
      "           1       0.11      0.80      0.19        46\n",
      "\n",
      "    accuracy                           0.33       482\n",
      "   macro avg       0.52      0.54      0.31       482\n",
      "weighted avg       0.85      0.33      0.41       482\n",
      "\n",
      "\n",
      "--- Prefix 24 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.30      0.46       371\n",
      "           1       0.08      0.83      0.15        29\n",
      "\n",
      "    accuracy                           0.34       400\n",
      "   macro avg       0.52      0.56      0.30       400\n",
      "weighted avg       0.89      0.34      0.43       400\n",
      "\n",
      "\n",
      "--- Prefix 25 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.28      0.44       291\n",
      "           1       0.10      0.96      0.19        25\n",
      "\n",
      "    accuracy                           0.34       316\n",
      "   macro avg       0.55      0.62      0.31       316\n",
      "weighted avg       0.92      0.34      0.42       316\n",
      "\n",
      "\n",
      "--- Prefix 26 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.41       228\n",
      "           1       0.11      1.00      0.19        20\n",
      "\n",
      "    accuracy                           0.31       248\n",
      "   macro avg       0.55      0.63      0.30       248\n",
      "weighted avg       0.93      0.31      0.39       248\n",
      "\n",
      "\n",
      "--- Prefix 27 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.25      0.39       185\n",
      "           1       0.10      0.89      0.18        18\n",
      "\n",
      "    accuracy                           0.31       203\n",
      "   macro avg       0.53      0.57      0.29       203\n",
      "weighted avg       0.88      0.31      0.38       203\n",
      "\n",
      "\n",
      "--- Prefix 28 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.19      0.32       148\n",
      "           1       0.09      0.92      0.17        13\n",
      "\n",
      "    accuracy                           0.25       161\n",
      "   macro avg       0.53      0.56      0.24       161\n",
      "weighted avg       0.89      0.25      0.30       161\n",
      "\n",
      "\n",
      "--- Prefix 29 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33       120\n",
      "           1       0.09      1.00      0.17        10\n",
      "\n",
      "    accuracy                           0.26       130\n",
      "   macro avg       0.55      0.60      0.25       130\n",
      "weighted avg       0.93      0.26      0.32       130\n",
      "\n",
      "\n",
      "--- Prefix 30 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.20      0.33        89\n",
      "           1       0.11      0.90      0.20        10\n",
      "\n",
      "    accuracy                           0.27        99\n",
      "   macro avg       0.53      0.55      0.27        99\n",
      "weighted avg       0.86      0.27      0.32        99\n",
      "\n",
      "\n",
      "--- Prefix 31 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.15      0.25        68\n",
      "           1       0.11      0.70      0.19        10\n",
      "\n",
      "    accuracy                           0.22        78\n",
      "   macro avg       0.44      0.42      0.22        78\n",
      "weighted avg       0.68      0.22      0.24        78\n",
      "\n",
      "\n",
      "--- Prefix 32 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.12      0.22        65\n",
      "           1       0.02      0.50      0.03         2\n",
      "\n",
      "    accuracy                           0.13        67\n",
      "   macro avg       0.45      0.31      0.12        67\n",
      "weighted avg       0.86      0.13      0.21        67\n",
      "\n",
      "\n",
      "--- Prefix 33 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.18      0.30        51\n",
      "           1       0.12      0.86      0.22         7\n",
      "\n",
      "    accuracy                           0.26        58\n",
      "   macro avg       0.51      0.52      0.26        58\n",
      "weighted avg       0.81      0.26      0.29        58\n",
      "\n",
      "\n",
      "--- Prefix 34 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.28        43\n",
      "           1       0.05      1.00      0.10         2\n",
      "\n",
      "    accuracy                           0.20        45\n",
      "   macro avg       0.53      0.58      0.19        45\n",
      "weighted avg       0.96      0.20      0.27        45\n",
      "\n",
      "\n",
      "--- Prefix 35 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.13      0.23        31\n",
      "           1       0.16      1.00      0.27         5\n",
      "\n",
      "    accuracy                           0.25        36\n",
      "   macro avg       0.58      0.56      0.25        36\n",
      "weighted avg       0.88      0.25      0.23        36\n",
      "\n",
      "\n",
      "--- Prefix 36 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29        30\n",
      "           1       0.11      1.00      0.19         3\n",
      "\n",
      "    accuracy                           0.24        33\n",
      "   macro avg       0.55      0.58      0.24        33\n",
      "weighted avg       0.92      0.24      0.28        33\n",
      "\n",
      "\n",
      "--- Prefix 37 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.16        23\n",
      "           1       0.19      1.00      0.32         5\n",
      "\n",
      "    accuracy                           0.25        28\n",
      "   macro avg       0.60      0.54      0.24        28\n",
      "weighted avg       0.86      0.25      0.19        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) Summarize\n",
    "reports_df = pd.DataFrame(online_ad_reports)\n",
    "for p in prefix_range:\n",
    "    sub = reports_df[reports_df[\"prefix\"] == p]\n",
    "    if not sub.empty:\n",
    "        print(f\"\\n--- Prefix {p} ---\")\n",
    "        print(classification_report(\n",
    "            sub[\"true_noise\"], sub[\"pred_ad_anom\"], zero_division=0\n",
    "        ))\n",
    "reports_df \n",
    "reports_df.to_csv('../result/%s_classifier_lstm.csv'%(dataset), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
