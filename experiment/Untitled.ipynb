{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f49f83-8701-4cd0-9db8-1fea86867c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d912d7-b9e8-48e3-a355-783d5b90cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from collections import Counter, defaultdict, deque\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, log_loss, roc_auc_score\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59cd5088-605e-4079-9d76-e64cc4c07c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# suppress only the “y_pred values do not sum to one” warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*y_pred values do not sum to one.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b0bf26-dcbe-4525-a672-dcf55811171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = -∑_c [1{c = y_true_i} · log P_model(c | x_i)]\n",
    "    If the true label isn’t in model.classes_, returns a default high loss.\n",
    "    Works for any len(x_test) >= 1, including the single-class case.\n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(x_test)\n",
    "    default = log_loss([[1, 0]], [[0, 1]]) + 1  # fallback loss\n",
    "\n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        classes = model.classes_\n",
    "\n",
    "        # if only one class in the model\n",
    "        if sample_probs.size == 1:\n",
    "            if classes[0] == true_label:\n",
    "                losses.append(0.0)  # perfect prediction\n",
    "            else:\n",
    "                losses.append(default)\n",
    "            continue\n",
    "\n",
    "        # find index of the true label\n",
    "        idx_arr = np.where(classes == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(default)\n",
    "        else:\n",
    "            y_true_onehot = np.zeros_like(sample_probs)\n",
    "            y_true_onehot[idx_arr[0]] = 1\n",
    "\n",
    "            # normalize just in case\n",
    "            sample_probs = sample_probs / sample_probs.sum()\n",
    "            y_true_onehot = y_true_onehot / y_true_onehot.sum()\n",
    "\n",
    "            loss_i = log_loss([y_true_onehot], [sample_probs])\n",
    "            losses.append(loss_i)\n",
    "\n",
    "    return np.array(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42a3934-19fa-4e99-8443-c69886c0a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = 1 - P_model(y_true_i | x_i)\n",
    "    If the true label isn’t in model.classes_, we return 1.1 as before.\n",
    "    Works for any len(x_test) >= 1.\n",
    "    \"\"\"\n",
    "    # predict_proba returns shape (n_samples, n_classes)\n",
    "    probs = model.predict_proba(x_test)\n",
    "    \n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        # find index of the true label in model.classes_\n",
    "        idx_arr = np.where(model.classes_ == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(1.1)\n",
    "        else:\n",
    "            col_index = idx_arr[0]\n",
    "            losses.append(1 - sample_probs[col_index])\n",
    "    \n",
    "    return np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1d2ab2-5635-4821-9f65-b93c130e72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_transform_target(encoder, targets, unknown_value=-1):\n",
    "    classes = set(encoder.classes_)\n",
    "    transformed = []\n",
    "    for t in targets:\n",
    "        if t in classes:\n",
    "            transformed.append(encoder.transform([t])[0])\n",
    "        else:\n",
    "            transformed.append(unknown_value)\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c000cd-3056-4670-bd35-fe5b25b02344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_loss(normal_loss_value, cross_entropy_loss_value):\n",
    "    normal_loss_dist = []\n",
    "    cross_loss_dist = []\n",
    "    for pos, prediction in  enumerate(normal_loss_value):\n",
    "        if prediction != 1:\n",
    "            cross_loss_dist.append(cross_entropy_loss_value[pos])\n",
    "            normal_loss_dist.append(prediction)\n",
    "\n",
    "    return np.array(normal_loss_dist), np.array(cross_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed27071-1817-417d-8a52-9ec2fc8130bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_cls_result(classification_result):\n",
    "    \n",
    "    for i in classification_result.keys():\n",
    "        print(i, classification_result[i].keys())\n",
    "\n",
    "        if '1' not in classification_result[i].keys():\n",
    "            classification_result[i]['1'] = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0.0}\n",
    "    return classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26c3531-0049-454e-bb79-041b1f84ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_min_anomalies(gt_labels, num_samples=10, min_anomalies=3, random_state=None):\n",
    "    \"\"\"\n",
    "    Randomly sample `num_samples` indices from gt_labels (0/1 array),\n",
    "    ensuring at least `min_anomalies` true-anomaly (1) indices are included.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt_labels : array-like, shape (n_samples,)\n",
    "        Ground-truth labels (0 = normal, 1 = anomaly).\n",
    "    num_samples : int, default=10\n",
    "        Total number of indices to sample.\n",
    "    min_anomalies : int, default=3\n",
    "        Minimum number of anomaly indices to include.\n",
    "    random_state : int or None\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_indices : ndarray, shape (<= num_samples,)\n",
    "        Shuffled indices, containing at least `min_anomalies` anomalies\n",
    "        (or as many as available if fewer exist).\n",
    "    \"\"\"\n",
    "    gt_labels = np.asarray(gt_labels)\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # locate anomaly vs normal indices\n",
    "    anomaly_idx = np.where(gt_labels == 1)[0]\n",
    "    normal_idx  = np.where(gt_labels == 0)[0]\n",
    "\n",
    "    # determine how many anomalies we can pick\n",
    "    n_anom = min(len(anomaly_idx), min_anomalies)\n",
    "    # pick anomalies without replacement\n",
    "    picked_anom = np.random.choice(anomaly_idx, n_anom, replace=False) if n_anom > 0 else np.array([], dtype=int)\n",
    "\n",
    "    # fill the rest from normals\n",
    "    n_normal = num_samples - n_anom\n",
    "    n_normal = min(n_normal, len(normal_idx))\n",
    "    picked_norm = np.random.choice(normal_idx, n_normal, replace=False) if n_normal > 0 else np.array([], dtype=int)\n",
    "\n",
    "    # combine and shuffle\n",
    "    selected = np.concatenate([picked_anom, picked_norm])\n",
    "    np.random.shuffle(selected)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32ac7543-18d0-4c97-a743-de300f30d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_gap(losses):\n",
    "    if len(losses) ==1:\n",
    "        return 0, -1\n",
    "    else:\n",
    "        y = sorted(losses, reverse=True)\n",
    "        diffs = abs(np.diff(y))\n",
    "        idx = np.argmax(diffs) + 1   # +1 because diffs[i] = y[i+1]-y[i]\n",
    "    return idx, y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0b964c-9ece-41c3-a46d-a0adb3ae026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap_cutoff(rf, Xw, yw):\n",
    "    \"\"\"\n",
    "    Given a fitted RandomForest `rf` and its training data (Xw, yw),\n",
    "    compute cross‐entropy losses for each sample. If there are fewer than\n",
    "    2 samples, just return the single loss (or 0 if somehow empty). Otherwise\n",
    "    use find_largest_gap to get a gap‐based cutoff.\n",
    "    \"\"\"\n",
    "    ce_losses = cross_entropy_loss(rf, Xw, yw)\n",
    "    n = ce_losses.size\n",
    "\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    if n == 1:\n",
    "        # Only one loss → no “gap” to find. Use the single value as cutoff.\n",
    "        return float(ce_losses[0])\n",
    "\n",
    "    # Now we have ≥2 losses; sorting in descending order ensures diff is nonempty\n",
    "    _, cutoff_gap = find_largest_gap(ce_losses)\n",
    "    return cutoff_gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e21ff1-39f9-4403-a8aa-91559aa40c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_sampling_balanced(model, x_pool, y_pool, k=20):\n",
    "    \"\"\"\n",
    "    Unlabeled pool(x_pool)에서 margin이 가장 작은 순으로 정렬한 뒤,\n",
    "    anomaly:normal = 1:1 비율로 총 k개 인덱스 반환.\n",
    "    \n",
    "    Args:\n",
    "        model:        predict_proba 지원하는 classifier\n",
    "        x_pool:       np.array or DataFrame, shape (n_samples, n_features)\n",
    "        y_pool:       1D array-like of true labels (0=normal, 1=anomaly)\n",
    "        k:            total 선택 개수 (짝수 권장)\n",
    "    Returns:\n",
    "        selected_idx: np.array of length k\n",
    "    \"\"\"\n",
    "    # 1) margin 계산\n",
    "    probs = model.predict_proba(x_pool)                       # (n_samples, n_classes)\n",
    "    # 내림차순 정렬된 확률\n",
    "    sorted_probs = -np.sort(-probs, axis=1)\n",
    "    top1 = sorted_probs[:, 0]\n",
    "    top2 = sorted_probs[:, 1] if sorted_probs.shape[1] > 1 else np.zeros_like(top1)\n",
    "    margins = top1 - top2\n",
    "\n",
    "    # 2) margin 오름차순 인덱스\n",
    "    idx_sorted = np.argsort(margins)\n",
    "\n",
    "    # 3) 클래스별 분리\n",
    "    anomaly_idxs = [i for i in idx_sorted if y_pool[i] == 1]\n",
    "    normal_idxs  = [i for i in idx_sorted if y_pool[i] == 0]\n",
    "\n",
    "    # 4) 반반씩 선택 (부족하면 있는 만큼만)\n",
    "    half = k // 2\n",
    "    sel_anom = anomaly_idxs[:half]\n",
    "    sel_norm = normal_idxs[:k - len(sel_anom)]\n",
    "\n",
    "    # 만약 normal도 부족하면 anomaly로 채우기(또는 그 반대)\n",
    "    if len(sel_norm) < (k - half):\n",
    "        sel_norm += normal_idxs[:(k - len(sel_anom))]  # 재사용 or 남은 idx\n",
    "    if len(sel_anom) < half:\n",
    "        sel_anom += anomaly_idxs[:(k - len(sel_norm))]\n",
    "\n",
    "    # 5) 합치고 shuffle\n",
    "    selected_idx = np.array(sel_anom + sel_norm)\n",
    "    np.random.shuffle(selected_idx)\n",
    "    return selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e30d87-ab83-412a-b90f-16b79d753033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125_noise.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Read and Process the Data\n",
    "# ----------------------------\n",
    "dataset = '0.125_noise.csv'\n",
    "df = pd.read_csv(\"../data/%s\" % (dataset))\n",
    "df = df.sort_values(by='Timestamp')\n",
    "# Process the 'noise' column:\n",
    "# - If NaN, assume Normal (0).\n",
    "# - Otherwise, treat True/1/'True' as anomaly (1); everything else as Normal (0).\n",
    "df['noise'] = df['noise'].fillna(0).apply(lambda x: 1 if (x == True or x == 1 or x == 'True' or x=='true') else 0)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "print(dataset)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Prefixes & global window settings\n",
    "# ----------------------------\n",
    "prefix_range = range(2, 35)   # prefix lengths 2..15\n",
    "WINDOW_EVENTS = 2500          # keep the last 2 500 raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d1674e1-bbc7-49c6-b031-ad4665e92d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Pre‐fit encoders for each prefix’s NAP ---\n",
    "all_acts = df[\"Activity\"].unique()\n",
    "ohe_nap  = {p: OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "              .fit(np.array([[a]*(p-1) for a in all_acts]))\n",
    "            for p in prefix_range}\n",
    "le_nap   = {p: LabelEncoder().fit(all_acts) for p in prefix_range}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a665f0-33e6-41a4-b426-3bf485372e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 4) Buffers & State Initialization\n",
    "# ----------------------------\n",
    "# Global sliding window of the last WINDOW_EVENTS prefix‐events\n",
    "global_events = deque(maxlen=WINDOW_EVENTS)\n",
    "\n",
    "# Per‐prefix buffers (unbounded; we’ll evict manually)\n",
    "buffers = {}\n",
    "for p in prefix_range:\n",
    "    buffers[p] = {\n",
    "        \"raw_feats\":      deque(),\n",
    "        \"raw_tgts\":       deque(),\n",
    "        \"X\":               deque(),\n",
    "        \"y\":               deque(),\n",
    "        \"noise\":           deque(),\n",
    "        \"model\":          None,\n",
    "        \"filled\":         False,\n",
    "        \"cutoff\":         None\n",
    "    }\n",
    "\n",
    "case_events      = defaultdict(list)\n",
    "detect_pool      = []   # list of dicts for AD training\n",
    "anom_clf         = None\n",
    "enc_ad           = None\n",
    "max_prob_ad      = 0\n",
    "max_pfx          = max(prefix_range) - 1  # for padding raw_feats\n",
    "\n",
    "online_nap_reports = []\n",
    "online_ad_reports  = []\n",
    "\n",
    "# Build a vocabulary (activity→index) for LSTM sequencing\n",
    "act2idx = {act: i + 1 for i, act in enumerate(all_acts)}\n",
    "vocab_size = len(act2idx) + 1  # +1 for padding index=0\n",
    "\n",
    "# ----------------------------\n",
    "# 4.5) Helper: compute gap‐based CE cutoff\n",
    "# ----------------------------\n",
    "def compute_gap_cutoff(rf, Xw, yw):\n",
    "    ce_losses = cross_entropy_loss(rf, Xw, yw)\n",
    "    n = ce_losses.size\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    if n == 1:\n",
    "        return float(ce_losses[0])\n",
    "    # find_largest_gap returns (idx, cutoff)\n",
    "    _, cutoff_gap = find_largest_gap(ce_losses)\n",
    "    return cutoff_gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c19a106-1cb8-4637-be10-4a4aff00eca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/83183 rows (1.2%)\n",
      "Processed 2000/83183 rows (2.4%)\n",
      "Processed 3000/83183 rows (3.6%)\n",
      "Processed 4000/83183 rows (4.8%)\n",
      "Processed 5000/83183 rows (6.0%)\n",
      "Processed 6000/83183 rows (7.2%)\n",
      "Processed 7000/83183 rows (8.4%)\n",
      "Processed 8000/83183 rows (9.6%)\n",
      "Processed 9000/83183 rows (10.8%)\n",
      "Processed 10000/83183 rows (12.0%)\n",
      "Processed 11000/83183 rows (13.2%)\n",
      "Processed 12000/83183 rows (14.4%)\n",
      "Processed 13000/83183 rows (15.6%)\n",
      "Processed 14000/83183 rows (16.8%)\n",
      "Processed 15000/83183 rows (18.0%)\n",
      "Processed 16000/83183 rows (19.2%)\n",
      "Processed 17000/83183 rows (20.4%)\n",
      "Processed 18000/83183 rows (21.6%)\n",
      "Processed 19000/83183 rows (22.8%)\n",
      "Processed 20000/83183 rows (24.0%)\n",
      "Processed 21000/83183 rows (25.2%)\n",
      "Processed 22000/83183 rows (26.4%)\n",
      "Processed 23000/83183 rows (27.6%)\n",
      "Processed 24000/83183 rows (28.9%)\n",
      "Processed 25000/83183 rows (30.1%)\n",
      "Processed 26000/83183 rows (31.3%)\n",
      "Processed 27000/83183 rows (32.5%)\n",
      "Processed 28000/83183 rows (33.7%)\n",
      "Processed 29000/83183 rows (34.9%)\n",
      "Processed 30000/83183 rows (36.1%)\n",
      "Processed 31000/83183 rows (37.3%)\n",
      "Processed 32000/83183 rows (38.5%)\n",
      "Processed 33000/83183 rows (39.7%)\n",
      "Processed 34000/83183 rows (40.9%)\n",
      "Processed 35000/83183 rows (42.1%)\n",
      "Processed 36000/83183 rows (43.3%)\n",
      "Processed 37000/83183 rows (44.5%)\n",
      "Processed 38000/83183 rows (45.7%)\n",
      "Processed 39000/83183 rows (46.9%)\n",
      "Processed 40000/83183 rows (48.1%)\n",
      "Processed 41000/83183 rows (49.3%)\n",
      "Processed 42000/83183 rows (50.5%)\n",
      "Processed 43000/83183 rows (51.7%)\n",
      "Processed 44000/83183 rows (52.9%)\n",
      "Processed 45000/83183 rows (54.1%)\n",
      "Processed 46000/83183 rows (55.3%)\n",
      "Processed 47000/83183 rows (56.5%)\n",
      "Processed 48000/83183 rows (57.7%)\n",
      "Processed 49000/83183 rows (58.9%)\n",
      "Processed 50000/83183 rows (60.1%)\n",
      "Processed 51000/83183 rows (61.3%)\n",
      "Processed 52000/83183 rows (62.5%)\n",
      "Processed 53000/83183 rows (63.7%)\n",
      "Processed 54000/83183 rows (64.9%)\n",
      "Processed 55000/83183 rows (66.1%)\n",
      "Processed 56000/83183 rows (67.3%)\n",
      "Processed 57000/83183 rows (68.5%)\n",
      "Processed 58000/83183 rows (69.7%)\n",
      "Processed 59000/83183 rows (70.9%)\n",
      "Processed 60000/83183 rows (72.1%)\n",
      "Processed 61000/83183 rows (73.3%)\n",
      "Processed 62000/83183 rows (74.5%)\n",
      "Processed 63000/83183 rows (75.7%)\n",
      "Processed 64000/83183 rows (76.9%)\n",
      "Processed 65000/83183 rows (78.1%)\n",
      "Processed 66000/83183 rows (79.3%)\n",
      "Processed 67000/83183 rows (80.5%)\n",
      "Processed 68000/83183 rows (81.7%)\n",
      "Processed 69000/83183 rows (82.9%)\n",
      "Processed 70000/83183 rows (84.2%)\n",
      "Processed 71000/83183 rows (85.4%)\n",
      "Processed 72000/83183 rows (86.6%)\n",
      "Processed 73000/83183 rows (87.8%)\n",
      "Processed 74000/83183 rows (89.0%)\n",
      "Processed 75000/83183 rows (90.2%)\n",
      "Processed 76000/83183 rows (91.4%)\n",
      "Processed 77000/83183 rows (92.6%)\n",
      "Processed 78000/83183 rows (93.8%)\n",
      "Processed 79000/83183 rows (95.0%)\n",
      "Processed 80000/83183 rows (96.2%)\n",
      "Processed 81000/83183 rows (97.4%)\n",
      "Processed 82000/83183 rows (98.6%)\n",
      "Processed 83000/83183 rows (99.8%)\n",
      "Processed 83183/83183 rows (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Streaming loop with NAP + AD\n",
    "# ----------------------------\n",
    "total = len(df)\n",
    "# single sliding window of the last WINDOW_EVENTS raw events\n",
    "global_update_counter = 0\n",
    "global_retrain_batch = WINDOW_EVENTS // 2   # 1250\n",
    "known_nap_anomalies = set() \n",
    "for i, (_, row) in enumerate(df.iterrows(), start=1):\n",
    "    # progress logging\n",
    "    if i % 1000 == 0 or i == total:\n",
    "        pct = i / total * 100\n",
    "        print(f\"Processed {i}/{total} rows ({pct:.1f}%)\")\n",
    "    global_update_counter += 1\n",
    "    \n",
    "    cid = row[\"Case ID\"]\n",
    "    case_events[cid].append(row)\n",
    "    cur_len = len(case_events[cid])\n",
    "\n",
    "   # Only process when a case first reaches prefix length p\n",
    "    for p in prefix_range:\n",
    "        if cur_len != p:\n",
    "            continue\n",
    "\n",
    "        # 5.1) Build current sample\n",
    "        group      = case_events[cid]\n",
    "        feats      = [e.Activity for e in group[: p - 1]]\n",
    "        target_act = group[p - 1].Activity\n",
    "        noise_flag = group[p - 1].noise\n",
    "\n",
    "        buf = buffers[p]\n",
    "\n",
    "        # --- Slide the global window: peek dropped if full ---\n",
    "        dropped = None\n",
    "        if len(global_events) == WINDOW_EVENTS:\n",
    "            dropped = global_events[0]  # will be auto-evicted on append()\n",
    "\n",
    "        # Transform features/target for NAP\n",
    "        Xp_vec = ohe_nap[p].transform([feats]).ravel()\n",
    "        yp     = le_nap[p].transform([target_act])[0]\n",
    "\n",
    "        # Append to global_events: store (prefix, X_vec, y_label, noise, raw_feats, raw_target)\n",
    "        global_events.append((p, Xp_vec, yp, noise_flag, feats, target_act))\n",
    "\n",
    "        # Append to this prefix’s buffers (unbounded deques)\n",
    "        buf[\"raw_feats\"].append(feats)\n",
    "        buf[\"raw_tgts\"].append(target_act)\n",
    "        buf[\"X\"].append(Xp_vec)\n",
    "        buf[\"y\"].append(yp)\n",
    "        buf[\"noise\"].append(noise_flag)\n",
    "\n",
    "        # If something was dropped from global_events, evict it from its prefix buffer\n",
    "        if dropped is not None:\n",
    "            old_p, old_Xp, old_yp, old_noise, old_feats, old_tgt = dropped\n",
    "            old_buf = buffers[old_p]\n",
    "            if old_buf[\"X\"]:\n",
    "                old_buf[\"raw_feats\"].popleft()\n",
    "                old_buf[\"raw_tgts\"].popleft()\n",
    "                old_buf[\"X\"].popleft()\n",
    "                old_buf[\"y\"].popleft()\n",
    "                old_buf[\"noise\"].popleft()\n",
    "\n",
    "        # --- 5.2) Initial NAP training (once we have the first sample) ---\n",
    "        if buf[\"model\"] is None:\n",
    "            Xw = np.vstack(buf[\"X\"])\n",
    "            yw = np.array(buf[\"y\"])\n",
    "            \n",
    "            # 5.2a) Bootstrap the AD pool\n",
    "            MAX_ANOM = 25\n",
    "            TOTAL_SAMPLES = 50\n",
    "\n",
    "            anom_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 1]\n",
    "            norm_idxs = [idx for idx, flag in enumerate(buf[\"noise\"]) if flag == 0]\n",
    "            \n",
    "            n_anom = min(MAX_ANOM, len(anom_idxs))\n",
    "            sel_anom = random.sample(anom_idxs, n_anom) if n_anom > 0 else []\n",
    "            needed_norm = TOTAL_SAMPLES - n_anom\n",
    "            sel_norm = (random.sample(norm_idxs, needed_norm)\n",
    "                        if len(norm_idxs) >= needed_norm\n",
    "                        else norm_idxs)\n",
    "            \n",
    "            sel_idxs = sel_anom + sel_norm\n",
    "            random.shuffle(sel_idxs)\n",
    "            sel_idxs = sample_with_min_anomalies(buf[\"noise\"], num_samples=TOTAL_SAMPLES, min_anomalies=MAX_ANOM, random_state=None)\n",
    "\n",
    "            for idx in sel_idxs:\n",
    "                if buf[\"noise\"][idx] == 1:\n",
    "                    raw_feat = tuple(buf[\"raw_feats\"][idx])\n",
    "                    raw_tgt = buf[\"raw_tgts\"][idx]\n",
    "                    known_nap_anomalies.add((p, raw_feat, raw_tgt))\n",
    "                    \n",
    "            normal_indices = [\n",
    "                i for i in range(len(buf[\"X\"]))\n",
    "                if (p, tuple(buf[\"raw_feats\"][0][i]), buf[\"raw_tgts\"][0][i]) not in known_nap_anomalies\n",
    "            ]\n",
    "\n",
    "            Xw = np.vstack([buf[\"X\"][i] for i in normal_indices])\n",
    "            yw = np.array([buf[\"y\"][i] for i in normal_indices])\n",
    "            \n",
    "            if len(normal_indices) == 0:\n",
    "                continue\n",
    "    \n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=100, random_state=42, n_jobs=-1\n",
    "            )\n",
    "            rf.fit(Xw, yw)\n",
    "            \n",
    "            feats_i = buf[\"raw_feats\"][idx]\n",
    "            Xp_i = ohe_nap[p].transform([feats_i]).ravel().reshape(1, -1)\n",
    "            \n",
    "            # Compute CE‐loss cutoff (gap‐based) on current buffer\n",
    "            cutoff = compute_gap_cutoff(rf, Xw, yw)\n",
    "\n",
    "            buf[\"model\"]  = rf\n",
    "            buf[\"filled\"] = True\n",
    "            buf[\"cutoff\"] = cutoff\n",
    "\n",
    "            for idx in sel_idxs:\n",
    "                prob_vec = rf.predict_proba(buf[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                ce0      = cross_entropy_loss(rf, buf[\"X\"][idx].reshape(1, -1), [buf[\"y\"][idx]])[0]\n",
    "                detect_pool.append({\n",
    "                    \"raw_feats\": buf[\"raw_feats\"][idx],\n",
    "                    \"target\":    buf[\"raw_tgts\"][idx],\n",
    "                    \"prefix\":    p,\n",
    "                    \"prob\":      prob_vec,\n",
    "                    \"ce_loss\":   ce0,\n",
    "                    \"anomaly\":   buf[\"noise\"][idx]\n",
    "                })\n",
    "                    \n",
    "            # print(f\"Prefix {p} NAP initial train (buffer size = {len(buf['X'])})\")\n",
    "\n",
    "\n",
    "            # 5.2b) Train the AD classifier if we have ≥20 samples\n",
    "            cat_rows = []\n",
    "            for d in detect_pool:\n",
    "                row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                cat_rows.append(row_cat)\n",
    "            enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "            X_cat = enc_ad.transform(cat_rows)\n",
    "\n",
    "            max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "            prob_mat = [\n",
    "                d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                for d in detect_pool\n",
    "            ]\n",
    "            ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "            X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "            y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "            X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "            # anom_clf = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "            # anom_clf.fit(X_ad, y_ad)\n",
    "            # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "            #     random_state=42).fit(X_ad, y_ad)\n",
    "            anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.1, eval_metric='logloss',\n",
    "                                     random_state=42).fit(X_ad, y_ad)\n",
    "\n",
    "            # print(f\"Prefix {p} AD initial train on {len(detect_pool)} samples\")\n",
    "\n",
    "            AD_CAT_FEATS = X_cat.shape[1]\n",
    "            AD_NUM_FEATS = X_num.shape[1]\n",
    "            # Skip further processing of this new event\n",
    "    \n",
    "\n",
    "        # --- 5.3) Prequential NAP prediction & store ---\n",
    "        rf   = buf[\"model\"]\n",
    "        Xp   = Xp_vec.reshape(1, -1)\n",
    "        y_sp = yp\n",
    "        cutoff_nap = buf[\"cutoff\"]\n",
    "\n",
    "        ce_cur = cross_entropy_loss(rf, Xp, [y_sp])[0]\n",
    "        pred_nap_anom = int(ce_cur > cutoff_nap)\n",
    "\n",
    "        online_nap_reports.append({\n",
    "            \"i\":             i,\n",
    "            \"prefix\":        p,\n",
    "            \"case_id\":       cid,\n",
    "            \"true_noise\":    noise_flag,\n",
    "            \"pred_nap_anom\": pred_nap_anom,\n",
    "            \"cutoff\":        cutoff_nap\n",
    "        })\n",
    "\n",
    "        # --- 5.4) Global retrain trigger (increment once per prefix-event) ---\n",
    "        if global_update_counter >= global_retrain_batch:\n",
    "            # print(\"=== Global retrain of all prefix NAP models ===\")\n",
    "\n",
    "            # Retrain each NAP model on its current buffer, recompute cutoff, \n",
    "            # and sample AD points\n",
    "            for q in prefix_range:\n",
    "                buf_q = buffers[q]\n",
    "                if len(buf_q[\"X\"]) == 0:\n",
    "                    continue\n",
    "                                        \n",
    "                Xw = np.vstack(buf_q[\"X\"])\n",
    "                yw = np.array(buf_q[\"y\"])\n",
    "                \n",
    "                anom_idxs = [idx for idx, flag in enumerate(buf_q[\"noise\"]) if flag == 1]\n",
    "                norm_idxs = [idx for idx, flag in enumerate(buf_q[\"noise\"]) if flag == 0]\n",
    "            \n",
    "                n_anom = min(MAX_ANOM, len(anom_idxs))\n",
    "                sel_anom = random.sample(anom_idxs, n_anom) if n_anom > 0 else []\n",
    "                needed_norm = TOTAL_SAMPLES - n_anom\n",
    "                sel_norm = (random.sample(norm_idxs, needed_norm)\n",
    "                            if len(norm_idxs) >= needed_norm\n",
    "                            else norm_idxs)\n",
    "                \n",
    "                sel_idxs = sel_anom + sel_norm\n",
    "                random.shuffle(sel_idxs)\n",
    "                sel_idxs = sample_with_min_anomalies(buf_q[\"noise\"], num_samples=TOTAL_SAMPLES, min_anomalies=MAX_ANOM, random_state=None)\n",
    "\n",
    "                for idx in sel_idxs:\n",
    "                    if buf_q[\"noise\"][idx] == 1:\n",
    "                        raw_feat = tuple(buf_q[\"raw_feats\"][idx])\n",
    "                        raw_tgt = buf_q[\"raw_tgts\"][idx]\n",
    "                        known_nap_anomalies.add((q, raw_feat, raw_tgt))\n",
    "                normal_indices = [\n",
    "                    i for i in range(len(buf_q[\"X\"]))\n",
    "                    if (p, tuple(buf_q[\"raw_feats\"][i]), buf_q[\"raw_tgts\"][i]) not in known_nap_anomalies\n",
    "                ]\n",
    "\n",
    "                if len(normal_indices) !=0:\n",
    "                    Xw = np.vstack([buf_q[\"X\"][i] for i in normal_indices])\n",
    "                    yw = np.array([buf_q[\"y\"][i] for i in normal_indices])     \n",
    "                    \n",
    "                    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                    rf.fit(Xw, yw)\n",
    "                buf_q[\"model\"] = rf\n",
    "\n",
    "                # Recompute CE‐loss cutoff (gap-based)\n",
    "                # cutoff_q = compute_gap_cutoff(rf, Xw, yw)\n",
    "                # buf_q[\"cutoff\"] = cutoff_q\n",
    "                # print(f\"  Recomputed cutoff for prefix {q} (buffer size = {len(buf_q['X'])})\")\n",
    "            \n",
    "                for idx in sel_idxs:\n",
    "                    prob_vec = rf.predict_proba(buf_q[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                    ce0      = cross_entropy_loss(rf, buf_q[\"X\"][idx].reshape(1, -1), [buf_q[\"y\"][idx]])[0]\n",
    "                    detect_pool.append({\n",
    "                        \"raw_feats\": buf_q[\"raw_feats\"][idx],\n",
    "                        \"target\":    buf_q[\"raw_tgts\"][idx],\n",
    "                        \"prefix\":    q,\n",
    "                        \"prob\":      prob_vec,\n",
    "                        \"ce_loss\":   ce0,\n",
    "                        \"anomaly\":   buf_q[\"noise\"][idx]\n",
    "                    })\n",
    "                    \n",
    "            # Retrain AD classifier if we have ≥20 samples\n",
    "            if len(detect_pool) >= 20:\n",
    "                cat_rows = []\n",
    "                for d in detect_pool:\n",
    "                    row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                    row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                    cat_rows.append(row_cat)\n",
    "                enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "                X_cat = enc_ad.transform(cat_rows)\n",
    "                max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "                prob_mat = [\n",
    "                    d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                    for d in detect_pool\n",
    "                ]\n",
    "                ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "                X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "                y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "                X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "                # anom_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                # anom_clf.fit(X_ad, y_ad)\n",
    "                AD_CAT_FEATS = X_cat.shape[1]\n",
    "                AD_NUM_FEATS = X_num.shape[1]\n",
    "                                \n",
    "                # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "                #     random_state=42).fit(X_ad, y_ad)\n",
    "                anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.1, eval_metric='logloss',\n",
    "                                         random_state=42).fit(X_ad, y_ad)\n",
    "                # print(f\"  AD retrain on {len(detect_pool)} samples\")\n",
    "                # detect_pool = []\n",
    "            global_update_counter = 0\n",
    "\n",
    "        # --- 5.5) Prequential AD classification for current event ---\n",
    "        if anom_clf is not None:\n",
    "            # Build AD feature vector: categorical + numeric\n",
    "            row_cat = feats + [None] * (max_pfx - len(feats)) + [p, y_sp]\n",
    "            # 1) Categorical part\n",
    "            Xc = enc_ad.transform([row_cat])\n",
    "            if Xc.shape[1] != AD_CAT_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_CAT_FEATS} cat features, got {Xc.shape[1]}\")\n",
    "            \n",
    "            # 2) Numeric part (prob_vector + ce_loss)\n",
    "            model = buffers[p]['model']\n",
    "            pvec = model.predict_proba(Xp)[0].tolist()\n",
    "            pad_len = AD_NUM_FEATS - 1\n",
    "            pvec_padded = pvec + [0.0] * (pad_len - len(pvec))\n",
    "            Xn = np.array([pvec_padded + [ce_cur]])\n",
    "            if Xn.shape[1] != AD_NUM_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_NUM_FEATS} num features, got {Xn.shape[1]}\")\n",
    "            \n",
    "            # 3) Combine & predict\n",
    "            Xa = np.hstack([Xc, Xn])\n",
    "            pred_ad = anom_clf.predict(Xa)[0]\n",
    "            prob_ad = anom_clf.predict_proba(Xa)[0, 1]\n",
    "            \n",
    "            online_ad_reports.append({\n",
    "                \"i\":            i,\n",
    "                \"prefix\":       p,\n",
    "                \"case_id\":      cid,\n",
    "                \"true_noise\":   noise_flag,\n",
    "                \"pred_ad_anom\": int(pred_ad),\n",
    "                \"prob_ad\":        float(prob_ad),\n",
    "                \"nap_prob\": pvec,\n",
    "                \"nap_class\": model.classes_,\n",
    "                \"predict_act\":model.predict(Xp),\n",
    "                \"actual_act\":y_sp\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c3dc749-8767-47f8-b086-fc381a066233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prefix 2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4410\n",
      "           1       1.00      0.96      0.98       590\n",
      "\n",
      "    accuracy                           1.00      5000\n",
      "   macro avg       1.00      0.98      0.99      5000\n",
      "weighted avg       1.00      1.00      1.00      5000\n",
      "\n",
      "\n",
      "--- Prefix 3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      4416\n",
      "           1       0.74      0.96      0.83       584\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.86      0.96      0.90      5000\n",
      "weighted avg       0.96      0.95      0.96      5000\n",
      "\n",
      "\n",
      "--- Prefix 4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      4475\n",
      "           1       0.67      0.92      0.78       525\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.83      0.93      0.87      5000\n",
      "weighted avg       0.96      0.94      0.95      5000\n",
      "\n",
      "\n",
      "--- Prefix 5 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90      4464\n",
      "           1       0.40      0.94      0.56       536\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.70      0.89      0.73      5000\n",
      "weighted avg       0.93      0.84      0.87      5000\n",
      "\n",
      "\n",
      "--- Prefix 6 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95      4493\n",
      "           1       0.53      0.95      0.68       507\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.76      0.93      0.81      5000\n",
      "weighted avg       0.95      0.91      0.92      5000\n",
      "\n",
      "\n",
      "--- Prefix 7 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      4448\n",
      "           1       0.50      0.94      0.65       552\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.75      0.91      0.79      5000\n",
      "weighted avg       0.94      0.89      0.90      5000\n",
      "\n",
      "\n",
      "--- Prefix 8 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      4482\n",
      "           1       0.41      0.95      0.57       518\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.70      0.90      0.74      5000\n",
      "weighted avg       0.93      0.85      0.88      5000\n",
      "\n",
      "\n",
      "--- Prefix 9 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86      4452\n",
      "           1       0.33      0.96      0.50       548\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.66      0.86      0.68      5000\n",
      "weighted avg       0.92      0.79      0.82      5000\n",
      "\n",
      "\n",
      "--- Prefix 10 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85      4476\n",
      "           1       0.30      0.96      0.46       524\n",
      "\n",
      "    accuracy                           0.76      5000\n",
      "   macro avg       0.65      0.85      0.65      5000\n",
      "weighted avg       0.92      0.76      0.81      5000\n",
      "\n",
      "\n",
      "--- Prefix 11 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.70      0.82      4106\n",
      "           1       0.28      0.95      0.44       507\n",
      "\n",
      "    accuracy                           0.73      4613\n",
      "   macro avg       0.64      0.83      0.63      4613\n",
      "weighted avg       0.91      0.73      0.78      4613\n",
      "\n",
      "\n",
      "--- Prefix 12 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.66      0.79      3668\n",
      "           1       0.25      0.95      0.40       448\n",
      "\n",
      "    accuracy                           0.69      4116\n",
      "   macro avg       0.62      0.80      0.60      4116\n",
      "weighted avg       0.91      0.69      0.75      4116\n",
      "\n",
      "\n",
      "--- Prefix 13 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78      3462\n",
      "           1       0.24      0.96      0.38       409\n",
      "\n",
      "    accuracy                           0.67      3871\n",
      "   macro avg       0.62      0.80      0.58      3871\n",
      "weighted avg       0.91      0.67      0.73      3871\n",
      "\n",
      "\n",
      "--- Prefix 14 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.61      0.76      3279\n",
      "           1       0.22      0.95      0.35       366\n",
      "\n",
      "    accuracy                           0.65      3645\n",
      "   macro avg       0.60      0.78      0.55      3645\n",
      "weighted avg       0.91      0.65      0.72      3645\n",
      "\n",
      "\n",
      "--- Prefix 15 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.64      0.78      2821\n",
      "           1       0.23      0.95      0.37       324\n",
      "\n",
      "    accuracy                           0.67      3145\n",
      "   macro avg       0.61      0.80      0.57      3145\n",
      "weighted avg       0.91      0.67      0.73      3145\n",
      "\n",
      "\n",
      "--- Prefix 16 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.59      0.74      2290\n",
      "           1       0.20      0.92      0.33       262\n",
      "\n",
      "    accuracy                           0.62      2552\n",
      "   macro avg       0.59      0.75      0.54      2552\n",
      "weighted avg       0.90      0.62      0.70      2552\n",
      "\n",
      "\n",
      "--- Prefix 17 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.72      1860\n",
      "           1       0.22      0.94      0.35       239\n",
      "\n",
      "    accuracy                           0.61      2099\n",
      "   macro avg       0.60      0.75      0.54      2099\n",
      "weighted avg       0.90      0.61      0.68      2099\n",
      "\n",
      "\n",
      "--- Prefix 18 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.52      0.68      1569\n",
      "           1       0.17      0.96      0.28       157\n",
      "\n",
      "    accuracy                           0.56      1726\n",
      "   macro avg       0.58      0.74      0.48      1726\n",
      "weighted avg       0.92      0.56      0.65      1726\n",
      "\n",
      "\n",
      "--- Prefix 19 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.47      0.64      1235\n",
      "           1       0.19      0.95      0.31       156\n",
      "\n",
      "    accuracy                           0.53      1391\n",
      "   macro avg       0.59      0.71      0.47      1391\n",
      "weighted avg       0.90      0.53      0.60      1391\n",
      "\n",
      "\n",
      "--- Prefix 20 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.43      0.60      1026\n",
      "           1       0.15      0.93      0.26       115\n",
      "\n",
      "    accuracy                           0.48      1141\n",
      "   macro avg       0.57      0.68      0.43      1141\n",
      "weighted avg       0.90      0.48      0.56      1141\n",
      "\n",
      "\n",
      "--- Prefix 21 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.39      0.55       854\n",
      "           1       0.12      0.93      0.22        80\n",
      "\n",
      "    accuracy                           0.43       934\n",
      "   macro avg       0.55      0.66      0.39       934\n",
      "weighted avg       0.91      0.43      0.52       934\n",
      "\n",
      "\n",
      "--- Prefix 22 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.35      0.52       700\n",
      "           1       0.11      0.97      0.20        60\n",
      "\n",
      "    accuracy                           0.40       760\n",
      "   macro avg       0.55      0.66      0.36       760\n",
      "weighted avg       0.92      0.40      0.50       760\n",
      "\n",
      "\n",
      "--- Prefix 23 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.34      0.50       573\n",
      "           1       0.12      0.94      0.21        53\n",
      "\n",
      "    accuracy                           0.39       626\n",
      "   macro avg       0.55      0.64      0.35       626\n",
      "weighted avg       0.91      0.39      0.48       626\n",
      "\n",
      "\n",
      "--- Prefix 24 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.31      0.47       452\n",
      "           1       0.12      0.87      0.20        47\n",
      "\n",
      "    accuracy                           0.36       499\n",
      "   macro avg       0.54      0.59      0.34       499\n",
      "weighted avg       0.88      0.36      0.44       499\n",
      "\n",
      "\n",
      "--- Prefix 25 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.24      0.39       356\n",
      "           1       0.13      0.93      0.23        43\n",
      "\n",
      "    accuracy                           0.32       399\n",
      "   macro avg       0.55      0.59      0.31       399\n",
      "weighted avg       0.88      0.32      0.37       399\n",
      "\n",
      "\n",
      "--- Prefix 26 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.28      0.44       305\n",
      "           1       0.10      0.93      0.18        27\n",
      "\n",
      "    accuracy                           0.33       332\n",
      "   macro avg       0.54      0.60      0.31       332\n",
      "weighted avg       0.91      0.33      0.42       332\n",
      "\n",
      "\n",
      "--- Prefix 27 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.31      0.47       232\n",
      "           1       0.12      0.92      0.21        24\n",
      "\n",
      "    accuracy                           0.36       256\n",
      "   macro avg       0.55      0.61      0.34       256\n",
      "weighted avg       0.89      0.36      0.44       256\n",
      "\n",
      "\n",
      "--- Prefix 28 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.28      0.42       183\n",
      "           1       0.09      0.65      0.16        20\n",
      "\n",
      "    accuracy                           0.32       203\n",
      "   macro avg       0.48      0.46      0.29       203\n",
      "weighted avg       0.80      0.32      0.40       203\n",
      "\n",
      "\n",
      "--- Prefix 29 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.28      0.44       145\n",
      "           1       0.14      0.94      0.24        18\n",
      "\n",
      "    accuracy                           0.36       163\n",
      "   macro avg       0.56      0.61      0.34       163\n",
      "weighted avg       0.88      0.36      0.42       163\n",
      "\n",
      "\n",
      "--- Prefix 30 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.28      0.43       123\n",
      "           1       0.05      0.83      0.10         6\n",
      "\n",
      "    accuracy                           0.30       129\n",
      "   macro avg       0.51      0.55      0.27       129\n",
      "weighted avg       0.93      0.30      0.42       129\n",
      "\n",
      "\n",
      "--- Prefix 31 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.22      0.35        87\n",
      "           1       0.17      0.88      0.29        16\n",
      "\n",
      "    accuracy                           0.32       103\n",
      "   macro avg       0.54      0.55      0.32       103\n",
      "weighted avg       0.79      0.32      0.34       103\n",
      "\n",
      "\n",
      "--- Prefix 32 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.21      0.34        77\n",
      "           1       0.08      1.00      0.14         5\n",
      "\n",
      "    accuracy                           0.26        82\n",
      "   macro avg       0.54      0.60      0.24        82\n",
      "weighted avg       0.94      0.26      0.33        82\n",
      "\n",
      "\n",
      "--- Prefix 33 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40        56\n",
      "           1       0.19      1.00      0.32        10\n",
      "\n",
      "    accuracy                           0.36        66\n",
      "   macro avg       0.60      0.62      0.36        66\n",
      "weighted avg       0.88      0.36      0.39        66\n",
      "\n",
      "\n",
      "--- Prefix 34 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.30        46\n",
      "           1       0.10      1.00      0.17         4\n",
      "\n",
      "    accuracy                           0.24        50\n",
      "   macro avg       0.55      0.59      0.24        50\n",
      "weighted avg       0.93      0.24      0.29        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) Summarize\n",
    "reports_df = pd.DataFrame(online_ad_reports)\n",
    "for p in prefix_range:\n",
    "    sub = reports_df[reports_df[\"prefix\"] == p]\n",
    "    if not sub.empty:\n",
    "        print(f\"\\n--- Prefix {p} ---\")\n",
    "        print(classification_report(\n",
    "            sub[\"true_noise\"], sub[\"pred_ad_anom\"], zero_division=0\n",
    "        ))\n",
    "reports_df \n",
    "reports_df.to_csv('../result/%s_classifier_xgb_%s_random_sample_napv2.csv'%(dataset, TOTAL_SAMPLES), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d3608-7c40-44df-981d-f3bd909ec281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
