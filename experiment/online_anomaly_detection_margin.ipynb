{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255f42c8-8abf-4a9f-878c-95c0855f8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from collections import Counter, defaultdict, deque\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, log_loss, roc_auc_score\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bbb639-31b8-4d67-a7ca-c06249675d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# suppress only the “y_pred values do not sum to one” warning\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*y_pred values do not sum to one.*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41802843-d3b7-49ee-8578-64c755bd3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = -∑_c [1{c = y_true_i} · log P_model(c | x_i)]\n",
    "    If the true label isn’t in model.classes_, returns a default high loss.\n",
    "    Works for any len(x_test) >= 1, including the single-class case.\n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(x_test)\n",
    "    default = log_loss([[1, 0]], [[0, 1]]) + 1  # fallback loss\n",
    "\n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        classes = model.classes_\n",
    "\n",
    "        # if only one class in the model\n",
    "        if sample_probs.size == 1:\n",
    "            if classes[0] == true_label:\n",
    "                losses.append(0.0)  # perfect prediction\n",
    "            else:\n",
    "                losses.append(default)\n",
    "            continue\n",
    "\n",
    "        # find index of the true label\n",
    "        idx_arr = np.where(classes == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(default)\n",
    "        else:\n",
    "            y_true_onehot = np.zeros_like(sample_probs)\n",
    "            y_true_onehot[idx_arr[0]] = 1\n",
    "\n",
    "            # normalize just in case\n",
    "            sample_probs = sample_probs / sample_probs.sum()\n",
    "            y_true_onehot = y_true_onehot / y_true_onehot.sum()\n",
    "\n",
    "            loss_i = log_loss([y_true_onehot], [sample_probs])\n",
    "            losses.append(loss_i)\n",
    "\n",
    "    return np.array(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a1b700-e48f-4ae7-8c56-33d46180ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    For each sample i:\n",
    "      loss_i = 1 - P_model(y_true_i | x_i)\n",
    "    If the true label isn’t in model.classes_, we return 1.1 as before.\n",
    "    Works for any len(x_test) >= 1.\n",
    "    \"\"\"\n",
    "    # predict_proba returns shape (n_samples, n_classes)\n",
    "    probs = model.predict_proba(x_test)\n",
    "    \n",
    "    losses = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        sample_probs = probs[i]\n",
    "        # find index of the true label in model.classes_\n",
    "        idx_arr = np.where(model.classes_ == true_label)[0]\n",
    "        if idx_arr.size == 0:\n",
    "            losses.append(1.1)\n",
    "        else:\n",
    "            col_index = idx_arr[0]\n",
    "            losses.append(1 - sample_probs[col_index])\n",
    "    \n",
    "    return np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfb33b2-2b77-43a0-a9a2-607922582eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_transform_target(encoder, targets, unknown_value=-1):\n",
    "    classes = set(encoder.classes_)\n",
    "    transformed = []\n",
    "    for t in targets:\n",
    "        if t in classes:\n",
    "            transformed.append(encoder.transform([t])[0])\n",
    "        else:\n",
    "            transformed.append(unknown_value)\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599b1c0f-b2ad-4405-a91a-3acabe9d8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_loss(normal_loss_value, cross_entropy_loss_value):\n",
    "    normal_loss_dist = []\n",
    "    cross_loss_dist = []\n",
    "    for pos, prediction in  enumerate(normal_loss_value):\n",
    "        if prediction != 1:\n",
    "            cross_loss_dist.append(cross_entropy_loss_value[pos])\n",
    "            normal_loss_dist.append(prediction)\n",
    "\n",
    "    return np.array(normal_loss_dist), np.array(cross_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486221ec-c06a-47c4-9536-081bb8ce1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_cls_result(classification_result):\n",
    "    \n",
    "    for i in classification_result.keys():\n",
    "        print(i, classification_result[i].keys())\n",
    "\n",
    "        if '1' not in classification_result[i].keys():\n",
    "            classification_result[i]['1'] = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0.0}\n",
    "    return classification_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20559e12-1320-433b-8623-54e74f4b2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_largest_gap(losses):\n",
    "    y = sorted(losses, reverse=True)\n",
    "    diffs = abs(np.diff(y))\n",
    "    idx = np.argmax(diffs) + 1   # +1 because diffs[i] = y[i+1]-y[i]\n",
    "    return idx, y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b7bffe-679e-4e5d-9fd7-4aad33b15076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gap_cutoff(rf, Xw, yw):\n",
    "    \"\"\"\n",
    "    Given a fitted RandomForest `rf` and its training data (Xw, yw),\n",
    "    compute cross‐entropy losses for each sample. If there are fewer than\n",
    "    2 samples, just return the single loss (or 0 if somehow empty). Otherwise\n",
    "    use find_largest_gap to get a gap‐based cutoff.\n",
    "    \"\"\"\n",
    "    ce_losses = cross_entropy_loss(rf, Xw, yw)\n",
    "    n = ce_losses.size\n",
    "\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    if n == 1:\n",
    "        # Only one loss → no “gap” to find. Use the single value as cutoff.\n",
    "        return float(ce_losses[0])\n",
    "\n",
    "    # Now we have ≥2 losses; sorting in descending order ensures diff is nonempty\n",
    "    _, cutoff_gap = find_largest_gap(ce_losses)\n",
    "    return cutoff_gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03dcceb8-857e-45c6-aee6-b35c85573002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_sampling_balanced(model, x_pool, y_pool, k=20):\n",
    "    \"\"\"\n",
    "    Unlabeled pool(x_pool)에서 margin이 가장 작은 순으로 정렬한 뒤,\n",
    "    anomaly:normal = 1:1 비율로 총 k개 인덱스 반환.\n",
    "    \n",
    "    Args:\n",
    "        model:        predict_proba 지원하는 classifier\n",
    "        x_pool:       np.array or DataFrame, shape (n_samples, n_features)\n",
    "        y_pool:       1D array-like of true labels (0=normal, 1=anomaly)\n",
    "        k:            total 선택 개수 (짝수 권장)\n",
    "    Returns:\n",
    "        selected_idx: np.array of length k\n",
    "    \"\"\"\n",
    "    # 1) margin 계산\n",
    "    probs = model.predict_proba(x_pool)                       # (n_samples, n_classes)\n",
    "    # 내림차순 정렬된 확률\n",
    "    sorted_probs = -np.sort(-probs, axis=1)\n",
    "    top1 = sorted_probs[:, 0]\n",
    "    top2 = sorted_probs[:, 1] if sorted_probs.shape[1] > 1 else np.zeros_like(top1)\n",
    "    margins = top1 - top2\n",
    "\n",
    "    # 2) margin 오름차순 인덱스\n",
    "    idx_sorted = np.argsort(margins)\n",
    "\n",
    "    # 3) 클래스별 분리\n",
    "    anomaly_idxs = [i for i in idx_sorted if y_pool[i] == 1]\n",
    "    normal_idxs  = [i for i in idx_sorted if y_pool[i] == 0]\n",
    "\n",
    "    # 4) 반반씩 선택 (부족하면 있는 만큼만)\n",
    "    half = k // 2\n",
    "    sel_anom = anomaly_idxs[:half]\n",
    "    sel_norm = normal_idxs[:k - len(sel_anom)]\n",
    "\n",
    "    # 만약 normal도 부족하면 anomaly로 채우기(또는 그 반대)\n",
    "    if len(sel_norm) < (k - half):\n",
    "        sel_norm += normal_idxs[:(k - len(sel_anom))]  # 재사용 or 남은 idx\n",
    "    if len(sel_anom) < half:\n",
    "        sel_anom += anomaly_idxs[:(k - len(sel_norm))]\n",
    "\n",
    "    # 5) 합치고 shuffle\n",
    "    selected_idx = np.array(sel_anom + sel_norm)\n",
    "    np.random.shuffle(selected_idx)\n",
    "    return selected_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6338a1-26b5-44cd-9ae7-60e88a205c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099_noise.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Read and Process the Data\n",
    "# ----------------------------\n",
    "dataset = '0.099_noise.csv'\n",
    "df = pd.read_csv(\"../data/%s\" % (dataset))\n",
    "df = df.sort_values(by='Timestamp')\n",
    "# Process the 'noise' column:\n",
    "# - If NaN, assume Normal (0).\n",
    "# - Otherwise, treat True/1/'True' as anomaly (1); everything else as Normal (0).\n",
    "df['noise'] = df['noise'].fillna(0).apply(lambda x: 1 if (x == True or x == 1 or x == 'True' or x=='true') else 0)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "print(dataset)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Prefixes & global window settings\n",
    "# ----------------------------\n",
    "prefix_range = range(2, 35)   # prefix lengths 2..15\n",
    "WINDOW_EVENTS = 2500          # keep the last 2 500 raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503fb309-0bb6-4732-bdcd-51c075833ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Pre‐fit encoders for each prefix’s NAP ---\n",
    "all_acts = df[\"Activity\"].unique()\n",
    "ohe_nap  = {p: OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "              .fit(np.array([[a]*(p-1) for a in all_acts]))\n",
    "            for p in prefix_range}\n",
    "le_nap   = {p: LabelEncoder().fit(all_acts) for p in prefix_range}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f32050a7-bc26-40e6-a1f0-5ae4c3aa8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4) Buffers & global state\n",
    "# ----------------------------\n",
    "# Create a single sliding window for the last WINDOW_EVENTS raw prefix-events\n",
    "global_events = deque(maxlen=WINDOW_EVENTS)\n",
    "\n",
    "# Per-prefix buffers (unbounded; we’ll evict manually when global_events drops)\n",
    "buffers = {}\n",
    "for p in prefix_range:\n",
    "    buffers[p] = {\n",
    "        \"raw_feats\":      deque(),   # stores list of activities for each prefix-event\n",
    "        \"raw_tgts\":       deque(),   # stores the target activity string\n",
    "        \"X\":               deque(),   # one-hot–encoded feature vectors\n",
    "        \"y\":               deque(),   # label‐encoded target indices\n",
    "        \"noise\":           deque(),   # true anomaly flag (0/1)\n",
    "        \"model\":          None,       # RandomForest NAP model\n",
    "        \"filled\":         False,      # has the NAP model been trained at least once?\n",
    "        \"cutoff\":         None,       # CE‐loss cutoff for anomaly flagging\n",
    "        \"update_counter\": 0           # no longer used per-prefix\n",
    "    }\n",
    "\n",
    "case_events      = defaultdict(list)\n",
    "detect_pool      = []   # accumulated AD training samples (dicts)\n",
    "anom_clf         = None\n",
    "enc_ad           = None\n",
    "max_prob_ad      = 0\n",
    "max_pfx          = max(prefix_range) - 1\n",
    "\n",
    "online_nap_reports = []\n",
    "online_ad_reports  = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ec4578-d6b8-4544-ba50-be3367941337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/79441 rows (1.3%)\n",
      "Processed 2000/79441 rows (2.5%)\n",
      "Processed 3000/79441 rows (3.8%)\n",
      "Processed 4000/79441 rows (5.0%)\n",
      "Processed 5000/79441 rows (6.3%)\n",
      "Processed 6000/79441 rows (7.6%)\n",
      "Processed 7000/79441 rows (8.8%)\n",
      "Processed 8000/79441 rows (10.1%)\n",
      "Processed 9000/79441 rows (11.3%)\n",
      "Processed 10000/79441 rows (12.6%)\n",
      "Processed 11000/79441 rows (13.8%)\n",
      "Processed 12000/79441 rows (15.1%)\n",
      "Processed 13000/79441 rows (16.4%)\n",
      "Processed 14000/79441 rows (17.6%)\n",
      "Processed 15000/79441 rows (18.9%)\n",
      "Processed 16000/79441 rows (20.1%)\n",
      "Processed 17000/79441 rows (21.4%)\n",
      "Processed 18000/79441 rows (22.7%)\n",
      "Processed 19000/79441 rows (23.9%)\n",
      "Processed 20000/79441 rows (25.2%)\n",
      "Processed 21000/79441 rows (26.4%)\n",
      "Processed 22000/79441 rows (27.7%)\n",
      "Processed 23000/79441 rows (29.0%)\n",
      "Processed 24000/79441 rows (30.2%)\n",
      "Processed 25000/79441 rows (31.5%)\n",
      "Processed 26000/79441 rows (32.7%)\n",
      "Processed 27000/79441 rows (34.0%)\n",
      "Processed 28000/79441 rows (35.2%)\n",
      "Processed 29000/79441 rows (36.5%)\n",
      "Processed 30000/79441 rows (37.8%)\n",
      "Processed 31000/79441 rows (39.0%)\n",
      "Processed 32000/79441 rows (40.3%)\n",
      "Processed 33000/79441 rows (41.5%)\n",
      "Processed 34000/79441 rows (42.8%)\n",
      "Processed 35000/79441 rows (44.1%)\n",
      "Processed 36000/79441 rows (45.3%)\n",
      "Processed 37000/79441 rows (46.6%)\n",
      "Processed 38000/79441 rows (47.8%)\n",
      "Processed 39000/79441 rows (49.1%)\n",
      "Processed 40000/79441 rows (50.4%)\n",
      "Processed 41000/79441 rows (51.6%)\n",
      "Processed 42000/79441 rows (52.9%)\n",
      "Processed 43000/79441 rows (54.1%)\n",
      "Processed 44000/79441 rows (55.4%)\n",
      "Processed 45000/79441 rows (56.6%)\n",
      "Processed 46000/79441 rows (57.9%)\n",
      "Processed 47000/79441 rows (59.2%)\n",
      "Processed 48000/79441 rows (60.4%)\n",
      "Processed 49000/79441 rows (61.7%)\n",
      "Processed 50000/79441 rows (62.9%)\n",
      "Processed 51000/79441 rows (64.2%)\n",
      "Processed 52000/79441 rows (65.5%)\n",
      "Processed 53000/79441 rows (66.7%)\n",
      "Processed 54000/79441 rows (68.0%)\n",
      "Processed 55000/79441 rows (69.2%)\n",
      "Processed 56000/79441 rows (70.5%)\n",
      "Processed 57000/79441 rows (71.8%)\n",
      "Processed 58000/79441 rows (73.0%)\n",
      "Processed 59000/79441 rows (74.3%)\n",
      "Processed 60000/79441 rows (75.5%)\n",
      "Processed 61000/79441 rows (76.8%)\n",
      "Processed 62000/79441 rows (78.0%)\n",
      "Processed 63000/79441 rows (79.3%)\n",
      "Processed 64000/79441 rows (80.6%)\n",
      "Processed 65000/79441 rows (81.8%)\n",
      "Processed 66000/79441 rows (83.1%)\n",
      "Processed 67000/79441 rows (84.3%)\n",
      "Processed 68000/79441 rows (85.6%)\n",
      "Processed 69000/79441 rows (86.9%)\n",
      "Processed 70000/79441 rows (88.1%)\n",
      "Processed 71000/79441 rows (89.4%)\n",
      "Processed 72000/79441 rows (90.6%)\n",
      "Processed 73000/79441 rows (91.9%)\n",
      "Processed 74000/79441 rows (93.2%)\n",
      "Processed 75000/79441 rows (94.4%)\n",
      "Processed 76000/79441 rows (95.7%)\n",
      "Processed 77000/79441 rows (96.9%)\n",
      "Processed 78000/79441 rows (98.2%)\n",
      "Processed 79000/79441 rows (99.4%)\n",
      "Processed 79441/79441 rows (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Streaming loop with NAP + AD\n",
    "# ----------------------------\n",
    "total = len(df)\n",
    "# single sliding window of the last WINDOW_EVENTS raw events\n",
    "global_update_counter = 0\n",
    "global_retrain_batch = WINDOW_EVENTS // 2   # 1250\n",
    "\n",
    "for i, (_, row) in enumerate(df.iterrows(), start=1):\n",
    "    # progress logging\n",
    "    if i % 1000 == 0 or i == total:\n",
    "        pct = i / total * 100\n",
    "        print(f\"Processed {i}/{total} rows ({pct:.1f}%)\")\n",
    "    global_update_counter += 1\n",
    "    \n",
    "    cid = row[\"Case ID\"]\n",
    "    case_events[cid].append(row)\n",
    "    cur_len = len(case_events[cid])\n",
    "\n",
    "   # Only process when a case first reaches prefix length p\n",
    "    for p in prefix_range:\n",
    "        if cur_len != p:\n",
    "            continue\n",
    "\n",
    "        # 5.1) Build current sample\n",
    "        group      = case_events[cid]\n",
    "        feats      = [e.Activity for e in group[: p - 1]]\n",
    "        target_act = group[p - 1].Activity\n",
    "        noise_flag = group[p - 1].noise\n",
    "\n",
    "        buf = buffers[p]\n",
    "\n",
    "        # --- Slide the global window: peek dropped if full ---\n",
    "        dropped = None\n",
    "        if len(global_events) == WINDOW_EVENTS:\n",
    "            dropped = global_events[0]  # will be auto-evicted on append()\n",
    "\n",
    "        # Transform features/target for NAP\n",
    "        Xp_vec = ohe_nap[p].transform([feats]).ravel()\n",
    "        yp     = le_nap[p].transform([target_act])[0]\n",
    "\n",
    "        # Append to global_events: store (prefix, X_vec, y_label, noise, raw_feats, raw_target)\n",
    "        global_events.append((p, Xp_vec, yp, noise_flag, feats, target_act))\n",
    "\n",
    "        # Append to this prefix’s buffers (unbounded deques)\n",
    "        buf[\"raw_feats\"].append(feats)\n",
    "        buf[\"raw_tgts\"].append(target_act)\n",
    "        buf[\"X\"].append(Xp_vec)\n",
    "        buf[\"y\"].append(yp)\n",
    "        buf[\"noise\"].append(noise_flag)\n",
    "\n",
    "        # If something was dropped from global_events, evict it from its prefix buffer\n",
    "        if dropped is not None:\n",
    "            old_p, old_Xp, old_yp, old_noise, old_feats, old_tgt = dropped\n",
    "            old_buf = buffers[old_p]\n",
    "            if old_buf[\"X\"]:\n",
    "                old_buf[\"raw_feats\"].popleft()\n",
    "                old_buf[\"raw_tgts\"].popleft()\n",
    "                old_buf[\"X\"].popleft()\n",
    "                old_buf[\"y\"].popleft()\n",
    "                old_buf[\"noise\"].popleft()\n",
    "\n",
    "        # --- 5.2) Initial NAP training (once we have the first sample) ---\n",
    "        if buf[\"model\"] is None:\n",
    "            Xw = np.vstack(buf[\"X\"])\n",
    "            yw = np.array(buf[\"y\"])\n",
    "\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=100, random_state=42, n_jobs=-1\n",
    "            )\n",
    "            rf.fit(Xw, yw)\n",
    "\n",
    "            # Compute CE‐loss cutoff (gap‐based) on current buffer\n",
    "            cutoff = compute_gap_cutoff(rf, Xw, yw)\n",
    "\n",
    "            buf[\"model\"]  = rf\n",
    "            buf[\"filled\"] = True\n",
    "            buf[\"cutoff\"] = cutoff\n",
    "\n",
    "            # print(f\"Prefix {p} NAP initial train (buffer size = {len(buf['X'])})\")\n",
    "\n",
    "            # 5.2a) Bootstrap the AD pool\n",
    "            MAX_ANOM = 10\n",
    "            TOTAL_SAMPLES = 50\n",
    "\n",
    "            sel_idxs = margin_sampling_balanced(model=rf, x_pool=Xw, y_pool=yw, k=TOTAL_SAMPLES)\n",
    "            random.shuffle(sel_idxs)\n",
    "\n",
    "            for idx in sel_idxs:\n",
    "                prob_vec = rf.predict_proba(buf[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                ce0      = cross_entropy_loss(rf, buf[\"X\"][idx].reshape(1, -1), [buf[\"y\"][idx]])[0]\n",
    "                detect_pool.append({\n",
    "                    \"raw_feats\": buf[\"raw_feats\"][idx],\n",
    "                    \"target\":    buf[\"raw_tgts\"][idx],\n",
    "                    \"prefix\":    p,\n",
    "                    \"prob\":      prob_vec,\n",
    "                    \"ce_loss\":   ce0,\n",
    "                    \"anomaly\":   buf[\"noise\"][idx]\n",
    "                })\n",
    "\n",
    "            # 5.2b) Train the AD classifier if we have ≥20 samples\n",
    "            if len(detect_pool) >= 20:\n",
    "                cat_rows = []\n",
    "                for d in detect_pool:\n",
    "                    row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                    row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                    cat_rows.append(row_cat)\n",
    "                enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "                X_cat = enc_ad.transform(cat_rows)\n",
    "\n",
    "                max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "                prob_mat = [\n",
    "                    d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                    for d in detect_pool\n",
    "                ]\n",
    "                ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "                X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "                y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "                X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "                anom_clf = RandomForestClassifier(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "                anom_clf.fit(X_ad, y_ad)\n",
    "                # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "                #     random_state=42).fit(X_ad, y_ad)\n",
    "                # anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.01, eval_metric='logloss',\n",
    "                #                          random_state=42).fit(X_ad, y_ad)\n",
    "\n",
    "                # print(f\"Prefix {p} AD initial train on {len(detect_pool)} samples\")\n",
    "\n",
    "                AD_CAT_FEATS = X_cat.shape[1]\n",
    "                AD_NUM_FEATS = X_num.shape[1]\n",
    "            # Skip further processing of this new event\n",
    "                \n",
    "            continue\n",
    "\n",
    "        # --- 5.3) Prequential NAP prediction & store ---\n",
    "        rf   = buf[\"model\"]\n",
    "        Xp   = Xp_vec.reshape(1, -1)\n",
    "        y_sp = yp\n",
    "        cutoff_nap = buf[\"cutoff\"]\n",
    "\n",
    "        ce_cur = cross_entropy_loss(rf, Xp, [y_sp])[0]\n",
    "        pred_nap_anom = int(ce_cur > cutoff_nap)\n",
    "\n",
    "        online_nap_reports.append({\n",
    "            \"i\":             i,\n",
    "            \"prefix\":        p,\n",
    "            \"case_id\":       cid,\n",
    "            \"true_noise\":    noise_flag,\n",
    "            \"pred_nap_anom\": pred_nap_anom,\n",
    "            \"cutoff\":        cutoff_nap\n",
    "        })\n",
    "\n",
    "        # --- 5.4) Global retrain trigger (increment once per prefix-event) ---\n",
    "        if global_update_counter >= global_retrain_batch:\n",
    "            # print(\"=== Global retrain of all prefix NAP models ===\")\n",
    "\n",
    "            # Retrain each NAP model on its current buffer, recompute cutoff, \n",
    "            # and sample AD points\n",
    "            for q in prefix_range:\n",
    "                buf_q = buffers[q]\n",
    "                if len(buf_q[\"X\"]) == 0:\n",
    "                    continue\n",
    "\n",
    "                Xw = np.vstack(buf_q[\"X\"])\n",
    "                yw = np.array(buf_q[\"y\"])\n",
    "                rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "                rf.fit(Xw, yw)\n",
    "                buf_q[\"model\"] = rf\n",
    "\n",
    "                # Recompute CE‐loss cutoff (gap-based)\n",
    "                cutoff_q = compute_gap_cutoff(rf, Xw, yw)\n",
    "                buf_q[\"cutoff\"] = cutoff_q\n",
    "                # print(f\"  Recomputed cutoff for prefix {q} (buffer size = {len(buf_q['X'])})\")\n",
    "\n",
    "                sel_idxs = margin_sampling_balanced(model=rf, x_pool=Xw, y_pool=yw, k=TOTAL_SAMPLES)\n",
    "                # print(sel_idxs)\n",
    "                # print([buf_q[\"noise\"][idx] for idx in sel_idxs])\n",
    "                random.shuffle(sel_idxs)\n",
    "    \n",
    "                for idx in sel_idxs:\n",
    "                    prob_vec = rf.predict_proba(buf_q[\"X\"][idx].reshape(1, -1))[0].tolist()\n",
    "                    ce0      = cross_entropy_loss(rf, buf_q[\"X\"][idx].reshape(1, -1), [buf_q[\"y\"][idx]])[0]\n",
    "                    detect_pool.append({\n",
    "                        \"raw_feats\": buf_q[\"raw_feats\"][idx],\n",
    "                        \"target\":    buf_q[\"raw_tgts\"][idx],\n",
    "                        \"prefix\":    p,\n",
    "                        \"prob\":      prob_vec,\n",
    "                        \"ce_loss\":   ce0,\n",
    "                        \"anomaly\":   buf_q[\"noise\"][idx]\n",
    "                    })\n",
    "\n",
    "            # Retrain AD classifier if we have ≥20 samples\n",
    "            # if len(detect_pool) >= 20:\n",
    "            cat_rows = []\n",
    "            for d in detect_pool:\n",
    "                row_cat = d[\"raw_feats\"] + [None] * (max_pfx - len(d[\"raw_feats\"]))\n",
    "                row_cat += [d[\"prefix\"], d[\"target\"]]\n",
    "                cat_rows.append(row_cat)\n",
    "            enc_ad = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\").fit(cat_rows)\n",
    "            X_cat = enc_ad.transform(cat_rows)\n",
    "            max_prob_ad = max(len(d[\"prob\"]) for d in detect_pool)\n",
    "            prob_mat = [\n",
    "                d[\"prob\"] + [0.0] * (max_prob_ad - len(d[\"prob\"]))\n",
    "                for d in detect_pool\n",
    "            ]\n",
    "            ce_vec = [[d[\"ce_loss\"]] for d in detect_pool]\n",
    "            X_num = np.hstack([prob_mat, ce_vec])\n",
    "\n",
    "            y_ad = np.array([d[\"anomaly\"] for d in detect_pool])\n",
    "            X_ad = np.hstack([X_cat, X_num])\n",
    "\n",
    "            anom_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "            anom_clf.fit(X_ad, y_ad)\n",
    "            AD_CAT_FEATS = X_cat.shape[1]\n",
    "            AD_NUM_FEATS = X_num.shape[1]\n",
    "                            \n",
    "            # anom_clf = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced',  # if your anomalies are rare\n",
    "            #     random_state=42).fit(X_ad, y_ad)\n",
    "            # anom_clf = XGBClassifier(objective='binary:logistic', n_estimators=10, learning_rate=0.01, eval_metric='logloss',\n",
    "            #                          random_state=42).fit(X_ad, y_ad)\n",
    "            # print(f\"  AD retrain on {len(detect_pool)} samples\")\n",
    "            # detect_pool = []\n",
    "            global_update_counter = 0\n",
    "\n",
    "        # --- 5.5) Prequential AD classification for current event ---\n",
    "        if anom_clf is not None:\n",
    "            # Build AD feature vector: categorical + numeric\n",
    "            row_cat = feats + [None] * (max_pfx - len(feats)) + [p, y_sp]\n",
    "            # 1) Categorical part\n",
    "            Xc = enc_ad.transform([row_cat])\n",
    "            if Xc.shape[1] != AD_CAT_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_CAT_FEATS} cat features, got {Xc.shape[1]}\")\n",
    "            \n",
    "            # 2) Numeric part (prob_vector + ce_loss)\n",
    "            model = buffers[p]['model']\n",
    "            pvec = model.predict_proba(Xp)[0].tolist()\n",
    "            pad_len = AD_NUM_FEATS - 1\n",
    "            pvec_padded = pvec + [0.0] * (pad_len - len(pvec))\n",
    "            Xn = np.array([pvec_padded + [ce_cur]])\n",
    "            if Xn.shape[1] != AD_NUM_FEATS:\n",
    "               raise ValueError(f\"Expected {AD_NUM_FEATS} num features, got {Xn.shape[1]}\")\n",
    "            \n",
    "            # 3) Combine & predict\n",
    "            Xa = np.hstack([Xc, Xn])\n",
    "            pred_ad = anom_clf.predict(Xa)[0]\n",
    "            prob_ad = anom_clf.predict_proba(Xa)[0, 1]\n",
    "            \n",
    "            online_ad_reports.append({\n",
    "                \"i\":            i,\n",
    "                \"prefix\":       p,\n",
    "                \"case_id\":      cid,\n",
    "                \"true_noise\":   noise_flag,\n",
    "                \"pred_ad_anom\": int(pred_ad),\n",
    "                \"score\":        float(prob_ad)\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d04f0f3-87ea-4d4e-a6b5-533dfa38cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prefix 2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02      4387\n",
      "           1       0.11      1.00      0.20       529\n",
      "\n",
      "    accuracy                           0.11      4916\n",
      "   macro avg       0.55      0.50      0.11      4916\n",
      "weighted avg       0.90      0.11      0.04      4916\n",
      "\n",
      "\n",
      "--- Prefix 3 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01      4475\n",
      "           1       0.09      1.00      0.17       441\n",
      "\n",
      "    accuracy                           0.10      4916\n",
      "   macro avg       0.55      0.50      0.09      4916\n",
      "weighted avg       0.92      0.10      0.03      4916\n",
      "\n",
      "\n",
      "--- Prefix 4 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87      4449\n",
      "           1       0.29      0.86      0.44       467\n",
      "\n",
      "    accuracy                           0.79      4916\n",
      "   macro avg       0.64      0.82      0.65      4916\n",
      "weighted avg       0.92      0.79      0.83      4916\n",
      "\n",
      "\n",
      "--- Prefix 5 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.34      0.50      4404\n",
      "           1       0.14      0.94      0.25       512\n",
      "\n",
      "    accuracy                           0.40      4916\n",
      "   macro avg       0.56      0.64      0.38      4916\n",
      "weighted avg       0.89      0.40      0.48      4916\n",
      "\n",
      "\n",
      "--- Prefix 6 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.21      0.34      4469\n",
      "           1       0.11      0.97      0.20       447\n",
      "\n",
      "    accuracy                           0.28      4916\n",
      "   macro avg       0.55      0.59      0.27      4916\n",
      "weighted avg       0.91      0.28      0.33      4916\n",
      "\n",
      "\n",
      "--- Prefix 7 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.36      0.52      4431\n",
      "           1       0.14      0.93      0.24       485\n",
      "\n",
      "    accuracy                           0.41      4916\n",
      "   macro avg       0.56      0.64      0.38      4916\n",
      "weighted avg       0.90      0.41      0.50      4916\n",
      "\n",
      "\n",
      "--- Prefix 8 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.20      0.34      4432\n",
      "           1       0.12      0.97      0.21       484\n",
      "\n",
      "    accuracy                           0.28      4916\n",
      "   macro avg       0.55      0.58      0.27      4916\n",
      "weighted avg       0.90      0.28      0.32      4916\n",
      "\n",
      "\n",
      "--- Prefix 9 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.14      0.24      4442\n",
      "           1       0.11      0.96      0.19       474\n",
      "\n",
      "    accuracy                           0.22      4916\n",
      "   macro avg       0.54      0.55      0.22      4916\n",
      "weighted avg       0.89      0.22      0.24      4916\n",
      "\n",
      "\n",
      "--- Prefix 10 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.23      0.37      4461\n",
      "           1       0.11      0.89      0.19       455\n",
      "\n",
      "    accuracy                           0.29      4916\n",
      "   macro avg       0.53      0.56      0.28      4916\n",
      "weighted avg       0.88      0.29      0.35      4916\n",
      "\n",
      "\n",
      "--- Prefix 11 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.32      0.48      4020\n",
      "           1       0.12      0.89      0.22       429\n",
      "\n",
      "    accuracy                           0.37      4449\n",
      "   macro avg       0.54      0.61      0.35      4449\n",
      "weighted avg       0.88      0.37      0.45      4449\n",
      "\n",
      "\n",
      "--- Prefix 12 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.46      0.62      3616\n",
      "           1       0.13      0.85      0.22       337\n",
      "\n",
      "    accuracy                           0.49      3953\n",
      "   macro avg       0.55      0.65      0.42      3953\n",
      "weighted avg       0.90      0.49      0.59      3953\n",
      "\n",
      "\n",
      "--- Prefix 13 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.51      0.66      3397\n",
      "           1       0.14      0.79      0.24       344\n",
      "\n",
      "    accuracy                           0.53      3741\n",
      "   macro avg       0.55      0.65      0.45      3741\n",
      "weighted avg       0.88      0.53      0.62      3741\n",
      "\n",
      "\n",
      "--- Prefix 14 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72      2921\n",
      "           1       0.15      0.74      0.25       287\n",
      "\n",
      "    accuracy                           0.59      3208\n",
      "   macro avg       0.55      0.66      0.48      3208\n",
      "weighted avg       0.89      0.59      0.68      3208\n",
      "\n",
      "\n",
      "--- Prefix 15 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73      2295\n",
      "           1       0.14      0.70      0.24       223\n",
      "\n",
      "    accuracy                           0.60      2518\n",
      "   macro avg       0.55      0.65      0.48      2518\n",
      "weighted avg       0.88      0.60      0.69      2518\n",
      "\n",
      "\n",
      "--- Prefix 16 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.65      0.78      1913\n",
      "           1       0.17      0.74      0.27       180\n",
      "\n",
      "    accuracy                           0.66      2093\n",
      "   macro avg       0.57      0.70      0.52      2093\n",
      "weighted avg       0.90      0.66      0.73      2093\n",
      "\n",
      "\n",
      "--- Prefix 17 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.69      0.80      1583\n",
      "           1       0.17      0.61      0.27       163\n",
      "\n",
      "    accuracy                           0.69      1746\n",
      "   macro avg       0.56      0.65      0.53      1746\n",
      "weighted avg       0.87      0.69      0.75      1746\n",
      "\n",
      "\n",
      "--- Prefix 18 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82      1266\n",
      "           1       0.17      0.53      0.26       128\n",
      "\n",
      "    accuracy                           0.72      1394\n",
      "   macro avg       0.55      0.63      0.54      1394\n",
      "weighted avg       0.87      0.72      0.77      1394\n",
      "\n",
      "\n",
      "--- Prefix 19 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83      1049\n",
      "           1       0.14      0.44      0.21        93\n",
      "\n",
      "    accuracy                           0.73      1142\n",
      "   macro avg       0.54      0.60      0.52      1142\n",
      "weighted avg       0.87      0.73      0.78      1142\n",
      "\n",
      "\n",
      "--- Prefix 20 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83       834\n",
      "           1       0.18      0.47      0.26        95\n",
      "\n",
      "    accuracy                           0.72       929\n",
      "   macro avg       0.55      0.61      0.54       929\n",
      "weighted avg       0.85      0.72      0.77       929\n",
      "\n",
      "\n",
      "--- Prefix 21 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87       670\n",
      "           1       0.15      0.34      0.21        64\n",
      "\n",
      "    accuracy                           0.77       734\n",
      "   macro avg       0.54      0.58      0.54       734\n",
      "weighted avg       0.86      0.77      0.81       734\n",
      "\n",
      "\n",
      "--- Prefix 22 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89       558\n",
      "           1       0.10      0.31      0.15        35\n",
      "\n",
      "    accuracy                           0.80       593\n",
      "   macro avg       0.53      0.57      0.52       593\n",
      "weighted avg       0.90      0.80      0.84       593\n",
      "\n",
      "\n",
      "--- Prefix 23 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87       429\n",
      "           1       0.20      0.42      0.27        45\n",
      "\n",
      "    accuracy                           0.78       474\n",
      "   macro avg       0.57      0.62      0.57       474\n",
      "weighted avg       0.86      0.78      0.82       474\n",
      "\n",
      "\n",
      "--- Prefix 24 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       366\n",
      "           1       0.09      0.25      0.13        28\n",
      "\n",
      "    accuracy                           0.76       394\n",
      "   macro avg       0.51      0.53      0.50       394\n",
      "weighted avg       0.87      0.76      0.81       394\n",
      "\n",
      "\n",
      "--- Prefix 25 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88       288\n",
      "           1       0.14      0.32      0.20        25\n",
      "\n",
      "    accuracy                           0.79       313\n",
      "   macro avg       0.54      0.57      0.54       313\n",
      "weighted avg       0.87      0.79      0.82       313\n",
      "\n",
      "\n",
      "--- Prefix 26 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86       226\n",
      "           1       0.07      0.15      0.09        20\n",
      "\n",
      "    accuracy                           0.76       246\n",
      "   macro avg       0.49      0.48      0.48       246\n",
      "weighted avg       0.85      0.76      0.80       246\n",
      "\n",
      "\n",
      "--- Prefix 27 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86       184\n",
      "           1       0.11      0.22      0.14        18\n",
      "\n",
      "    accuracy                           0.76       202\n",
      "   macro avg       0.51      0.52      0.50       202\n",
      "weighted avg       0.84      0.76      0.80       202\n",
      "\n",
      "\n",
      "--- Prefix 28 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       147\n",
      "           1       0.06      0.15      0.09        13\n",
      "\n",
      "    accuracy                           0.74       160\n",
      "   macro avg       0.49      0.47      0.47       160\n",
      "weighted avg       0.84      0.74      0.79       160\n",
      "\n",
      "\n",
      "--- Prefix 29 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87       120\n",
      "           1       0.12      0.30      0.17        10\n",
      "\n",
      "    accuracy                           0.77       130\n",
      "   macro avg       0.52      0.55      0.52       130\n",
      "weighted avg       0.87      0.77      0.81       130\n",
      "\n",
      "\n",
      "--- Prefix 30 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87        89\n",
      "           1       0.07      0.10      0.08        10\n",
      "\n",
      "    accuracy                           0.78        99\n",
      "   macro avg       0.48      0.48      0.48        99\n",
      "weighted avg       0.81      0.78      0.79        99\n",
      "\n",
      "\n",
      "--- Prefix 31 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90        68\n",
      "           1       0.36      0.40      0.38        10\n",
      "\n",
      "    accuracy                           0.83        78\n",
      "   macro avg       0.64      0.65      0.64        78\n",
      "weighted avg       0.84      0.83      0.84        78\n",
      "\n",
      "\n",
      "--- Prefix 32 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.79        67\n",
      "   macro avg       0.48      0.41      0.44        67\n",
      "weighted avg       0.93      0.79      0.86        67\n",
      "\n",
      "\n",
      "--- Prefix 33 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87        51\n",
      "           1       0.12      0.14      0.13         7\n",
      "\n",
      "    accuracy                           0.78        58\n",
      "   macro avg       0.50      0.50      0.50        58\n",
      "weighted avg       0.79      0.78      0.78        58\n",
      "\n",
      "\n",
      "--- Prefix 34 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        43\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.80        45\n",
      "   macro avg       0.47      0.42      0.44        45\n",
      "weighted avg       0.91      0.80      0.85        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) Summarize\n",
    "reports_df = pd.DataFrame(online_ad_reports)\n",
    "for p in prefix_range:\n",
    "    sub = reports_df[reports_df[\"prefix\"] == p]\n",
    "    if not sub.empty:\n",
    "        print(f\"\\n--- Prefix {p} ---\")\n",
    "        print(classification_report(\n",
    "            sub[\"true_noise\"], sub[\"pred_ad_anom\"], zero_division=0\n",
    "        ))\n",
    "reports_df \n",
    "reports_df.to_csv('../result/%s_classifier_rf_%ssample_margin_cumulative.csv'%(dataset, TOTAL_SAMPLES), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
