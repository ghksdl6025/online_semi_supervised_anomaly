{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d142fcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root { --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, log_loss\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bdbd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, x_test, y_test):\n",
    "    \n",
    "    probs = model.predict_proba(X_test)\n",
    "    \n",
    "    predicted_probs = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        idx_arr = np.where(model.classes_ == true_label)[0]\n",
    "        if len(idx_arr) == 0:\n",
    "            predicted_probs.append(log_loss(y_true = [1,0], y_pred=[0,1])+1)\n",
    "        else:\n",
    "            col_index = idx_arr[0]\n",
    "            true_label_one_hot = np.zeros_like(probs[i])\n",
    "            true_label_one_hot[idx_arr] = 1\n",
    "            predicted_probs.append(log_loss(y_true = true_label_one_hot, y_pred = probs[i]))\n",
    "            \n",
    "    return np.array(predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "582a3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_loss(model, x_test, y_test):\n",
    "    \n",
    "    probs = model.predict_proba(X_test)\n",
    "\n",
    "    predicted_probs = []\n",
    "    for i, true_label in enumerate(y_test):\n",
    "        idx_arr = np.where(model.classes_ == true_label)[0]\n",
    "        if len(idx_arr) == 0:\n",
    "            predicted_probs.append(1.1)\n",
    "        else:\n",
    "            col_index = idx_arr[0]\n",
    "            \n",
    "            true_label_one_hot = np.zeros_like(probs[i])\n",
    "            true_label_one_hot[idx_arr] = 1\n",
    "            predicted_probs.append(1-probs[i][col_index])\n",
    "            \n",
    "    return np.array(predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32d49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_transform_target(encoder, targets, unknown_value=-1):\n",
    "    classes = set(encoder.classes_)\n",
    "    transformed = []\n",
    "    for t in targets:\n",
    "        if t in classes:\n",
    "            transformed.append(encoder.transform([t])[0])\n",
    "        else:\n",
    "            transformed.append(unknown_value)\n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b28549-009c-4453-9422-8ffa6ff0f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_loss(normal_loss_value, cross_entropy_loss_value):\n",
    "    normal_loss_dist = []\n",
    "    cross_loss_dist = []\n",
    "    for pos, prediction in  enumerate(normal_loss_value):\n",
    "        if prediction != 1:\n",
    "            cross_loss_dist.append(cross_entropy_loss_value[pos])\n",
    "            normal_loss_dist.append(prediction)\n",
    "\n",
    "    return normal_loss_dist, cross_loss_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a345773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Read and Process the Data\n",
    "# ----------------------------\n",
    "dataset = '0.099_sample.csv'\n",
    "df = pd.read_csv(\"../data/%s\" % (dataset))\n",
    "df = df.sort_values(by='Timestamp')\n",
    "# Process the 'noise' column:\n",
    "# - If NaN, assume Normal (0).\n",
    "# - Otherwise, treat True/1/'True' as anomaly (1); everything else as Normal (0).\n",
    "df['noise'] = df['noise'].fillna(0).apply(lambda x: 1 if (x == True or x == 1 or x == 'True' or x=='true') else 0)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "print(dataset)\n",
    "# Calculate the cutoff time (e.g., the median of all timestamps)\n",
    "cutoff_time = df['Timestamp'].median()\n",
    "\n",
    "# Filter out only those cases where the last event's timestamp is before or equal to the cutoff_time\n",
    "first_half_data = df.groupby('ID').filter(lambda group: group['Timestamp'].max() <= cutoff_time)\n",
    "second_half_data = df.groupby('ID').filter(lambda group: group['Timestamp'].max() > cutoff_time)\n",
    "\n",
    "anomaly_f1_list = []\n",
    "anomaly_support_list = []\n",
    "prefix_range = range(2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2a1b64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training window size: 0.2\n",
      "prefix: 2\n",
      "Total cases with at least 2 events: 244\n",
      "Encoded feature shape: (244, 12)\n",
      "Training cases: 48 Test cases: 196\n",
      "Cross entropy based adaptive threshold: 0.17399688283340758 in Probability threshod: 0.5173625250363063\n",
      "Total test cases from second half with at least 2 events: 256\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 2 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.7857142857142857, Support = 17.0\n",
      "prefix: 3\n",
      "Total cases with at least 3 events: 244\n",
      "Encoded feature shape: (244, 28)\n",
      "Training cases: 48 Test cases: 196\n",
      "Cross entropy based adaptive threshold: 0.4833758311764414 in Probability threshod: 0.7652989258621854\n",
      "Total test cases from second half with at least 3 events: 256\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 3 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.926829268292683, Support = 22.0\n",
      "prefix: 4\n",
      "Total cases with at least 4 events: 244\n",
      "Encoded feature shape: (244, 43)\n",
      "Training cases: 48 Test cases: 196\n",
      "Cross entropy based adaptive threshold: 0.8460779468289615 in Probability threshod: 0.99\n",
      "Total test cases from second half with at least 4 events: 256\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 4 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.8928571428571429, Support = 28.0\n",
      "prefix: 5\n",
      "Total cases with at least 5 events: 244\n",
      "Encoded feature shape: (244, 55)\n",
      "Training cases: 48 Test cases: 196\n",
      "Cross entropy based adaptive threshold: 1.0480161400033423 in Probability threshod: 0.99\n",
      "Total test cases from second half with at least 5 events: 256\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 5 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.8771929824561403, Support = 25.0\n",
      "prefix: 6\n",
      "Total cases with at least 6 events: 244\n",
      "Encoded feature shape: (244, 70)\n",
      "Training cases: 48 Test cases: 196\n",
      "Cross entropy based adaptive threshold: 0.815081731741726 in Probability threshod: 0.9975\n",
      "Total test cases from second half with at least 6 events: 256\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 6 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.6774193548387096, Support = 30.0\n",
      "prefix: 7\n",
      "Total cases with at least 7 events: 244\n",
      "Encoded feature shape: (244, 83)\n",
      "Training cases: 48 Test cases: 196\n",
      "Cross entropy based adaptive threshold: 0.6997666331562654 in Probability threshod: 0.997\n",
      "Total test cases from second half with at least 7 events: 256\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 7 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.547945205479452, Support = 26.0\n",
      "prefix: 8\n",
      "Total cases with at least 8 events: 244\n",
      "Encoded feature shape: (244, 101)\n",
      "Training cases: 48 Test cases: 196\n",
      "Cross entropy based adaptive threshold: 0.40398982146794593 in Probability threshod: 0.984\n",
      "Total test cases from second half with at least 8 events: 256\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 8 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.6, Support = 22.0\n",
      "prefix: 9\n",
      "Total cases with at least 9 events: 213\n",
      "Encoded feature shape: (213, 119)\n",
      "Training cases: 42 Test cases: 171\n",
      "Cross entropy based adaptive threshold: 0.4706561012679962 in Probability threshod: 0.994\n",
      "Total test cases from second half with at least 9 events: 233\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 9 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.56, Support = 22.0\n",
      "prefix: 10\n",
      "Total cases with at least 10 events: 190\n",
      "Encoded feature shape: (190, 130)\n",
      "Training cases: 38 Test cases: 152\n",
      "Cross entropy based adaptive threshold: 0.33571982577942217 in Probability threshod: 0.98\n",
      "Total test cases from second half with at least 10 events: 212\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 10 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.38095238095238093, Support = 30.0\n",
      "prefix: 11\n",
      "Total cases with at least 11 events: 175\n",
      "Encoded feature shape: (175, 137)\n",
      "Training cases: 35 Test cases: 140\n",
      "Cross entropy based adaptive threshold: 0.385324679368856 in Probability threshod: 0.99\n",
      "Total test cases from second half with at least 11 events: 198\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 11 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.3, Support = 11.0\n",
      "prefix: 12\n",
      "Total cases with at least 12 events: 149\n",
      "Encoded feature shape: (149, 151)\n",
      "Training cases: 29 Test cases: 120\n",
      "Cross entropy based adaptive threshold: 0.44493183545846315 in Probability threshod: 0.99\n",
      "Total test cases from second half with at least 12 events: 169\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 12 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.2857142857142857, Support = 18.0\n",
      "prefix: 13\n",
      "Total cases with at least 13 events: 117\n",
      "Encoded feature shape: (117, 161)\n",
      "Training cases: 23 Test cases: 94\n",
      "Cross entropy based adaptive threshold: 0.4189971093270198 in Probability threshod: 0.98\n",
      "Total test cases from second half with at least 13 events: 124\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 13 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.21818181818181817, Support = 17.0\n",
      "prefix: 14\n",
      "Total cases with at least 14 events: 99\n",
      "Encoded feature shape: (99, 164)\n",
      "Training cases: 19 Test cases: 80\n",
      "Cross entropy based adaptive threshold: 0.38476456515060414 in Probability threshod: 0.98\n",
      "Total test cases from second half with at least 14 events: 102\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 14 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.16666666666666666, Support = 7.0\n",
      "prefix: 15\n",
      "Total cases with at least 15 events: 87\n",
      "Encoded feature shape: (87, 163)\n",
      "Training cases: 17 Test cases: 70\n",
      "Cross entropy based adaptive threshold: 0.4483797603296605 in Probability threshod: 0.98\n",
      "Total test cases from second half with at least 15 events: 84\n",
      "\n",
      "--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix 15 ---\n",
      "Classification Report (Anomaly Detection using CE Loss): F1-score = 0.13333333333333333, Support = 5.0\n",
      "    Prefix length  Normal precision  Normal recall  Normal f1-score  \\\n",
      "0               2          0.975510       1.000000         0.987603   \n",
      "1               3          0.987342       1.000000         0.993631   \n",
      "2               4          0.986842       0.986842         0.986842   \n",
      "3               5          1.000000       0.969697         0.984615   \n",
      "4               6          0.959821       0.951327         0.955556   \n",
      "5               7          0.971292       0.882609         0.924829   \n",
      "6               8          0.969298       0.944444         0.956710   \n",
      "7               9          0.960976       0.933649         0.947115   \n",
      "8              10          0.899441       0.884615         0.891967   \n",
      "9              11          0.970414       0.877005         0.921348   \n",
      "10             12          0.931624       0.721854         0.813433   \n",
      "11             13          0.872093       0.700935         0.777202   \n",
      "12             14          0.945205       0.726316         0.821429   \n",
      "13             15          0.949153       0.708861         0.811594   \n",
      "\n",
      "    Normal support  Anomal precision  Anomal recall  Anomal f1-score  \\\n",
      "0            239.0          1.000000       0.647059         0.785714   \n",
      "1            234.0          1.000000       0.863636         0.926829   \n",
      "2            228.0          0.892857       0.892857         0.892857   \n",
      "3            231.0          0.781250       1.000000         0.877193   \n",
      "4            226.0          0.656250       0.700000         0.677419   \n",
      "5            230.0          0.425532       0.769231         0.547945   \n",
      "6            234.0          0.535714       0.681818         0.600000   \n",
      "7            211.0          0.500000       0.636364         0.560000   \n",
      "8            182.0          0.363636       0.400000         0.380952   \n",
      "9            187.0          0.206897       0.545455         0.300000   \n",
      "10           151.0          0.192308       0.555556         0.285714   \n",
      "11           107.0          0.157895       0.352941         0.218182   \n",
      "12            95.0          0.103448       0.428571         0.166667   \n",
      "13            79.0          0.080000       0.400000         0.133333   \n",
      "\n",
      "    Anomal support  Macro precision  Macro recall  Macro f1-score  \n",
      "0             17.0         0.987755      0.823529        0.886659  \n",
      "1             22.0         0.993671      0.931818        0.960230  \n",
      "2             28.0         0.939850      0.939850        0.939850  \n",
      "3             25.0         0.890625      0.984848        0.930904  \n",
      "4             30.0         0.808036      0.825664        0.816487  \n",
      "5             26.0         0.698412      0.825920        0.736387  \n",
      "6             22.0         0.752506      0.813131        0.778355  \n",
      "7             22.0         0.730488      0.785006        0.753558  \n",
      "8             30.0         0.631539      0.642308        0.636460  \n",
      "9             11.0         0.588655      0.711230        0.610674  \n",
      "10            18.0         0.561966      0.638705        0.549574  \n",
      "11            17.0         0.514994      0.526938        0.497692  \n",
      "12             7.0         0.524327      0.577444        0.494048  \n",
      "13             5.0         0.514576      0.554430        0.472464  \n"
     ]
    }
   ],
   "source": [
    "training_size = 0.2\n",
    "print('Training window size: %s' % (training_size))\n",
    "adaptive_thr_dict = dict()\n",
    "for anomaly_thr_method in ['fixed']:\n",
    "    classification_result = dict()\n",
    "    for prefix in prefix_range:\n",
    "        print('prefix: %s' % (prefix))\n",
    "    \n",
    "        # Extract per case:\n",
    "        # - The first (prefix-1) events (activities) as features.\n",
    "        # - The prefix-th event's activity as the target.\n",
    "        # - The prefix-th event's noise flag as the ground truth anomaly.\n",
    "        case_features = []\n",
    "        case_targets = []\n",
    "        ground_truth_anomaly = []\n",
    "    \n",
    "        for case_id, group in first_half_data.groupby('ID'):\n",
    "            group = group.sort_index()  # assuming the order in the file is the event order\n",
    "            if len(group) >= prefix:\n",
    "                events = group['Activity'].values  # adjust 'Activity' if needed\n",
    "                features = events[:prefix-1]\n",
    "                target_activity = events[prefix-1]  # prefix-th event's activity\n",
    "                noise_flag = group['noise'].iloc[prefix-1]\n",
    "    \n",
    "                case_features.append(features)\n",
    "                case_targets.append(target_activity)\n",
    "                ground_truth_anomaly.append(noise_flag)\n",
    "    \n",
    "        # Convert to numpy arrays\n",
    "        case_features = np.array(case_features)\n",
    "        case_targets = np.array(case_targets)\n",
    "        ground_truth_anomaly = np.array(ground_truth_anomaly)\n",
    "        print(\"Total cases with at least %s events:\" % (prefix), case_features.shape[0])\n",
    "    \n",
    "        # ----------------------------\n",
    "        # Step 2: Encode the Features and Target\n",
    "        # ----------------------------\n",
    "        encoder_features = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        X_encoded = encoder_features.fit_transform(case_features)\n",
    "        print(\"Encoded feature shape:\", X_encoded.shape)\n",
    "    \n",
    "        # IMPORTANT: Fit LabelEncoder on the full set of target activities (all cases)\n",
    "        target_encoder = LabelEncoder()\n",
    "        target_encoder.fit(case_targets)\n",
    "        y_encoded = target_encoder.transform(case_targets)\n",
    "        full_classes = target_encoder.classes_\n",
    "        # print(\"Full set of event classes (for prefix %s):\" % prefix, full_classes)\n",
    "    \n",
    "        # ----------------------------\n",
    "        # Step 3: Ordered Train/Test Split and Next Event Prediction Model (Stage 1)\n",
    "        # ----------------------------\n",
    "        # Instead of a random split, take the first 80% for training and the remaining 20% for testing.\n",
    "        n_cases = X_encoded.shape[0]\n",
    "        split_index = int(training_size * n_cases)\n",
    "        test_index = split_index\n",
    "        X_train = X_encoded[:split_index]\n",
    "        X_test = X_encoded[test_index:]\n",
    "        y_train = y_encoded[:split_index]\n",
    "        y_test = y_encoded[test_index:]\n",
    "        gt_anomaly_train = ground_truth_anomaly[:split_index]\n",
    "        gt_anomaly_test = ground_truth_anomaly[test_index:]\n",
    "        print(\"Training cases:\", X_train.shape[0], \"Test cases:\", X_test.shape[0])\n",
    "    \n",
    "        \n",
    "        # Train a RandomForest classifier with the training set.\n",
    "        rf_model  = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        # Now rf_model.classes_ should include all classes from full_classes.\n",
    "        \n",
    "        # ----------------------------\n",
    "        # Step 4: Anomaly Detection (Stage 2) with Dynamic Thresholding\n",
    "        # ----------------------------\n",
    "        # Obtain predicted probabilities for the test set.\n",
    "    \n",
    "        normal_loss_dist = normal_loss(rf_model, X_test, y_test)\n",
    "        normal_loss_dist = [i for i in normal_loss_dist if i <1.1]\n",
    "        sorted_normal_loss_dist = sorted(normal_loss_dist, reverse=True)\n",
    "        predicted_probs = [1-i for i in normal_loss_dist]\n",
    "        \n",
    "        cross_entropy_loss_dist = cross_entropy_loss(rf_model, X_test, y_test)\n",
    "        sorted_cross_entropy_loss_dist = [i for i in cross_entropy_loss_dist if i < log_loss([1,0], [0,1])+1]\n",
    "        sorted_cross_entropy_loss_dist = sorted(sorted_cross_entropy_loss_dist, reverse=True)\n",
    "    \n",
    "        sorted_normal_loss_dist,sorted_cross_entropy_loss_dist = get_clean_loss(sorted_normal_loss_dist, sorted_cross_entropy_loss_dist)\n",
    "                \n",
    "        diffs = np.diff(sorted_cross_entropy_loss_dist)  # consecutive differences\n",
    "        threshold = -0.02  # e.g., define a large negative drop as dramatic\n",
    "        dramatic_indices = [i for i, d in enumerate(diffs, start=1) if d < threshold]\n",
    "        adaptive_thr = sorted_cross_entropy_loss_dist[dramatic_indices[0]]\n",
    "        \n",
    "        print(\"Cross entropy based adaptive threshold:\", adaptive_thr, 'in Probability threshod:', sorted_normal_loss_dist[dramatic_indices[0]])\n",
    "        \n",
    "        # ----------------------------\n",
    "        # NEW: Override Test Set with Second Half Data\n",
    "        # ----------------------------\n",
    "        # Extract test cases from the second half using the same logic as for the training cases.\n",
    "        test_case_features = []\n",
    "        test_case_targets = []\n",
    "        test_ground_truth_anomaly = []\n",
    "    \n",
    "        for case_id, group in second_half_data.groupby('ID'):\n",
    "            group = group.sort_index()  # Ensure correct order in the case\n",
    "            if len(group) >= prefix:\n",
    "                events = group['Activity'].values\n",
    "                features = events[:prefix-1]\n",
    "                target_activity = events[prefix-1]\n",
    "                noise_flag = group['noise'].iloc[prefix-1]\n",
    "    \n",
    "                test_case_features.append(features)\n",
    "                test_case_targets.append(target_activity)\n",
    "                test_ground_truth_anomaly.append(noise_flag)\n",
    "    \n",
    "        test_case_features = np.array(test_case_features)\n",
    "        test_case_targets = np.array(test_case_targets)\n",
    "        test_ground_truth_anomaly = np.array(test_ground_truth_anomaly)\n",
    "        print(\"Total test cases from second half with at least %s events:\" % (prefix), test_case_features.shape[0])\n",
    "    \n",
    "        # Transform test features with the same encoder fitted on training cases.\n",
    "        X_test_second = encoder_features.transform(test_case_features)\n",
    "        y_test_second = safe_transform_target(target_encoder, test_case_targets)\n",
    "        \n",
    "        # Override test set variables\n",
    "        X_test = X_test_second\n",
    "        y_test = y_test_second\n",
    "        gt_anomaly_test = test_ground_truth_anomaly\n",
    "        \n",
    "        test_normal_loss = normal_loss(rf_model, X_test, y_test)\n",
    "        sorted_normal_loss_dist = [i for i in test_normal_loss if i <1.1]\n",
    "        sorted_normal_loss_dist = sorted(sorted_normal_loss_dist, reverse=True)\n",
    "        \n",
    "        test_cross_entropy = cross_entropy_loss(rf_model, X_test, y_test)\n",
    "        sorted_cross_entropy_loss_dist = [i for i in test_cross_entropy if i < log_loss([1,0], [0,1])+1]\n",
    "        sorted_cross_entropy_loss_dist = sorted(sorted_cross_entropy_loss_dist, reverse=True)\n",
    "\n",
    "        if anomaly_thr_method == 'fixed':\n",
    "            adaptive_thr = 0.01\n",
    "            predicted_anomaly = (test_normal_loss > 1-adaptive_thr).astype(int)\n",
    "        elif anomaly_thr_method == 'diff':\n",
    "            predicted_anomaly = (test_cross_entropy > adaptive_thr).astype(int)\n",
    "            adaptive_thr_dict[prefix] = adaptive_thr\n",
    "        # adaptive_thr = 0.01\n",
    "        \n",
    "    \n",
    "        # ----------------------------\n",
    "        # Step 5: Evaluate the Anomaly Detection\n",
    "        # ----------------------------\n",
    "        print(\"\\n--- Anomaly Detection (Dynamic Threshold) Classification Report for prefix %s ---\" % prefix)\n",
    "        classification = classification_report(gt_anomaly_test, predicted_anomaly, output_dict=True)\n",
    "        f1 = classification.get('1', {}).get('f1-score', 0)\n",
    "        support = classification.get('1', {}).get('support', 0)\n",
    "        classification_result[prefix] = classification\n",
    "        print(f\"Classification Report (Anomaly Detection using CE Loss): F1-score = {f1}, Support = {support}\")\n",
    "        # print(classification)\n",
    "    \n",
    "        \n",
    "    revised_cls_result = {}\n",
    "    for i in classification_result.keys():\n",
    "        revised_cls_result[i] = dict()\n",
    "        revised_cls_result[i]['Normal precision'] =classification_result[i]['0']['precision']\n",
    "        revised_cls_result[i]['Normal recall'] =classification_result[i]['0']['recall']\n",
    "        revised_cls_result[i]['Normal f1-score'] =classification_result[i]['0']['f1-score']\n",
    "        revised_cls_result[i]['Normal support'] =classification_result[i]['0']['support']\n",
    "        \n",
    "        revised_cls_result[i]['Anomal precision'] =classification_result[i]['1']['precision']\n",
    "        revised_cls_result[i]['Anomal recall'] =classification_result[i]['1']['recall']\n",
    "        revised_cls_result[i]['Anomal f1-score'] =classification_result[i]['1']['f1-score']\n",
    "        revised_cls_result[i]['Anomal support'] =classification_result[i]['1']['support']    \n",
    "    \n",
    "        revised_cls_result[i]['Macro precision'] =classification_result[i]['macro avg']['precision']   \n",
    "        revised_cls_result[i]['Macro recall'] =classification_result[i]['macro avg']['recall']   \n",
    "        revised_cls_result[i]['Macro f1-score'] =classification_result[i]['macro avg']['f1-score']   \n",
    "    \n",
    "    result_df = pd.DataFrame.from_dict(revised_cls_result).T\n",
    "    result_df.index = result_df.index.set_names(['Prefix length'])\n",
    "    result_df = result_df.reset_index(drop=False)\n",
    "    result_file_title = '../result/%s_cross_entropy_%s_anomal_thr_result.csv'%(dataset, anomaly_thr_method)\n",
    "#     print(result_file_title)\n",
    "#     print(result_df)\n",
    "#     result_df.to_csv(result_file_title, index=False)\n",
    "    print(result_df)\n",
    "# loss_prefix_title = '../result/%s_cross_entropy_loss_list.json'%(dataset)\n",
    "# with open(loss_prefix_title, 'w') as f:\n",
    "#     json.dump(adaptive_thr_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9f98192",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_cls_result = {}\n",
    "for i in classification_result.keys():\n",
    "    normal_prefix_precision = classification_result[i]['0']['precision']\n",
    "    normal_prefix_recall = classification_result[i]['0']['recall']\n",
    "    normal_prefix_f1_score = classification_result[i]['0']['f1-score']\n",
    "    normal_prefix_support = classification_result[i]['0']['support']\n",
    "    \n",
    "    anomal_prefix_precision = classification_result[i]['1']['precision']\n",
    "    anomal_prefix_recall = classification_result[i]['1']['recall']\n",
    "    anomal_prefix_f1_score = classification_result[i]['1']['f1-score']\n",
    "    anomal_prefix_support = classification_result[i]['1']['support']\n",
    "\n",
    "    revised_cls_result[i] = dict()\n",
    "    revised_cls_result[i]['Normal precision'] =normal_prefix_precision\n",
    "    revised_cls_result[i]['Normal recall'] =normal_prefix_recall\n",
    "    revised_cls_result[i]['Normal f1-score'] =normal_prefix_f1_score\n",
    "    revised_cls_result[i]['Normal support'] =normal_prefix_support\n",
    "    \n",
    "    revised_cls_result[i]['Anomal precision'] =anomal_prefix_precision\n",
    "    revised_cls_result[i]['Anomal recall'] =anomal_prefix_recall\n",
    "    revised_cls_result[i]['Anomal f1-score'] =anomal_prefix_f1_score\n",
    "    revised_cls_result[i]['Anomal support'] =anomal_prefix_support    \n",
    "\n",
    "    revised_cls_result[i]['Macro precision'] =classification_result[i]['macro avg']['precision']   \n",
    "    revised_cls_result[i]['Macro recall'] =classification_result[i]['macro avg']['recall']   \n",
    "    revised_cls_result[i]['Macro f1-score'] =classification_result[i]['macro avg']['f1-score']   \n",
    "    \n",
    "result_df = pd.DataFrame.from_dict(revised_cls_result).T\n",
    "result_df.index = result_df.index.set_names(['Prefix length'])\n",
    "result_df = result_df.reset_index(drop=False)\n",
    "result_file_title = '../result/cross_entropy_dynamic_thr_result.csv'\n",
    "# result_file_title = '../result/probability_fixed_thr_result.csv'\n",
    "\n",
    "result_df\n",
    "result_df.to_csv(result_file_title, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97fa9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2116beef4f0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted_normal_loss_dist)\n",
    "plt.plot(sorted_cross_entropy_loss_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
